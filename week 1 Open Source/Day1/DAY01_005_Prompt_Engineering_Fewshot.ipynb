{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#  Few-shot 프롬프팅\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 환경 설정 및 준비"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Langfuse로 Few-shot 프롬프트 관리하기\n",
    "\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv()\n",
    "\n",
    "import os\n",
    "import json\n",
    "from langfuse import get_client\n",
    "from langfuse.langchain import CallbackHandler\n",
    "from langchain_openai import ChatOpenAI\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "\n",
    "# Langfuse 설정\n",
    "langfuse = get_client()\n",
    "langfuse_handler = CallbackHandler()\n",
    "\n",
    "# LLM 설정\n",
    "llm = ChatOpenAI(\n",
    "    model='gpt-4.1-mini',\n",
    "    temperature=0.3,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Zero-shot** 프롬프팅\n",
    "\n",
    "- **Zero-shot 프롬프팅**은 예시 없이 AI가 즉시 작업을 수행하는 기법입니다\n",
    "\n",
    "- 명확한 **지시사항**만으로 원하는 결과를 얻을 수 있어 **사용이 간단**합니다\n",
    "\n",
    "- 단순하고 직관적인 작업에 적합한 프롬프팅 방식이지만, 작업의 **복잡도에 따라 선택적 사용**이 필요합니다"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`(1) without context`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Zero-shot 프롬프트 생성\n",
    "langfuse.create_prompt(\n",
    "    name=\"competitor-analysis-zero-shot\",\n",
    "    type=\"text\",\n",
    "    prompt=\"다음 시장에서 삼성전자의 경쟁업체를 설명해주세요: {{topic}}\",\n",
    "    labels=[\"production\"],\n",
    "    tags=[\"competitor\", \"analysis\", \"zero-shot\"]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.prompts import PromptTemplate\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "\n",
    "# Zero-shot 프롬프트 템플릿 사용\n",
    "zero_shot_template = langfuse.get_prompt(\"competitor-analysis-zero-shot\")\n",
    "\n",
    "# Langfuse 프롬프트를 LangChain과 통합\n",
    "zero_shot_prompt = PromptTemplate.from_template(\n",
    "    zero_shot_template.get_langchain_prompt()\n",
    ")\n",
    "zero_shot_prompt.metadata={\"langfuse_prompt\": zero_shot_template}  # Langfuse 자동 링크를 위한 메타데이터\n",
    "\n",
    "# 체인 생성\n",
    "chain = zero_shot_prompt | llm | StrOutputParser()\n",
    "\n",
    "zero_shot_result = chain.invoke(\n",
    "    {\"topic\": \"인공지능 반도체\"},\n",
    "    config={\"callbacks\": [langfuse_handler]}\n",
    ")\n",
    "\n",
    "print(zero_shot_result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`(2) with context`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Zero-shot with context 프롬프트 생성 \n",
    "langfuse.create_prompt(\n",
    "    name=\"competitor-analysis-zero-shot-context\",\n",
    "    type=\"text\", \n",
    "    prompt=\"\"\"{{topic}} 시장에서 삼성전자의 경쟁업체를 설명해주세요. \n",
    "반드시 다음 제시된 뉴스에 근거해서 답변하세요:\n",
    "\n",
    "[뉴스]\n",
    "{{context}}\n",
    "\n",
    "[답변]\n",
    "\"\"\",\n",
    "    labels=[\"production\"],\n",
    "    tags=[\"competitor\", \"analysis\", \"zero-shot\", \"context\"]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Zero-shot with context 프롬프트 템플릿 사용\n",
    "zero_shot_template = langfuse.get_prompt(\"competitor-analysis-zero-shot-context\")\n",
    "\n",
    "# Langfuse 프롬프트를 LangChain과 통합\n",
    "zero_shot_prompt = PromptTemplate.from_template(\n",
    "    zero_shot_template.get_langchain_prompt()\n",
    ")\n",
    "zero_shot_prompt.metadata={\"langfuse_prompt\": zero_shot_template}  # Langfuse 자동 링크를 위한 메타데이터\n",
    "\n",
    "\n",
    "# 체인 생성\n",
    "chain = zero_shot_prompt | llm | StrOutputParser()\n",
    "\n",
    "# Zero-shot 실행\n",
    "context = \"\"\"삼성전자가 내년 초에 자체적으로 개발한 인공지능(AI) 가속기를 처음으로 출시할 예정이다. \n",
    "이는 AI 반도체 시장에서 지배적인 위치를 차지하고 있는 엔비디아의 독점을 도전하고, \n",
    "세계 최고의 반도체 제조업체로서의 지위를 다시 확립하려는 삼성전자의 노력으로 해석된다.\n",
    "\"\"\"\n",
    "\n",
    "topic = \"인공지능 반도체\"\n",
    "zero_shot_result = chain.invoke(\n",
    "    {\"context\": context, \"topic\": topic},\n",
    "    config={\"callbacks\": [langfuse_handler]}  # Langfuse 트레이싱을 위한 콜백\n",
    "    )\n",
    "\n",
    "print(zero_shot_result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **One-shot** 프롬프팅\n",
    "\n",
    "- **One-shot 프롬프팅**은 하나의 예시를 통해 AI가 작업 패턴을 학습하는 기법입니다\n",
    "\n",
    "- **Zero-shot** 방식보다 더 나은 성능을 제공하며, **형식화된 작업**에 특히 효과적입니다\n",
    "\n",
    "- 단일 예시로 **품질 향상**이 가능하나, 해당 예시에 **과의존**할 수 있는 한계가 있습니다"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### One-shot 프롬프트 템플릿 생성\n",
    "# 1. Zero-shot 프롬프트 템플릿에 예시(example)를 포함하도록 수정\n",
    "# 2. input_variables에 example_topic과 example_response 추가\n",
    "# 3. config에 예시들을 저장\n",
    "\n",
    "langfuse.create_prompt(\n",
    "    name=\"competitor-analysis-one-shot\",\n",
    "    type=\"text\",\n",
    "    prompt=\"\"\"다음은 특정 시장에서 삼성전자의 경쟁업체를 설명하는 예시이다:\n",
    "\n",
    "시장: {{example_topic}}\n",
    "경쟁업체: {{example_response}}\n",
    "\n",
    "이제 다음 시장에서 삼성전자의 경쟁업체를 설명해주세요:\n",
    "시장: {{topic}}\"\"\",\n",
    "    labels=[\"production\"],\n",
    "    tags=[\"competitor\", \"analysis\", \"one-shot\"],\n",
    "    config={\n",
    "        \"example_topic\": \"스마트폰\",\n",
    "        \"example_response\": \"애플: 프리미엄 시장에서 주요 경쟁사로, iPhone 시리즈로 경쟁\\n샤오미: 중저가 시장에서 강세를 보이며 글로벌 시장 점유율 확대\\n구글: Pixel 시리즈로 프리미엄 시장 진출, AI 기능 강조\"\n",
    "    }\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 프롬프트 템플릿 사용\n",
    "one_shot_template = langfuse.get_prompt(\"competitor-analysis-one-shot\")\n",
    "\n",
    "# Langfuse 프롬프트를 LangChain과 통합\n",
    "one_shot_prompt = PromptTemplate.from_template(\n",
    "    one_shot_template.get_langchain_prompt()\n",
    ")\n",
    "one_shot_prompt.metadata={\"langfuse_prompt\": one_shot_template}  # Langfuse 자동 링크를 위한 메타데이터\n",
    "\n",
    "# one_shot_prompt 적용한 체인 생성\n",
    "chain = one_shot_prompt | llm | StrOutputParser()\n",
    "\n",
    "# One-shot 실행\n",
    "topic = \"인공지능 반도체\"\n",
    "one_shot_result = chain.invoke(\n",
    "    input={\n",
    "        \"example_topic\": one_shot_template.config.get(\"example_topic\"),\n",
    "        \"example_response\": one_shot_template.config.get(\"example_response\"),\n",
    "        \"topic\": topic\n",
    "    },\n",
    "    config={\"callbacks\": [langfuse_handler]}  # Langfuse 트레이싱을 위한 콜백\n",
    ")\n",
    "\n",
    "print(f\"one_shot_result:\")\n",
    "print(one_shot_result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Few-shot** 프롬프팅\n",
    "\n",
    "- **Few-shot 프롬프팅**은 AI 모델에게 2-5개의 예시를 제공하여 학습시키는 방법입니다\n",
    "\n",
    "- 이 방식은 **Zero-shot**이나 **One-shot** 프롬프팅보다 더 우수한 성능을 보여주며, 복잡한 작업에서 특히 효과적입니다\n",
    "\n",
    "- Few-shot 프롬프팅은 높은 성능을 제공하지만, 긴 프롬프트로 인한 **비용 증가**를 고려해야 합니다"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example 데이터 준비\n",
    "examples = \"\"\"\n",
    "시장: 스마트폰\n",
    "경쟁업체: \n",
    "- 애플(미국): 프리미엄 시장 주도, iPhone으로 경쟁\n",
    "- 샤오미(중국): 중저가 시장 강세, 글로벌 확장중\n",
    "- 구글(미국): Pixel로 AI 기능 강조\n",
    "\n",
    "시장: TV\n",
    "경쟁업체:\n",
    "- LG전자(한국): OLED 기술 경쟁\n",
    "- Sony(일본): 프리미엄 시장 경쟁\n",
    "- TCL(중국): 중저가 시장 공략\n",
    "\"\"\"\n",
    "\n",
    "# Few-shot 프롬프트를 Langfuse에 저장 (예시는 config에 저장)\n",
    "langfuse.create_prompt(\n",
    "    name=\"competitor-analysis-few-shot\",\n",
    "    type=\"text\",\n",
    "    prompt=\"\"\"다음은 여러 시장에서 삼성전자의 경쟁업체를 설명하는 예시들이다:\n",
    "\n",
    "{{examples}}\n",
    "\n",
    "이제 다음 시장에서 삼성전자의 경쟁업체를 설명해주세요:\n",
    "시장: {{topic}}\"\"\",\n",
    "    labels=[\"production\"],\n",
    "    tags=[\"competitor\", \"analysis\", \"few-shot\"],\n",
    "    config={\n",
    "        \"examples\": examples\n",
    "    }\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.prompts import PromptTemplate\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "\n",
    "# Few-shot 프롬프트 템플릿 사용\n",
    "few_shot_template = langfuse.get_prompt(\"competitor-analysis-few-shot\")\n",
    "\n",
    "# Langfuse 프롬프트를 LangChain과 통합\n",
    "few_shot_prompt = PromptTemplate.from_template(\n",
    "    few_shot_template.get_langchain_prompt()\n",
    ")\n",
    "few_shot_prompt.metadata={\"langfuse_prompt\": few_shot_template}  # Langfuse 자동 링크를 위한 메타데이터\n",
    "\n",
    "# few_shot_prompt 적용한 체인 생성\n",
    "chain = few_shot_prompt | llm | StrOutputParser()\n",
    "\n",
    "# Few-shot 실행\n",
    "topic = \"인공지능 반도체\"\n",
    "few_shot_result = chain.invoke(\n",
    "    input={\n",
    "        \"examples\": few_shot_template.config.get(\"examples\"),\n",
    "        \"topic\": topic\n",
    "    },\n",
    "    config={\"callbacks\": [langfuse_handler]}  # Langfuse 트레이싱을 위한 콜백\n",
    ")\n",
    "\n",
    "print(f\"few_shot_result:\")\n",
    "print(few_shot_result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`(3) FewShotChatMessagePromptTemplate 사용`\n",
    "\n",
    "* FewShotChatMessagePromptTemplate는 LangChain에서 제공하는 템플릿으로, **미리 정의된 고정된 예제들(Fixed Examples)** 을 프롬프트에 포함시켜 모델이 일관된 형식과 품질의 응답을 생성할 수 있도록 돕습니다.\n",
    "\n",
    "* 이 방식은 특히 특정 형식이나 구조를 가진 출력이 필요한 경우(예: JSON 형식, 특정 분석 리포트 형식 등) 매우 유용하며, 예제들이 고정되어 있어 결과의 일관성을 보장할 수 있습니다.\n",
    "\n",
    "* 단, 고정된 예제를 사용하기 때문에 상황에 따라 유연하게 대응하기 어려울 수 있으며, 모든 케이스를 커버하기 위해서는 신중한 예제 선택이 필요합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.prompts import ChatPromptTemplate, FewShotChatMessagePromptTemplate\n",
    "from textwrap import dedent # text의 모든 줄에서 같은 선행 공백을 제거하는 함수\n",
    "\n",
    "# 예시 데이터 정의 : 뉴스 텍스트(input) + 키워드 추출 결과 (output)\n",
    "examples = [\n",
    "    {\n",
    "        \"input\": dedent(\"\"\"\n",
    "                        정부는 의과대학 입학 정원을 2000명 증가시킬 계획의 세부사항을 이달 20일에 공개할 예정이다. \n",
    "                        지역별 의료 서비스 향상과 소규모 의과대학의 발전을 목표로, 지역 중심의 국립대학 및 소형 의과대학의 \n",
    "                        입학 정원이 최소한 두 배 가량 확대될 것으로 보인다.\n",
    "                        \"\"\"),\n",
    "        \"output\": \"의대 | 정원 | 확대\"\n",
    "    },\n",
    "    {\n",
    "        \"input\": dedent(\"\"\"\n",
    "                        세계보건기구(WHO)는 최근 새로운 건강 위기에 대응하기 위해 국제 협력의 중요성을 강조했다. \n",
    "                        전염병 대응 역량의 강화와 글로벌 보건 시스템의 개선이 필요하다고 발표했다.\n",
    "                        \"\"\"),\n",
    "        \"output\": \"세계보건기구 | 건강위기 | 국제\"\n",
    "    }\n",
    "]\n",
    "\n",
    "# 각 예시를 포맷팅할 프롬프트 템플릿\n",
    "example_prompt = ChatPromptTemplate.from_messages([\n",
    "    (\"human\", \"{input}\"),\n",
    "    (\"assistant\", \"{output}\")\n",
    "])\n",
    "\n",
    "# Few-shot 프롬프트 템플릿 생성\n",
    "few_shot_prompt = FewShotChatMessagePromptTemplate(\n",
    "    example_prompt=example_prompt,      # 예시 포맷팅 템플릿\n",
    "    examples=examples                   # 예시 데이터 리스트 -> 예시 포맷팅 템플릿에 적용\n",
    ")\n",
    "\n",
    "# Few-shot 프롬프트 출력 예시\n",
    "print(few_shot_prompt.format())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 최종 프롬프트 템플릿 생성\n",
    "final_prompt = ChatPromptTemplate.from_messages([\n",
    "    (\"system\", \"당신은 뉴스 텍스트에서 핵심 키워드 3개를 추출하는 전문가입니다.\"),\n",
    "    few_shot_prompt,\n",
    "    (\"human\", \"{input}\")\n",
    "])\n",
    "\n",
    "# 프롬프트 템플릿 출력\n",
    "print(final_prompt.format(input=\"테스트 뉴스 기사입니다.\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 키워드 추출 체인 생성\n",
    "chain = final_prompt | llm | StrOutputParser()\n",
    "\n",
    "# 키워드 추출 체인 실행\n",
    "result = chain.invoke({\n",
    "    \"input\": dedent(\"\"\"삼성전자가 내년 초에 자체적으로 개발한 인공지능(AI) 가속기를 처음으로 출시할 예정이다. \n",
    "                    이는 AI 반도체 시장에서 지배적인 위치를 차지하고 있는 엔비디아의 독점을 도전하고, \n",
    "                    세계 최고의 반도체 제조업체로서의 지위를 다시 확립하려는 삼성전자의 노력으로 해석된다.\"\"\")\n",
    "})\n",
    "\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Langfuse에서 구현 (메시지플레이스홀더 사용)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Few-shot 프롬프트를 Langfuse에 생성 (Message Placeholder 사용)\n",
    "langfuse.create_prompt(\n",
    "    name=\"keyword-extractor-few-shot\",\n",
    "    type=\"chat\",\n",
    "    prompt=[\n",
    "        {\n",
    "            \"role\": \"system\",\n",
    "            \"content\": \"\"\"당신은 뉴스 텍스트에서 핵심 키워드를 추출하는 전문가입니다.\n",
    "다음 지침을 따라주세요:\n",
    "- 가장 중요한 키워드 3개를 추출\n",
    "- 키워드는 ' | ' 로 구분\n",
    "- 명사 위주로 추출\n",
    "- 고유명사와 핵심 개념 우선\"\"\"\n",
    "        },\n",
    "        {\n",
    "            \"type\": \"placeholder\", \n",
    "            \"name\": \"few_shot_examples\"  # Few-shot 예시들이 들어갈 placeholder\n",
    "        },\n",
    "        {\n",
    "            \"role\": \"user\",\n",
    "            \"content\": \"다음 뉴스 텍스트에서 핵심 키워드를 추출해주세요:\\n\\n{{input_text}}\"\n",
    "        }\n",
    "    ],\n",
    "    labels=[\"production\"],\n",
    "    tags=[\"keyword\", \"extraction\", \"few-shot\", \"news\"],\n",
    "    config={\n",
    "        \"model\": \"gpt-4.1-mini\",\n",
    "        \"temperature\": 0.1,  # 일관성을 위해 낮은 temperature\n",
    "        \"max_tokens\": 100\n",
    "    }\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Langfuse 프롬프트 가져오기\n",
    "prompt = langfuse.get_prompt(\"keyword-extractor-few-shot\", type=\"chat\")\n",
    "\n",
    "# LangChain과 통합하여 실행\n",
    "langchain_prompt = ChatPromptTemplate.from_messages(\n",
    "    prompt.get_langchain_prompt()\n",
    ")\n",
    "\n",
    "# 메타데이터 설정\n",
    "langchain_prompt.metadata = {\"langfuse_prompt\": prompt}\n",
    "\n",
    "# 모델 초기화\n",
    "model = ChatOpenAI(\n",
    "    model=prompt.config.get(\"model\", \"gpt-4.1-mini\"),\n",
    "    temperature=prompt.config.get(\"temperature\", 0.1),\n",
    "    max_completion_tokens=prompt.config.get(\"max_tokens\", 100)\n",
    ")\n",
    "\n",
    "# 체인 생성\n",
    "chain = langchain_prompt | model\n",
    "\n",
    "# Few-shot 프롬프트 실행\n",
    "\n",
    "# 뉴스 텍스트 정의\n",
    "news_text = dedent(\"\"\"\n",
    "정부는 내년부터 전기차 구매 보조금을 기존 대비 30% 확대하기로 결정했다.\n",
    "탄소 중립 목표 달성과 친환경 자동차 산업 육성을 위한 조치로, \n",
    "개인 구매자는 최대 800만원, 법인은 최대 500만원까지 지원받을 수 있다.\n",
    "\"\"\")\n",
    "\n",
    "\n",
    "# Few-shot 예시 데이터 정의\n",
    "few_shot_examples = [\n",
    "    {\n",
    "        \"role\": \"user\",\n",
    "        \"content\": dedent(\"\"\"\n",
    "                        정부는 의과대학 입학 정원을 2000명 증가시킬 계획의 세부사항을 이달 20일에 공개할 예정이다. \n",
    "                        지역별 의료 서비스 향상과 소규모 의과대학의 발전을 목표로, 지역 중심의 국립대학 및 소형 의과대학의 \n",
    "                        입학 정원이 최소한 두 배 가량 확대될 것으로 보인다.\n",
    "                        \"\"\")\n",
    "    },\n",
    "    {\n",
    "        \"role\": \"assistant\",\n",
    "        \"content\": \"의대 | 정원 | 확대\"\n",
    "    },\n",
    "    {\n",
    "        \"role\": \"user\", \n",
    "        \"content\": dedent(\"\"\"\n",
    "                        세계보건기구(WHO)는 최근 새로운 건강 위기에 대응하기 위해 국제 협력의 중요성을 강조했다. \n",
    "                        전염병 대응 역량의 강화와 글로벌 보건 시스템의 개선이 필요하다고 발표했다.\n",
    "                        \"\"\")\n",
    "    },\n",
    "    {\n",
    "        \"role\": \"assistant\",\n",
    "        \"content\": \"세계보건기구 | 건강위기 | 국제협력\"\n",
    "    },\n",
    "    {\n",
    "        \"role\": \"user\",\n",
    "        \"content\": dedent(\"\"\"\n",
    "                        삼성전자가 새로운 갤럭시 스마트폰 시리즈를 내년 1분기에 출시할 예정이라고 발표했다.\n",
    "                        인공지능 기능이 대폭 강화되고 배터리 수명도 20% 향상될 것으로 예상된다.\n",
    "                        \"\"\")\n",
    "    },\n",
    "    {\n",
    "        \"role\": \"assistant\", \n",
    "        \"content\": \"삼성전자 | 갤럭시 | 인공지능\"\n",
    "    }\n",
    "]\n",
    "\n",
    "response = chain.invoke(\n",
    "    input={\n",
    "        \"input_text\": news_text,\n",
    "        \"few_shot_examples\": few_shot_examples\n",
    "    },\n",
    "    config={\n",
    "        \"callbacks\": [langfuse_handler],\n",
    "        \"metadata\": {\n",
    "            \"user_id\": \"user_123\",\n",
    "            \"task\": \"keyword_extraction\",\n",
    "            \"method\": \"few_shot_learning\"\n",
    "        }\n",
    "    }\n",
    ")\n",
    "\n",
    "print(response.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`(4) Dynamic Few-Shot Prompting`\n",
    "\n",
    "* **Dynamic Few-Shot Prompting**은 상황에 따라 적절한 예시를 동적으로 선택하여 사용하는 고급 프롬프팅 기법으로, **BaseExampleSelector**를 통해 입력값과 가장 연관성이 높은 예시들을 자동으로 선별합니다.\n",
    "\n",
    "* 대표적으로 **SemanticSimilarityExampleSelector**는 의미적 유사도를 기반으로 예시를 선택하며, 이를 통해 주어진 입력 상황에 가장 적합한 예시들만을 효율적으로 활용할 수 있습니다.\n",
    "\n",
    "* **example_prompt**를 통해 선택된 예시들을 AI 시스템이 이해하기 쉬운 형태(예: human-AI 대화 , human-function call)로 변환하여 더 효과적인 학습과 응답 생성이 가능하게 합니다.\n",
    "\n",
    "\n",
    "- **장점**\n",
    "\n",
    "    - 상황에 맞는 가장 연관성 높은 예시만을 선택적으로 활용할 수 있다\n",
    "    - 프롬프트의 길이를 효율적으로 관리할 수 있다\n",
    "    - 응답의 일관성과 품질을 향상시킬 수 있다"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_ollama import OllamaEmbeddings \n",
    "from langchain_core.vectorstores import InMemoryVectorStore # type: ignore\n",
    "\n",
    "# 고객 문의 유형별 응대 예시 데이터\n",
    "examples = [\n",
    "    {\n",
    "        \"input\": \"환불 절차가 어떻게 되나요?\",\n",
    "        \"output\": \"환불 절차는 다음과 같습니다:\\n1. 구매내역에서 환불을 신청해주세요\\n2. 반품 상품을 발송해주세요\\n3. 상품 검수 후 3-5일 내 환불이 완료됩니다\"\n",
    "    },\n",
    "    {\n",
    "        \"input\": \"배송이 늦어지고 있어요\", \n",
    "        \"output\": \"불편을 드려 죄송합니다. 주문번호를 알려주시면 배송 상태를 즉시 확인해드리겠습니다.\"\n",
    "    },\n",
    "    {\n",
    "        \"input\": \"옷 사이즈가 안 맞아요\",\n",
    "        \"output\": \"사이즈 교환은 무료로 진행됩니다. 교환 신청 후 동일 상품의 다른 사이즈로 발송해드리겠습니다.\"\n",
    "    },\n",
    "    {\n",
    "        \"input\": \"제품이 불량이에요\",\n",
    "        \"output\": \"불편을 드려 대단히 죄송합니다. 불량 부분 사진과 함께 1:1 문의에 접수해주시면 빠르게 처리해드리겠습니다.\"\n",
    "    },\n",
    "    {\n",
    "        \"input\": \"주문을 취소하고 싶어요\",\n",
    "        \"output\": \"주문 취소는 배송 전까지 가능합니다. 마이페이지에서 주문 취소를 진행해주시거나 고객센터로 연락주세요.\"\n",
    "    },\n",
    "    {\n",
    "        \"input\": \"할인 쿠폰이 적용이 안 돼요\",\n",
    "        \"output\": \"쿠폰 사용 조건을 확인해주세요. 최소 구매 금액이나 적용 상품에 제한이 있을 수 있습니다.\"\n",
    "    },\n",
    "    {\n",
    "        \"input\": \"회원가입이 안 돼요\",\n",
    "        \"output\": \"회원가입 시 필수 정보를 모두 입력해주세요. 문제가 지속되면 고객센터로 연락주시기 바랍니다.\"\n",
    "    }\n",
    "]\n",
    "\n",
    "# 예시 데이터를 벡터화할 텍스트로 변환\n",
    "to_vectorize = [\" \".join(example.values()) for example in examples]\n",
    "\n",
    "# Ollama 임베딩 모델 생성\n",
    "embeddings = OllamaEmbeddings(model=\"bge-m3\")\n",
    "\n",
    "# 벡터 스토어 생성\n",
    "vector_store = InMemoryVectorStore.from_texts(\n",
    "    to_vectorize,    # 벡터화할 텍스트 리스트\n",
    "    embeddings,      # 임베딩 모델\n",
    "    metadatas=examples    # 메타데이터: 예시 데이터\n",
    "    )\n",
    "\n",
    "# VectorStore에 저장된 Document 개수 확인\n",
    "print(f\"VectorStore에 저장된 Document 개수: {len(vector_store.store.keys())}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.example_selectors import SemanticSimilarityExampleSelector\n",
    "\n",
    "# 유사한 2개의 예시를 선택하는 selector 생성\n",
    "example_selector = SemanticSimilarityExampleSelector(\n",
    "    vectorstore=vector_store,\n",
    "    k=2\n",
    ")\n",
    "\n",
    "# 선택된 예시 확인\n",
    "selected_examples = example_selector.select_examples({\"input\":\"상품이 파손되어 왔어요\"})\n",
    "\n",
    "from pprint import pprint\n",
    "pprint(selected_examples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 챗봇 프롬프트 템플릿 생성\n",
    "few_shot_prompt = FewShotChatMessagePromptTemplate(\n",
    "    input_variables=[\"input\"],\n",
    "    example_selector=example_selector,\n",
    "    example_prompt=ChatPromptTemplate.from_messages([\n",
    "        (\"human\", \"{input}\"),\n",
    "        (\"assistant\", \"{output}\")\n",
    "    ])\n",
    ")\n",
    "\n",
    "pprint(few_shot_prompt.invoke({\"input\": \"상품이 파손되어 왔어요\"}).to_messages())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 최종 프롬프트 생성 \n",
    "final_prompt = ChatPromptTemplate.from_messages([\n",
    "    (\"system\", \"당신은 친절하고 전문적인 고객 서비스 담당자입니다.\"),\n",
    "    few_shot_prompt,\n",
    "    (\"human\", \"{input}\")\n",
    "])\n",
    "\n",
    "pprint(final_prompt.invoke({\"input\": \"상품이 파손되어 왔어요\"}).to_messages())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 챗봇 체인 생성\n",
    "chain = final_prompt | llm | StrOutputParser()\n",
    "\n",
    "# 체인 실행\n",
    "response = chain.invoke({\n",
    "    \"input\": \"상품이 파손되어 왔어요\"\n",
    "})\n",
    "\n",
    "pprint(response)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- langfuse에서 구현 (메시지플레이스홀더 사용)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Langfuse에 Semantic Few-shot 프롬프트 생성\n",
    "langfuse.create_prompt(\n",
    "    name=\"customer-service-semantic-few-shot\",\n",
    "    type=\"chat\",\n",
    "    prompt=[\n",
    "        {\n",
    "            \"role\": \"system\",\n",
    "            \"content\": \"당신은 친절하고 전문적인 고객 서비스 담당자입니다. 고객의 문의에 정확하고 도움이 되는 답변을 제공해주세요.\"\n",
    "        },\n",
    "        {\n",
    "            \"type\": \"placeholder\",\n",
    "            \"name\": \"selected_examples\"  # 유사도 기반으로 선택된 예시들\n",
    "        },\n",
    "        {\n",
    "            \"role\": \"user\",\n",
    "            \"content\": \"{{customer_inquiry}}\"  # 실제 고객 문의\n",
    "        }\n",
    "    ],\n",
    "    labels=[\"production\"],\n",
    "    tags=[\"customer-service\", \"semantic-similarity\", \"few-shot\"],\n",
    "    config={\n",
    "        \"model\": \"gpt-4.1-mini\",\n",
    "        \"temperature\": 0.7,\n",
    "        \"max_tokens\": 300\n",
    "    }\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 선택된 예시 확인\n",
    "selected_examples = example_selector.select_examples({\"input\":\"상품이 파손되어 왔어요\"})\n",
    "\n",
    "from pprint import pprint\n",
    "pprint(selected_examples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 선택된 예시들을 메시지 형태로 변환\n",
    "selected_examples_messages = []\n",
    "for example in selected_examples:\n",
    "    selected_examples_messages.extend([\n",
    "        {\"role\": \"user\", \"content\": example[\"input\"]},\n",
    "        {\"role\": \"assistant\", \"content\": example[\"output\"]}\n",
    "    ])\n",
    "\n",
    "for message in selected_examples_messages:\n",
    "    print(message)\n",
    "    print(\"-\" * 80)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 동적 Few-shot 프롬프트 실행 함수\n",
    "def run_semantic_few_shot(customer_inquiry, k=2):\n",
    "    \"\"\"고객 문의에 대해 유사도 기반 Few-shot 프롬프트 실행\"\"\"\n",
    "    \n",
    "    # 유사한 예시들을 선택\n",
    "    selected_examples_raw = example_selector.select_examples({\"input\": customer_inquiry})\n",
    "    \n",
    "    # 선택된 예시들을 메시지 형태로 변환\n",
    "    selected_examples_messages = []\n",
    "    for example in selected_examples_raw:\n",
    "        selected_examples_messages.extend([\n",
    "            {\"role\": \"user\", \"content\": example[\"input\"]},\n",
    "            {\"role\": \"assistant\", \"content\": example[\"output\"]}\n",
    "        ])\n",
    "    \n",
    "    # Langfuse 프롬프트 가져오기\n",
    "    prompt = langfuse.get_prompt(\"customer-service-semantic-few-shot\", type=\"chat\")\n",
    "\n",
    "    langchain_prompt = ChatPromptTemplate.from_messages(\n",
    "        prompt.get_langchain_prompt()\n",
    "    )\n",
    "    langchain_prompt.metadata = {\"langfuse_prompt\": prompt}\n",
    "\n",
    "\n",
    "    compiled_prompt = prompt.compile(\n",
    "        customer_inquiry=customer_inquiry,\n",
    "        selected_examples=selected_examples_messages\n",
    "    )\n",
    "\n",
    "\n",
    "    # 모델 초기화\n",
    "    model = ChatOpenAI(\n",
    "        model=prompt.config.get(\"model\", \"gpt-4.1-mini\"),\n",
    "        temperature=prompt.config.get(\"temperature\", 0.7),\n",
    "        max_completion_tokens=prompt.config.get(\"max_tokens\", 300)\n",
    "    )\n",
    "\n",
    "    # LangChain 체인 설정\n",
    "    chain = langchain_prompt | model\n",
    "\n",
    "    # 체인 실행\n",
    "    response = chain.invoke(\n",
    "        input={\n",
    "            \"customer_inquiry\": customer_inquiry,\n",
    "            \"selected_examples\": selected_examples_messages\n",
    "        },\n",
    "        config={\"callbacks\": [langfuse_handler]}\n",
    "    )\n",
    "    \n",
    "    return response, selected_examples_messages\n",
    "\n",
    "# 테스트 실행\n",
    "test_inquiry = \"상품이 파손되어 왔어요\"\n",
    "response, selected_examples = run_semantic_few_shot(test_inquiry)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(response.content)\n",
    "print(\"=\" * 80)\n",
    "for message in selected_examples:\n",
    "    print(message)\n",
    "    print(\"-\" * 80)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
