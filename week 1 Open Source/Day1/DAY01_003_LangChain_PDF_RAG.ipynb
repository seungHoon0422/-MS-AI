{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8d256e61",
   "metadata": {},
   "source": [
    "## **Retrieval Augmented Generation (RAG)**\n",
    "\n",
    "- ëŒ€ê·œëª¨ ì–¸ì–´ ëª¨ë¸(LLM)ì— ì™¸ë¶€ ì§€ì‹ì„ ì—°ê²°í•˜ì—¬ ë” ì •í™•í•˜ê³  ìµœì‹ ì˜ ì •ë³´ë¥¼ ì œê³µí•˜ëŠ” AI í”„ë ˆì„ì›Œí¬\n",
    "\n",
    "- RAGì˜ ì‘ë™ ì›ë¦¬\n",
    "    - ì‚¬ìš©ì ì§ˆë¬¸ â†’ ê´€ë ¨ ë¬¸ì„œ ê²€ìƒ‰ â†’ ì»¨í…ìŠ¤íŠ¸ì™€ í•¨ê»˜ LLMì— ì „ë‹¬ â†’ ë‹µë³€ ìƒì„±\n",
    "\n",
    "- RAG vs ì¼ë°˜ LLM ë¹„êµ\n",
    "\n",
    "    | êµ¬ë¶„ | ì¼ë°˜ LLM | RAG |\n",
    "    |------|----------|-----|\n",
    "    | ì •ë³´ ì†ŒìŠ¤ | ì‚¬ì „ í›ˆë ¨ ë°ì´í„°ë§Œ | ì™¸ë¶€ ì§€ì‹ë² ì´ìŠ¤ + ì‚¬ì „ í›ˆë ¨ ë°ì´í„° |\n",
    "    | ìµœì‹ ì„± | í›ˆë ¨ ì‹œì ê¹Œì§€ | ì‹¤ì‹œê°„ ì—…ë°ì´íŠ¸ ê°€ëŠ¥ |\n",
    "    | ì •í™•ì„± | í™˜ê°(hallucination) ê°€ëŠ¥ì„± | ê²€ì¦ëœ ë¬¸ì„œ ê¸°ë°˜ ë‹µë³€ |\n",
    "    | ì‚¬ìš© ì‚¬ë¡€ | ì¼ë°˜ì ì¸ ì§ˆë¬¸ ë‹µë³€ | íŠ¹ì • ë„ë©”ì¸ì˜ ì „ë¬¸ì  ë‹µë³€ |\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2641ec21",
   "metadata": {},
   "source": [
    "## í™˜ê²½ ì„¤ì • ë° ì¤€ë¹„"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4be5eb8",
   "metadata": {},
   "source": [
    "`(1) Env í™˜ê²½ë³€ìˆ˜`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "829d8712",
   "metadata": {},
   "outputs": [],
   "source": [
    "# .env íŒŒì¼ ìƒì„±\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv()\n",
    "\n",
    "# OpenAI API í‚¤ ì„¤ì • (í•„ìš”ì‹œ)\n",
    "# OPENAI_API_KEY=your_openai_api_key_here"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5989430",
   "metadata": {},
   "source": [
    "`(2) ê¸°ë³¸ ë¼ì´ë¸ŒëŸ¬ë¦¬`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa02fc31",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from glob import glob\n",
    "from pprint import pprint\n",
    "import json\n",
    "from pathlib import Path"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e69732dd",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## ë¬¸ì„œ ë¡œë” (Document Loaders)\n",
    "\n",
    "- **Document Loader**ëŠ” ë‹¤ì–‘í•œ ì†ŒìŠ¤ì—ì„œ ë¬¸ì„œë¥¼ ë¡œë“œí•˜ì—¬ LangChainì˜ `Document` ê°ì²´ë¡œ ë³€í™˜í•˜ëŠ” ë„êµ¬\n",
    "\n",
    "- **Document ê°ì²´ êµ¬ì¡°**\n",
    "\n",
    "    ```python\n",
    "    from langchain_core.documents import Document\n",
    "\n",
    "    # Document ê°ì²´ì˜ ê¸°ë³¸ êµ¬ì¡°\n",
    "    document = Document(\n",
    "        page_content=\"ë¬¸ì„œì˜ í…ìŠ¤íŠ¸ ë‚´ìš©\",\n",
    "        metadata={\n",
    "            \"source\": \"ë¬¸ì„œ ì¶œì²˜\",\n",
    "            \"page\": 1,\n",
    "            \"title\": \"ë¬¸ì„œ ì œëª©\"\n",
    "        }\n",
    "    )\n",
    "    ```\n",
    "\n",
    "- **ë¬¸ì„œ ë¡œë”ì˜ ì¢…ë¥˜**\n",
    "    - PDF íŒŒì¼ ë¡œë”\n",
    "    - ì›¹ í˜ì´ì§€ ë¡œë” \n",
    "    - CSV ë°ì´í„° ë¡œë”\n",
    "    - ë””ë ‰í† ë¦¬ ë¡œë”\n",
    "    - HTML ë°ì´í„° ë¡œë”\n",
    "    - JSON ë°ì´í„° ë¡œë”\n",
    "    - Markdown ë°ì´í„° ë¡œë”\n",
    "    - Microsoft Office ë°ì´í„° ë¡œë”"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "807d28ef",
   "metadata": {},
   "source": [
    "### **PDF íŒŒì¼ ë¡œë”**\n",
    "\n",
    "- uv add langchain_community pypdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90aa754e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_community.document_loaders import PyPDFLoader\n",
    "\n",
    "# PDF ë¡œë” ì´ˆê¸°í™”\n",
    "pdf_loader = PyPDFLoader('data/labor_law.pdf', mode='page')\n",
    "\n",
    "# ë™ê¸° ë¡œë”©\n",
    "pdf_docs = pdf_loader.load()\n",
    "print(f'PDF ë¬¸ì„œ ê°œìˆ˜: {len(pdf_docs)}')\n",
    "print()\n",
    "\n",
    "# ê° í˜ì´ì§€ë³„ ì •ë³´ í™•ì¸\n",
    "for i, doc in enumerate(pdf_docs[:3]):\n",
    "    print(f\"í˜ì´ì§€ {i+1}: {len(doc.page_content)} ë¬¸ì\")\n",
    "    print(f\"ë©”íƒ€ë°ì´í„°: {doc.metadata}\")\n",
    "    print(\"-\" * 50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55aa14ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(pdf_docs[0].page_content[:1000])  # ì²« í˜ì´ì§€ì˜ ë‚´ìš© ì¼ë¶€ ì¶œë ¥"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "491ff6ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "pprint(pdf_docs[0].metadata)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5c87d63",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_community.document_loaders import PyPDFLoader\n",
    "\n",
    "# PDF ë¡œë” ì´ˆê¸°í™”\n",
    "pdf_loader = PyPDFLoader('data/labor_law.pdf', mode='single')\n",
    "\n",
    "# ë™ê¸° ë¡œë”©\n",
    "pdf_docs = pdf_loader.load()\n",
    "print(f'PDF ë¬¸ì„œ ê°œìˆ˜: {len(pdf_docs)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "936453f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "pprint(pdf_docs[0].metadata)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81a567f5",
   "metadata": {},
   "source": [
    "#### ğŸ“ ì—°ìŠµ ë¬¸ì œ 1: PDF íŒŒì¼ ë¡œë“œ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82358a04",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "ğŸ“Œ ì‹¤ìŠµ: data í´ë”ì— ìˆëŠ” ë‹¤ìŒ íŒŒì¼ì„ ë¡œë“œí•˜ì„¸ìš”:\n",
    "1. PDF íŒŒì¼ì„ í˜ì´ì§€ë³„ë¡œ ë¶„í• í•˜ì—¬ ë¡œë“œ (data/personal_info_law.pdf)\n",
    "2. ê° í˜ì´ì§€ì˜ ë©”íƒ€ë°ì´í„° í™•ì¸\n",
    "3. ì „ì²´ ë¬¸ì„œë¥¼ ë‹¨ì¼ Documentë¡œ ë¡œë“œ\n",
    "\"\"\"\n",
    "\n",
    "# ì—¬ê¸°ì— ì½”ë“œë¥¼ ì‘ì„±í•˜ì„¸ìš”"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7bf1418a",
   "metadata": {},
   "source": [
    "<details>\n",
    "<summary>ğŸ’¡ ì •ë‹µ ë³´ê¸°</summary>\n",
    "\n",
    "```python\n",
    "from langchain_community.document_loaders import PyPDFLoader\n",
    "\n",
    "# 1. í˜ì´ì§€ë³„ ë¶„í•  ë¡œë“œ\n",
    "pdf_loader_pages = PyPDFLoader('data/personal_info_law.pdf', mode='page')\n",
    "pages_docs = pdf_loader_pages.load()\n",
    "\n",
    "print(f\"í˜ì´ì§€ë³„ ë¶„í•  ì‹œ ë¬¸ì„œ ê°œìˆ˜: {len(pages_docs)}\")\n",
    "print(f\"ì²« í˜ì´ì§€ ë©”íƒ€ë°ì´í„°: {pages_docs[0].metadata}\")\n",
    "print(f\"ì²« í˜ì´ì§€ ë‚´ìš© (100ì): {pages_docs[0].page_content[:100]}\")\n",
    "\n",
    "# 2. ë‹¨ì¼ ë¬¸ì„œë¡œ ë¡œë“œ\n",
    "pdf_loader_single = PyPDFLoader('data/personal_info_law.pdf', mode='single')\n",
    "single_doc = pdf_loader_single.load()\n",
    "\n",
    "print(f\"\\në‹¨ì¼ ë¬¸ì„œ ë¡œë“œ ì‹œ ë¬¸ì„œ ê°œìˆ˜: {len(single_doc)}\")\n",
    "print(f\"ì „ì²´ ë¬¸ì„œ ê¸¸ì´: {len(single_doc[0].page_content)} ë¬¸ì\")\n",
    "```\n",
    "</details>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ebb33946",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## í…ìŠ¤íŠ¸ ë¶„í•  (Chunking)\n",
    "\n",
    "-  ğŸ¯ í…ìŠ¤íŠ¸ ë¶„í• ì´ í•„ìš”í•œ ì´ìœ \n",
    "    1. **í† í° ì œí•œ**: LLMì€ ì…ë ¥ í† í° ìˆ˜ì— ì œí•œì´ ìˆìŒ\n",
    "    2. **ê²€ìƒ‰ ì •í™•ë„**: ì‘ì€ ì²­í¬ê°€ ë” ì •í™•í•œ ê²€ìƒ‰ ê²°ê³¼ ì œê³µ\n",
    "    3. **ë©”ëª¨ë¦¬ íš¨ìœ¨ì„±**: ëŒ€ìš©ëŸ‰ ë¬¸ì„œì˜ íš¨ìœ¨ì  ì²˜ë¦¬\n",
    "\n",
    "- ğŸ“Š ë¶„í•  ì „ëµ ë¹„êµ\n",
    "\n",
    "    | ë°©ë²• | ì¥ì  | ë‹¨ì  | ì‚¬ìš© ì‚¬ë¡€ |\n",
    "    |------|------|------|----------|\n",
    "    | CharacterTextSplitter | ë‹¨ìˆœ, ë¹ ë¦„ | ë¬¸ë§¥ ê³ ë ¤ ì•ˆí•¨ | ê°„ë‹¨í•œ í…ìŠ¤íŠ¸ |\n",
    "    | RecursiveCharacterTextSplitter | ë¬¸ë§¥ ë³´ì¡´ ìš°ìˆ˜ | ê³„ì‚° ë³µì¡ | ì¼ë°˜ì ì¸ ë¬¸ì„œ |\n",
    "    | TokenTextSplitter | ì •í™•í•œ í† í° ìˆ˜ | í† í¬ë‚˜ì´ì € ì˜ì¡´ | API ë¹„ìš© ìµœì í™” |\n",
    "    | SemanticChunker | ì˜ë¯¸ ê¸°ë°˜ ë¶„í•  | ëŠë¦¼, ë¹„ìš© ë§ìŒ | í”Œë¡¯, ì‹œë‚˜ë¦¬ì˜¤ ë“± |"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a007e618",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f'ì²« ë²ˆì§¸ ë¬¸ì„œ: {pdf_docs[0]}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "742f6597",
   "metadata": {},
   "outputs": [],
   "source": [
    "long_text = pdf_docs[0].page_content\n",
    "print(f'ì²« ë²ˆì§¸ ë¬¸ì„œì˜ í…ìŠ¤íŠ¸ ê¸¸ì´: {len(long_text)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95a5ec79",
   "metadata": {},
   "source": [
    "### 1. **CharacterTextSplitter**\n",
    "- ê°€ì¥ ê¸°ë³¸ì ì¸ ë¶„í•  ë°©ì‹\n",
    "- ë¬¸ì ìˆ˜ë¥¼ ê¸°ì¤€ìœ¼ë¡œ í…ìŠ¤íŠ¸ë¥¼ ë¶„í• \n",
    "- ë‹¨ìˆœí•˜ì§€ë§Œ ë¬¸ë§¥ì„ ê³ ë ¤í•˜ì§€ ì•ŠëŠ”ë‹¤ëŠ” ë‹¨ì ì´ ìˆìŒ\n",
    "\n",
    "- ì„¤ì¹˜: pip install langchain_text_splitters ë˜ëŠ” uv add langchain_text_splitters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1a1f1b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_text_splitters import CharacterTextSplitter\n",
    "\n",
    "# ê¸°ë³¸ ì„¤ì •\n",
    "text_splitter = CharacterTextSplitter(\n",
    "    separator=\"\\n\\n\",        # êµ¬ë¶„ì\n",
    "    chunk_size=1000,         # ì²­í¬ í¬ê¸°\n",
    "    chunk_overlap=200,       # ì¤‘ë³µ í¬ê¸°\n",
    "    length_function=len,     # ê¸¸ì´ ì¸¡ì • í•¨ìˆ˜\n",
    "    is_separator_regex=False # ì •ê·œì‹ ì—¬ë¶€\n",
    ")\n",
    "\n",
    "# í…ìŠ¤íŠ¸ ë¶„í•  - split_text() ë©”ì„œë“œ ì‚¬ìš©\n",
    "chunks = text_splitter.split_text(long_text)\n",
    "print(f\"ë¶„í• ëœ ì²­í¬ ìˆ˜: {len(chunks)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1efde16e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ì²« ë²ˆì§¸ ì²­í¬ì˜ í…ìŠ¤íŠ¸ ì¶œë ¥\n",
    "print(f'ì²« ë²ˆì§¸ ì²­í¬ì˜ í…ìŠ¤íŠ¸: {chunks[0]}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5febd9bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_text_splitters import CharacterTextSplitter\n",
    "\n",
    "# ë¬¸ì¥ êµ¬ë¶„ìë¥¼ ê°œí–‰ë¬¸ìë¡œ ì„¤ì •\n",
    "text_splitter = CharacterTextSplitter(\n",
    "    separator = \"\\n\",        # ì²­í¬ êµ¬ë¶„ì: ê°œí–‰ë¬¸ì\n",
    "    chunk_size=1000,         # ì²­í¬ í¬ê¸°\n",
    "    chunk_overlap=200,       # ì¤‘ë³µ í¬ê¸°\n",
    "    length_function=len,     # ê¸¸ì´ ì¸¡ì • í•¨ìˆ˜\n",
    "    is_separator_regex=False # ì •ê·œì‹ ì—¬ë¶€\n",
    ")\n",
    "\n",
    "# split_documents() ë©”ì„œë“œ ì‚¬ìš© : Document ê°ì²´ë¥¼ ì—¬ëŸ¬ ê°œì˜ ì‘ì€ ì²­í¬ ë¬¸ì„œë¡œ ë¶„í• \n",
    "chunks = text_splitter.split_documents([pdf_docs[0]])   # ì²« ë²ˆì§¸ ë¬¸ì„œë§Œ ë¶„í• \n",
    "\n",
    "# ë¶„í• ëœ ì²­í¬ ê°œìˆ˜ ì¶œë ¥\n",
    "print(f'ë¶„í• ëœ ì²­í¬ ê°œìˆ˜: {len(chunks)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ebea41c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ê° ì²­í¬ì˜ í…ìŠ¤íŠ¸ ê¸¸ì´ ì¶œë ¥\n",
    "for i, chunk in enumerate(chunks):\n",
    "    print(f'ì²­í¬ {i+1}ì˜ í…ìŠ¤íŠ¸ ê¸¸ì´: {len(chunk.page_content)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "afcd2cef",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ì²« ë²ˆì§¸ ì²­í¬ì˜ í…ìŠ¤íŠ¸ ì¶œë ¥\n",
    "print(f'ì²« ë²ˆì§¸ ì²­í¬ì˜ í…ìŠ¤íŠ¸: {chunks[0].page_content}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba7466eb",
   "metadata": {},
   "source": [
    "### 2. **RecursiveCharacterTextSplitter**\n",
    "\n",
    "- ì¬ê·€ì ìœ¼ë¡œ í…ìŠ¤íŠ¸ë¥¼ ë¶„í• \n",
    "- êµ¬ë¶„ìë¥¼ ìˆœì°¨ì ìœ¼ë¡œ ì ìš©í•˜ì—¬ í° ì²­í¬ì—ì„œ ì‹œì‘í•˜ì—¬ ì ì§„ì ìœ¼ë¡œ ë” ì‘ì€ ë‹¨ìœ„ë¡œ ë¶„í• \n",
    "- ë¬¸ë§¥ì„ ë” ì˜ ë³´ì¡´í•  ìˆ˜ ìˆìŒ  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f67f7c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_text_splitters import RecursiveCharacterTextSplitter\n",
    "\n",
    "# ê¸°ë³¸ ì¬ê·€ ë¶„í• ê¸°\n",
    "text_splitter = RecursiveCharacterTextSplitter(\n",
    "    chunk_size=1000,\n",
    "    chunk_overlap=200,\n",
    "    length_function=len,\n",
    "    separators=[\"\\n\\n\", \"\\n\", \" \", \"\"]  # ìš°ì„ ìˆœìœ„ ìˆœì„œ\n",
    ")\n",
    "\n",
    "# Document ê°ì²´ ë¶„í• \n",
    "chunks = text_splitter.split_documents(pdf_docs)\n",
    "print(f\"ìƒì„±ëœ ì²­í¬ ìˆ˜: {len(chunks)}\")\n",
    "\n",
    "# ê° ì²­í¬ì˜ ê¸¸ì´ í™•ì¸\n",
    "for i, chunk in enumerate(chunks[:10]):\n",
    "    print(f\"ì²­í¬ {i+1}: {len(chunk.page_content)} ë¬¸ì\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef0ecd1d",
   "metadata": {},
   "source": [
    "### 3. **ì •ê·œí‘œí˜„ì‹ ì‚¬ìš©**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9134516a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_text_splitters import CharacterTextSplitter\n",
    "\n",
    "# ë¬¸ì¥ì„ êµ¬ë¶„í•˜ì—¬ ë¶„í•  - ì •ê·œí‘œí˜„ì‹ ì‚¬ìš© (ë¬¸ì¥ êµ¬ë¶„ì: ë§ˆì¹¨í‘œ, ëŠë‚Œí‘œ, ë¬¼ìŒí‘œ ë‹¤ìŒì— ê³µë°±ì´ ì˜¤ëŠ” ê²½ìš°)\n",
    "text_splitter = CharacterTextSplitter(\n",
    "    separator=r'(?<=[.!?])\\s+',  # ê° Document ê°ì²´ì˜ page_content ì†ì„±ì„ ë¬¸ì¥ìœ¼ë¡œ ë¶„í• \n",
    "    chunk_size=1000,\n",
    "    chunk_overlap=200,\n",
    "    is_separator_regex=True,      # êµ¬ë¶„ìê°€ ì •ê·œì‹ì¸ì§€ ì—¬ë¶€: True\n",
    "    keep_separator=True,          # êµ¬ë¶„ì ìœ ì§€ ì—¬ë¶€: True\n",
    ")\n",
    "\n",
    "# split_documents() ë©”ì„œë“œ ì‚¬ìš© : Document ê°ì²´ë¥¼ ì—¬ëŸ¬ ê°œì˜ ì‘ì€ ì²­í¬ ë¬¸ì„œë¡œ ë¶„í• \n",
    "chunks = text_splitter.split_documents(pdf_docs)  # ëª¨ë“  ë¬¸ì„œë¥¼ ë¶„í• \n",
    "print(f\"ìƒì„±ëœ í…ìŠ¤íŠ¸ ì²­í¬ ìˆ˜: {len(chunks)}\")\n",
    "print(f\"ê° ì²­í¬ì˜ ê¸¸ì´: {list(len(chunk.page_content) for chunk in chunks)}\")\n",
    "print()\n",
    "\n",
    "# ê° ì²­í¬ì˜ ì‹œì‘ ë¶€ë¶„ê³¼ ë ë¶€ë¶„ í™•ì¸ - 5ê°œ ì²­í¬ë§Œ ì¶œë ¥\n",
    "for chunk in chunks[:5]:\n",
    "    print(chunk.page_content[:200])\n",
    "    print(\"...\")\n",
    "    print(chunk.page_content[-200:])\n",
    "    print(\"=\" * 100)\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96f40a48",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ë²•ë¥  ë¬¸ì„œì™€ ê³µë¬¸ì„œì— ì í•©í•œ ë¬¸ì¥ ë¶„í• ê¸° ìƒì„±\n",
    "# ë¬¸ì¥ ë í›„ ê³µë°± ë¬¸ìê°€ ìˆëŠ” íŒ¨í„´ì„ ì°¾ì•„ì„œ ë¶„í• \n",
    "regex_pattern = r'(?<=[.!?])\\s+'\n",
    "\n",
    "sentence_splitter = CharacterTextSplitter(\n",
    "    separator=regex_pattern,\n",
    "    chunk_size=1000,\n",
    "    chunk_overlap=200,\n",
    "    is_separator_regex=True,\n",
    "    keep_separator=True\n",
    ")\n",
    "\n",
    "# split_documents() ë©”ì„œë“œ ì‚¬ìš© : Document ê°ì²´ë¥¼ ì—¬ëŸ¬ ê°œì˜ ì‘ì€ ì²­í¬ ë¬¸ì„œë¡œ ë¶„í• \n",
    "chunks = sentence_splitter.split_documents(pdf_docs)  # ëª¨ë“  ë¬¸ì„œë¥¼ ë¶„í• \n",
    "print(f\"ìƒì„±ëœ í…ìŠ¤íŠ¸ ì²­í¬ ìˆ˜: {len(chunks)}\")\n",
    "print(f\"ê° ì²­í¬ì˜ ê¸¸ì´: {list(len(chunk.page_content) for chunk in chunks)}\")\n",
    "print()\n",
    "\n",
    "# ê° ì²­í¬ì˜ ì‹œì‘ ë¶€ë¶„ê³¼ ë ë¶€ë¶„ í™•ì¸ - 5ê°œ ì²­í¬ë§Œ ì¶œë ¥\n",
    "for chunk in chunks[:5]:\n",
    "    print(chunk.page_content[:200])\n",
    "    print(\"...\")\n",
    "    print(chunk.page_content[-200:])\n",
    "    print(\"=\" * 100)\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "523d6626",
   "metadata": {},
   "source": [
    "### 4. **í† í° ìˆ˜ë¥¼ ê¸°ë°˜ìœ¼ë¡œ ë¶„í• **"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4d13c47",
   "metadata": {},
   "source": [
    "`(1) tiktoken`  \n",
    "\n",
    "- OpenAIì—ì„œ ë§Œë“  BPE Tokenizer\n",
    "\n",
    "- ì–¸ì–´ ëª¨ë¸ í† í¬ë‚˜ì´ì € ë¹„êµ\n",
    "\n",
    "    | ëª¨ë¸ | í† í¬ë‚˜ì´ì € | ì–´íœ˜ í¬ê¸° | íŠ¹ì§• |\n",
    "    |------|-----------|----------|------|\n",
    "    | GPT-4.1 | o200k_base | 200,000 | ìµœì‹  ëª¨ë¸, ë‹¤êµ­ì–´ íš¨ìœ¨ì„± ê°œì„  |\n",
    "    | GPT-4o | o200k_base | 200,000 | ë©€í‹°ëª¨ë‹¬ ì§€ì› |\n",
    "    | o1, o3, o4 ì‹œë¦¬ì¦ˆ | o200k_base | 200,000 | ìµœì‹  ì¶”ë¡  ëª¨ë¸ |\n",
    "    | GPT-4 | cl100k_base | 100,000 | ì´ì „ ì„¸ëŒ€ í”Œë˜ê·¸ì‹­ ëª¨ë¸ |\n",
    "    | GPT-3.5-Turbo | cl100k_base | 100,000 | íš¨ìœ¨ì ì¸ ëŒ€í™” ëª¨ë¸ |\n",
    "    | Codex | p50k_base | 50,000 | ì½”ë”© ì „ìš© ëª¨ë¸ |\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0cc7e0aa",
   "metadata": {},
   "source": [
    "- ì„ë² ë”© ëª¨ë¸ í† í¬ë‚˜ì´ì € ë¹„êµ\n",
    "\n",
    "    | ëª¨ë¸ëª… | í† í¬ë‚˜ì´ì € | ì–´íœ˜ í¬ê¸° | ì„ë² ë”© ì°¨ì› | íŠ¹ì§• |\n",
    "    |------|-----------|----------|------|------|\n",
    "    | text-embedding-3-large | cl100k_base | 100,000 | 3,072 | ìµœê³  ì„±ëŠ¥|\n",
    "    | text-embedding-3-small | cl100k_base | 100,000 | 1,536 | ê³ íš¨ìœ¨ |\n",
    "    | text-embedding-ada-002 | cl100k_base | 100,000 | 1,536 | ë ˆê±°ì‹œ ëª¨ë¸|\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d0f74a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ì²«ë²ˆì§¸ ë¬¸ì„œ ê°ì²´ì˜ í…ìŠ¤íŠ¸ ê¸¸ì´\n",
    "len(pdf_docs[0].page_content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09c015f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_text_splitters import RecursiveCharacterTextSplitter\n",
    "\n",
    "# TikToken ì¸ì½”ë”ë¥¼ ì‚¬ìš©í•˜ì—¬ ì¬ê·€ì  í…ìŠ¤íŠ¸ ë¶„í• ê¸° ì´ˆê¸°í™”\n",
    "text_splitter = RecursiveCharacterTextSplitter.from_tiktoken_encoder(\n",
    "    encoding_name=\"cl100k_base\", \n",
    "    chunk_size=300, \n",
    "    chunk_overlap=0,\n",
    ")\n",
    "\n",
    "# split_documents() ë©”ì„œë“œ ì‚¬ìš© : Document ê°ì²´ë¥¼ ì—¬ëŸ¬ ê°œì˜ ì‘ì€ ì²­í¬ ë¬¸ì„œë¡œ ë¶„í• \n",
    "chunks = text_splitter.split_documents([pdf_docs[0]])  # ì²« ë²ˆì§¸ ë¬¸ì„œë§Œ ë¶„í• \n",
    "\n",
    "print(f\"ìƒì„±ëœ ì²­í¬ ìˆ˜: {len(chunks)}\")\n",
    "print(f\"ê° ì²­í¬ì˜ ê¸¸ì´: {list(len(chunk.page_content) for chunk in chunks)}\")\n",
    "\n",
    "# ê° ì²­í¬ì˜ ì‹œì‘ ë¶€ë¶„ê³¼ ë ë¶€ë¶„ í™•ì¸\n",
    "for chunk in chunks[:5]:\n",
    "    print(chunk.page_content[:50])\n",
    "    print(\"-\" * 50)\n",
    "    print(chunk.page_content[-50:])\n",
    "    print(\"=\" * 50)\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b27d4ef9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tiktoken\n",
    "\n",
    "# TikToken ì¸ì½”ë” ì´ˆê¸°í™”\n",
    "tiktoken_tokenizer = tiktoken.get_encoding(\"cl100k_base\")\n",
    "\n",
    "# ê° ì²­í¬ì— ëŒ€í•´ í† í°í™” ë° ë‹¨ì–´ ìˆ˜ í™•ì¸\n",
    "for chunk in chunks[:5]:\n",
    "\n",
    "    # ê° ì²­í¬ë¥¼ í† í°í™”\n",
    "    tokens = tiktoken_tokenizer.encode(chunk.page_content)\n",
    "    # ê° ì²­í¬ì˜ ë‹¨ì–´ ìˆ˜ í™•ì¸\n",
    "    print(len(tokens))\n",
    "    # ê° ì²­í¬ì˜ í† í°í™” ê²°ê³¼ í™•ì¸ (ì²« 10ê°œ í† í°ë§Œ ì¶œë ¥)\n",
    "    print(tokens[:10])\n",
    "    # í† í° IDë¥¼ ì‹¤ì œ í† í°(ë¬¸ìì—´)ë¡œ ë³€í™˜í•´ì„œ ì¶œë ¥\n",
    "    token_strings = [tiktoken_tokenizer.decode([token]) for token in tokens[:10]]\n",
    "    print(token_strings)\n",
    "\n",
    "    print(\"=\" * 50)\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e436a5d",
   "metadata": {},
   "source": [
    "`(2) Hugging Face í† í¬ë‚˜ì´ì €`  \n",
    "- Hugging Face tokenizer ëª¨ë¸ì˜ í† í° ìˆ˜ë¥¼ ê¸°ì¤€ìœ¼ë¡œ ë¶„í• \n",
    "- uv add langchain_huggingface sentence_transformers\n",
    "\n",
    "- ì˜¤í”ˆì†ŒìŠ¤ ì–¸ì–´ ëª¨ë¸ í† í¬ë‚˜ì´ì € \n",
    "\n",
    "    | ëª¨ë¸ íŒ¨ë°€ë¦¬ | ëª¨ë¸ëª… | í† í¬ë‚˜ì´ì € | ì–´íœ˜ í¬ê¸° | ì•Œê³ ë¦¬ì¦˜ | íŠ¹ì§• |\n",
    "    |------------|--------|-----------|----------|----------------|------|\n",
    "    | **Meta LLaMA** | LLaMA 1, LLaMA 2 | SentencePiece | 32,000 | BPE | SentencePiece BPE with byte-fallback |\n",
    "    | | LLaMA 3 | tiktoken-style | 128,000 | Byte-level BPE | Non-SentencePiece, ì§ì ‘ ë°”ì´íŠ¸ ë ˆë²¨ BPE |\n",
    "    | **XLM-RoBERTa** | XLM-RoBERTa-base | SentencePiece | 250,000 | BPE/Unigram | 100+ ì–¸ì–´ ì§€ì›, ëŒ€ìš©ëŸ‰ ì–´íœ˜ |\n",
    "    | | XLM-RoBERTa-large | SentencePiece | 250,000 | BPE/Unigram | ë‹¤êµ­ì–´ ìµœì í™” |\n",
    "    | **BERT** | BERT-base/large (uncased) | WordPiece | 30,522 | WordPiece | ì†Œë¬¸ì ë³€í™˜ |\n",
    "    | | BERT-base/large (cased) | WordPiece | 28,996 | WordPiece | ëŒ€ì†Œë¬¸ì ìœ ì§€ |\n",
    "    | | BERT-multilingual | WordPiece | 119,547 | WordPiece | 104ê°œ ì–¸ì–´ ì§€ì› |"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0c47c8a",
   "metadata": {},
   "source": [
    "- ì˜¤í”ˆì†ŒìŠ¤ ì„ë² ë”© ëª¨ë¸ í† í¬ë‚˜ì´ì € \n",
    "\n",
    "    | ëª¨ë¸ëª… | í† í¬ë‚˜ì´ì € | ì–´íœ˜ í¬ê¸° | ìµœëŒ€ ì…ë ¥ ê¸¸ì´ | ë² ì´ìŠ¤ ëª¨ë¸ | íŠ¹ì§• |\n",
    "    |--------|-----------|----------|--------------|------------|------|\n",
    "    | BGE-M3 | SentencePiece | 250,000 | 8,192 tokens | XLM-RoBERTa-large | Multi-Functionality (dense/sparse/multi-vector), Multi-Linguality (100+ ì–¸ì–´), Multi-Granularity |\n",
    "    | BGE-large/base/small | BERT WordPiece | 30,522 | 512 tokens | BERT | ì˜ì–´/ì¤‘êµ­ì–´ ìµœì í™” |\n",
    "    | BGE-reranker-v2-m3 | SentencePiece | 250,000 | 512 tokens | XLM-RoBERTa | ê²½ëŸ‰ í¬ë¡œìŠ¤-ì¸ì½”ë” ì¬ìˆœìœ„í™” |"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d51cdaf",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer \n",
    "\n",
    "# Huggingface Tokenizer ì´ˆê¸°í™”\n",
    "bge_tokenizer = AutoTokenizer.from_pretrained(\"BAAI/bge-m3\")\n",
    "\n",
    "bge_tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5abee28",
   "metadata": {},
   "outputs": [],
   "source": [
    "# í† í¬ë‚˜ì´ì € ì¸ì½”ë”© - ë¬¸ì¥ì„ í† í°(ID)ìœ¼ë¡œ ë³€í™˜\n",
    "tokens = bge_tokenizer.encode(\"ì•ˆë…•í•˜ì„¸ìš”. ë°˜ê°‘ìŠµë‹ˆë‹¤.\")\n",
    "print(tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6a76e60",
   "metadata": {},
   "outputs": [],
   "source": [
    "# í† í°ì„ ì¶œë ¥ (í† í° IDë¥¼ ì‹¤ì œ í† í°(ë¬¸ìì—´)ë¡œ ë³€í™˜)\n",
    "print(bge_tokenizer.convert_ids_to_tokens(tokens)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6cfbaec9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ë””ì½”ë”© - í† í°ì„ ë¬¸ìì—´ë¡œ ë³€í™˜\n",
    "print(bge_tokenizer.decode(tokens, skip_special_tokens=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c468edc",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_text_splitters import RecursiveCharacterTextSplitter\n",
    "\n",
    "# Huggingface í† í¬ë‚˜ì´ì €ë¥¼ ì‚¬ìš©í•˜ì—¬ ì¬ê·€ì  í…ìŠ¤íŠ¸ ë¶„í• ê¸° ì´ˆê¸°í™”\n",
    "text_splitter = RecursiveCharacterTextSplitter.from_huggingface_tokenizer(\n",
    "    tokenizer=bge_tokenizer,\n",
    "    chunk_size=300, \n",
    "    chunk_overlap=0,\n",
    ")\n",
    "\n",
    "# split_documents() ë©”ì„œë“œ ì‚¬ìš© : Document ê°ì²´ë¥¼ ì—¬ëŸ¬ ê°œì˜ ì‘ì€ ì²­í¬ ë¬¸ì„œë¡œ ë¶„í• \n",
    "chunks = text_splitter.split_documents([pdf_docs[0]]) # ì²« ë²ˆì§¸ ë¬¸ì„œë§Œ ë¶„í• \n",
    "\n",
    "print(f\"ìƒì„±ëœ ì²­í¬ ìˆ˜: {len(chunks)}\")\n",
    "print(f\"ê° ì²­í¬ì˜ ê¸¸ì´: {list(len(chunk.page_content) for chunk in chunks)}\")\n",
    "print()\n",
    "\n",
    "for chunk in chunks[:5]:\n",
    "\n",
    "    # ê° ì²­í¬ë¥¼ í† í°í™”\n",
    "    tokens = bge_tokenizer.encode(chunk.page_content)\n",
    "    # ê° ì²­í¬ì˜ ë‹¨ì–´ ìˆ˜ í™•ì¸\n",
    "    print(len(tokens))\n",
    "    # ê° ì²­í¬ì˜ í† í°í™” ê²°ê³¼ í™•ì¸ (ì²« 10ê°œ í† í°ë§Œ ì¶œë ¥)\n",
    "    print(tokens[:10])\n",
    "    # í† í° IDë¥¼ ì‹¤ì œ í† í°(ë¬¸ìì—´)ë¡œ ë³€í™˜í•´ì„œ ì¶œë ¥\n",
    "    token_strings = bge_tokenizer.convert_ids_to_tokens(tokens[:10]) \n",
    "    print(token_strings)\n",
    "\n",
    "    print(\"=\" * 50)\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c3670cd",
   "metadata": {},
   "source": [
    "#### ğŸ“ ì—°ìŠµ ë¬¸ì œ 2: ìµœì  ì²­í¬ í¬ê¸° ì°¾ê¸°"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d85de1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "ğŸ“Œ ì‹¤ìŠµ: ë‹¤ì–‘í•œ ì²­í¬ í¬ê¸°ë¡œ ë¶„í• í•˜ê³  ë¹„êµí•˜ì„¸ìš” (data/personal_info_law.pdf)\n",
    "- ì²­í¬ í¬ê¸°: 500, 1000, 1500\n",
    "- ì˜¤ë²„ë©: ì²­í¬ í¬ê¸°ì˜ 20%\n",
    "- ê° ì„¤ì •ì—ì„œ ìƒì„±ëœ ì²­í¬ ìˆ˜ì™€ í‰ê·  ê¸¸ì´ ê³„ì‚°\n",
    "\"\"\"\n",
    "\n",
    "# ì—¬ê¸°ì— ì½”ë“œë¥¼ ì‘ì„±í•˜ì„¸ìš”"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "917c3678",
   "metadata": {},
   "source": [
    "<details>\n",
    "<summary>ğŸ’¡ ì •ë‹µ ë³´ê¸°</summary>\n",
    "\n",
    "```python\n",
    "from langchain_text_splitters import RecursiveCharacterTextSplitter\n",
    "\n",
    "# PDF ë¬¸ì„œ ë¡œë“œ (ì´ì „ ì½”ë“œ í™œìš©)\n",
    "pdf_loader = PyPDFLoader('data/personal_info_law.pdf', mode='single')\n",
    "docs = pdf_loader.load()\n",
    "\n",
    "# ë‹¤ì–‘í•œ ì²­í¬ í¬ê¸° í…ŒìŠ¤íŠ¸\n",
    "chunk_sizes = [500, 1000, 1500]\n",
    "results = []\n",
    "\n",
    "for size in chunk_sizes:\n",
    "    overlap = int(size * 0.2)  # 20% ì˜¤ë²„ë©\n",
    "    \n",
    "    splitter = RecursiveCharacterTextSplitter(\n",
    "        chunk_size=size,\n",
    "        chunk_overlap=overlap,\n",
    "        length_function=len,\n",
    "        separators=[\"\\n\\n\", \"\\n\", \".\", \" \", \"\"]\n",
    "    )\n",
    "    \n",
    "    chunks = splitter.split_documents(docs)\n",
    "    avg_length = sum(len(chunk.page_content) for chunk in chunks) / len(chunks)\n",
    "    \n",
    "    results.append({\n",
    "        'chunk_size': size,\n",
    "        'overlap': overlap,\n",
    "        'num_chunks': len(chunks),\n",
    "        'avg_length': avg_length\n",
    "    })\n",
    "    \n",
    "    print(f\"ì²­í¬ í¬ê¸° {size}:\")\n",
    "    print(f\"  - ì²­í¬ ìˆ˜: {len(chunks)}\")\n",
    "    print(f\"  - í‰ê·  ê¸¸ì´: {avg_length:.2f}\")\n",
    "    print(f\"  - ì˜¤ë²„ë©: {overlap}\")\n",
    "    print(\"-\" * 50)\n",
    "```\n",
    "</details>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09040fde",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## ë¬¸ì„œ ì„ë² ë”© (Document Embedding)\n",
    "\n",
    "- ğŸ¯ ì„ë² ë”©ì´ë€?\n",
    "    - í…ìŠ¤íŠ¸ë¥¼ ë²¡í„°(ìˆ«ì ë°°ì—´)ë¡œ ë³€í™˜í•˜ëŠ” ê³¼ì •\n",
    "    - ë¬¸ì„œì˜ ì˜ë¯¸ì  íŠ¹ì„±ì„ ìˆ˜ì¹˜í™”í•˜ì—¬ ì»´í“¨í„°ê°€ ì´í•´í•˜ê³  ì²˜ë¦¬í•  ìˆ˜ ìˆëŠ” í˜•íƒœë¡œ ë³€í™˜ \n",
    "\n",
    "- ëª©ì :\n",
    "    - í…ìŠ¤íŠ¸ ê°„ ìœ ì‚¬ë„ ê³„ì‚° ê°€ëŠ¥\n",
    "    - ë²¡í„° ë°ì´í„°ë² ì´ìŠ¤ ì €ì¥ ë° ê²€ìƒ‰\n",
    "    - ì˜ë¯¸ ê¸°ë°˜ ë¬¸ì„œ ê²€ìƒ‰ êµ¬í˜„\n",
    "\n",
    "- ğŸ“Š ì„ë² ë”© ëª¨ë¸ ë¹„êµ\n",
    "\n",
    "    | ëª¨ë¸ | ì°¨ì› | ì–¸ì–´ ì§€ì› | ë¹„ìš© | ì„±ëŠ¥ | ì‚¬ìš© ì‚¬ë¡€ |\n",
    "    |------|------|----------|------|------|----------|\n",
    "    | OpenAI text-embedding-3-small | 1536 | ë‹¤êµ­ì–´ | ìœ ë£Œ | ë†’ìŒ | í”„ë¡œë•ì…˜ |\n",
    "    | OpenAI text-embedding-3-large | 3072 | ë‹¤êµ­ì–´ | ìœ ë£Œ | ìµœê³  | ê³ ì„±ëŠ¥ ìš”êµ¬ |\n",
    "    | BAAI/bge-m3 | 1024 | ë‹¤êµ­ì–´ | ë¬´ë£Œ | ë†’ìŒ | í•œêµ­ì–´ íŠ¹í™” |\n",
    "    | sentence-transformers/all-MiniLM-L6-v2 | 384 | ì˜ì–´ | ë¬´ë£Œ | ì¤‘ê°„ | ë¡œì»¬ ê°œë°œ |"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54eb2653",
   "metadata": {},
   "source": [
    "### 1. OpenAI ì„ë² ë”©"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c991be2",
   "metadata": {},
   "source": [
    "`(1) ê¸°ë³¸ ì„¤ì •`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8a00802",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_openai import OpenAIEmbeddings\n",
    "\n",
    "# ê¸°ë³¸ ì„ë² ë”© ëª¨ë¸\n",
    "embeddings_openai = OpenAIEmbeddings(model=\"text-embedding-3-small\")\n",
    "\n",
    "print(f\"ì»¨í…ìŠ¤íŠ¸ ê¸¸ì´: {embeddings_openai.embedding_ctx_length}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a5b621b",
   "metadata": {},
   "source": [
    "`(2) ë¬¸ì„œ ì„ë² ë”©`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1839ccf5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ë¬¸ì„œ ì»¬ë ‰ì…˜ ì„ë² ë”©\n",
    "documents = [\n",
    "    \"ì¸ê³µì§€ëŠ¥ì€ ì»´í“¨í„° ê³¼í•™ì˜ í•œ ë¶„ì•¼ì…ë‹ˆë‹¤.\",\n",
    "    \"ë¨¸ì‹ ëŸ¬ë‹ì€ ì¸ê³µì§€ëŠ¥ì˜ í•˜ìœ„ ë¶„ì•¼ì…ë‹ˆë‹¤.\",\n",
    "    \"ë”¥ëŸ¬ë‹ì€ ë¨¸ì‹ ëŸ¬ë‹ì˜ í•œ ì¢…ë¥˜ì…ë‹ˆë‹¤.\",\n",
    "    \"ìì—°ì–´ ì²˜ë¦¬ëŠ” ì»´í“¨í„°ê°€ ì¸ê°„ì˜ ì–¸ì–´ë¥¼ ì´í•´í•˜ëŠ” ê¸°ìˆ ì…ë‹ˆë‹¤.\",\n",
    "    \"ì»´í“¨í„° ë¹„ì „ì€ ì´ë¯¸ì§€ë¥¼ ë¶„ì„í•˜ëŠ” ê¸°ìˆ ì…ë‹ˆë‹¤.\"\n",
    "]\n",
    "\n",
    "# ë°°ì¹˜ ì„ë² ë”© (íš¨ìœ¨ì )\n",
    "openai_small_embeddings = embeddings_openai.embed_documents(documents)\n",
    "print(f\"ì„ë² ë”© ë²¡í„° ìˆ˜: {len(openai_small_embeddings)}\")\n",
    "print(f\"ê° ë²¡í„° ì°¨ì›: {len(openai_small_embeddings[0])}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be254b32",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ì¿¼ë¦¬ ì„ë² ë”©\n",
    "query = \"AI ê¸°ìˆ ì— ëŒ€í•´ ì•Œë ¤ì£¼ì„¸ìš”\"\n",
    "query_embedding = embeddings_openai.embed_query(query)\n",
    "print(f\"ì¿¼ë¦¬ ì„ë² ë”© ì°¨ì›: {len(query_embedding)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da945a55",
   "metadata": {},
   "source": [
    "### 2. Hugging Face ì„ë² ë”©\n",
    "\n",
    "`(1) BGE-M3 ëª¨ë¸ (í•œêµ­ì–´ ìš°ìˆ˜)`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f6f520e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_huggingface import HuggingFaceEmbeddings\n",
    "\n",
    "# BGE-M3 ëª¨ë¸ (ë‹¤êµ­ì–´, í•œêµ­ì–´ ì„±ëŠ¥ ìš°ìˆ˜)\n",
    "embeddings_bge = HuggingFaceEmbeddings(\n",
    "    model_name=\"BAAI/bge-m3\",\n",
    "    model_kwargs={'device': 'cpu'},        # 'cuda' for GPU\n",
    "    encode_kwargs={'normalize_embeddings': True}  # L2 ì •ê·œí™”\n",
    ")\n",
    "\n",
    "# BGE-M3 ëª¨ë¸ë¡œ ë¬¸ì„œ ì„ë² ë”©\n",
    "bge_hf_embeddings = embeddings_bge.embed_documents(documents)\n",
    "print(f\"í•œêµ­ì–´ ì„ë² ë”© ì°¨ì›: {len(bge_hf_embeddings[0])}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e145c67",
   "metadata": {},
   "source": [
    "`(2) ê²½ëŸ‰ ëª¨ë¸`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c99db52d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ë¹ ë¥¸ ì²˜ë¦¬ë¥¼ ìœ„í•œ ê²½ëŸ‰ ëª¨ë¸\n",
    "embedding_gte = HuggingFaceEmbeddings(\n",
    "    model_name=\"Alibaba-NLP/gte-multilingual-base\",\n",
    "    model_kwargs={'device': 'cpu', 'trust_remote_code': True},  \n",
    "    encode_kwargs={'normalize_embeddings': True}\n",
    ")\n",
    "    \n",
    "# ê²½ëŸ‰ ëª¨ë¸ë¡œ ë¬¸ì„œ ì„ë² ë”©\n",
    "alibaba_hf_embeddings = embedding_gte.embed_documents(documents)\n",
    "print(f\"ê²½ëŸ‰ ëª¨ë¸ í•œêµ­ì–´ ì„ë² ë”© ì°¨ì›: {len(alibaba_hf_embeddings[0])}\") "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50389f43",
   "metadata": {},
   "source": [
    "### 3. Ollama ì„ë² ë”© (ë¡œì»¬)\n",
    "\n",
    "- ì„¤ì¹˜: uv add langchain_ollama"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4c471ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_ollama import OllamaEmbeddings\n",
    "\n",
    "# Ollama ì„œë²„ê°€ ì‹¤í–‰ ì¤‘ì´ì–´ì•¼ í•¨\n",
    "embeddings_ollama = OllamaEmbeddings(\n",
    "    model=\"bge-m3\",                    # ì‚¬ìš©í•  ëª¨ë¸\n",
    "    # base_url=\"http://localhost:11434\"  # Ollama ì„œë²„ ì£¼ì†Œ\n",
    ")\n",
    "\n",
    "# ë¡œì»¬ ì„ë² ë”©\n",
    "local_embeddings = embeddings_ollama.embed_documents(documents)\n",
    "\n",
    "print(f\"ë¡œì»¬ ì„ë² ë”© ë²¡í„° ìˆ˜: {len(local_embeddings)}\")\n",
    "print(f\"ê° ë²¡í„° ì°¨ì›: {len(local_embeddings[0])}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53e0e4ee",
   "metadata": {},
   "source": [
    "### 4. ìœ ì‚¬ë„ ê³„ì‚° ë° ê²€ìƒ‰\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0cfc73a6",
   "metadata": {},
   "source": [
    "`(1) ì½”ì‚¬ì¸ ìœ ì‚¬ë„`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92a41a53",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_community.utils.math import cosine_similarity\n",
    "import numpy as np\n",
    "\n",
    "def find_most_similar(query, doc_embeddings, documents, embeddings_model):\n",
    "    \"\"\"ê°€ì¥ ìœ ì‚¬í•œ ë¬¸ì„œ ì°¾ê¸°\"\"\"\n",
    "    # ì¿¼ë¦¬ ì„ë² ë”©\n",
    "    query_embedding = embeddings_model.embed_query(query)\n",
    "    \n",
    "    # ì½”ì‚¬ì¸ ìœ ì‚¬ë„ ê³„ì‚°\n",
    "    similarities = cosine_similarity([query_embedding], doc_embeddings)[0]\n",
    "    \n",
    "    # ê°€ì¥ ìœ ì‚¬í•œ ë¬¸ì„œ ì¸ë±ìŠ¤\n",
    "    most_similar_idx = np.argmax(similarities)\n",
    "    \n",
    "    return {\n",
    "        \"document\": documents[most_similar_idx],\n",
    "        \"similarity\": similarities[most_similar_idx],\n",
    "        \"index\": most_similar_idx\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc8eac6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ì¿¼ë¦¬ì™€ ë¬¸ì„œ ì„ë² ë”©ì„ ì‚¬ìš©í•˜ì—¬ ê°€ì¥ ìœ ì‚¬í•œ ë¬¸ì„œ ì°¾ê¸°\n",
    "queries = [\n",
    "    \"ì¸ê³µì§€ëŠ¥ì´ë€ ë¬´ì—‡ì¸ê°€ìš”?\",\n",
    "    \"ë”¥ëŸ¬ë‹ê³¼ ë¨¸ì‹ ëŸ¬ë‹ì˜ ê´€ê³„ëŠ” ì–´ë–»ê²Œ ë˜ë‚˜ìš”?\",\n",
    "    \"ì»´í“¨í„°ê°€ ì´ë¯¸ì§€ë¥¼ ì´í•´í•˜ëŠ” ë°©ë²•ì€?\"\n",
    "]\n",
    "\n",
    "# OpenAIEmbeddings ì‚¬ìš©í•œ ìœ ì‚¬ë„ ê²€ìƒ‰ (OpenAI)\n",
    "for query in queries:\n",
    "    result = find_most_similar(query, openai_small_embeddings, documents, embeddings_openai)\n",
    "\n",
    "    print(f\"ì¿¼ë¦¬: {query}\")\n",
    "    print(f\"ê°€ì¥ ìœ ì‚¬í•œ ë¬¸ì„œ: {result['document']}\")\n",
    "    print(f\"ìœ ì‚¬ë„ ì ìˆ˜: {result['similarity']:.4f}\")\n",
    "    print(\"-\" * 50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "739aa28c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# HuggingFaceEmbeddingsë¥¼ ì‚¬ìš©í•œ ìœ ì‚¬ë„ ê²€ìƒ‰ (BGE-M3)\n",
    "for query in queries:\n",
    "    result = find_most_similar(query, bge_hf_embeddings, documents, embeddings_bge)\n",
    "\n",
    "    print(f\"ì¿¼ë¦¬: {query}\")\n",
    "    print(f\"ê°€ì¥ ìœ ì‚¬í•œ ë¬¸ì„œ: {result['document']}\")\n",
    "    print(f\"ìœ ì‚¬ë„ ì ìˆ˜: {result['similarity']:.4f}\")\n",
    "    print(\"-\" * 50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc56d9ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Alibaba-NLP/gte-multilingual-base ëª¨ë¸ë¡œ ìœ ì‚¬ë„ ê²€ìƒ‰\n",
    "\n",
    "for query in queries:\n",
    "    result = find_most_similar(query, alibaba_hf_embeddings, documents, embedding_gte)\n",
    "\n",
    "    print(f\"ì¿¼ë¦¬: {query}\")\n",
    "    print(f\"ê°€ì¥ ìœ ì‚¬í•œ ë¬¸ì„œ: {result['document']}\")\n",
    "    print(f\"ìœ ì‚¬ë„ ì ìˆ˜: {result['similarity']:.4f}\")\n",
    "    print(\"-\" * 50)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74eb9445",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ollama ëª¨ë¸ë¡œ ìœ ì‚¬ë„ ê²€ìƒ‰ (bge-m3)\n",
    "\n",
    "for query in queries:\n",
    "    result = find_most_similar(query, local_embeddings, documents, embeddings_ollama)\n",
    "\n",
    "    print(f\"ì¿¼ë¦¬: {query}\")\n",
    "    print(f\"ê°€ì¥ ìœ ì‚¬í•œ ë¬¸ì„œ: {result['document']}\")\n",
    "    print(f\"ìœ ì‚¬ë„ ì ìˆ˜: {result['similarity']:.4f}\")\n",
    "    print(\"-\" * 50)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5655b646",
   "metadata": {},
   "source": [
    "#### ğŸ“ ì—°ìŠµ ë¬¸ì œ 3: ì„ë² ë”© ëª¨ë¸ ì„±ëŠ¥ ë¹„êµ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cdc9c805",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "ğŸ“Œ ì‹¤ìŠµ: ì„œë¡œ ë‹¤ë¥¸ ì„ë² ë”© ëª¨ë¸ì˜ ì„±ëŠ¥ ë¹„êµ \n",
    "- BGE-M3ì™€ GTE-multilingual ëª¨ë¸ ë¹„êµ\n",
    "- ë™ì¼í•œ ì¿¼ë¦¬ì— ëŒ€í•œ ê²€ìƒ‰ ê²°ê³¼ ë¹„êµ\n",
    "- ì²˜ë¦¬ ì‹œê°„ ì¸¡ì •\n",
    "\"\"\"\n",
    "\n",
    "# í…ŒìŠ¤íŠ¸ ë¬¸ì„œì™€ ì¿¼ë¦¬\n",
    "test_docs = [\n",
    "    \"ì˜ë£Œ ì¸ê³µì§€ëŠ¥ì€ ì§ˆë³‘ ì§„ë‹¨ì— í™œìš©ë©ë‹ˆë‹¤.\",\n",
    "    \"ë”¥ëŸ¬ë‹ì€ ì˜ë£Œ ì˜ìƒ ë¶„ì„ì— íš¨ê³¼ì ì…ë‹ˆë‹¤.\",\n",
    "    \"í™˜ì ë°ì´í„° ë³´ì•ˆì€ ë§¤ìš° ì¤‘ìš”í•©ë‹ˆë‹¤.\",\n",
    "    \"ì›ê²© ì§„ë£ŒëŠ” ì˜ë£Œ ì ‘ê·¼ì„±ì„ í–¥ìƒì‹œí‚µë‹ˆë‹¤.\",\n",
    "    \"ìƒëª…ì •ë³´í•™ì€ ìœ ì „ì²´ ë°ì´í„°ë¥¼ ë¶„ì„í•©ë‹ˆë‹¤.\"\n",
    "]\n",
    "\n",
    "test_query = \"AIë¥¼ í™œìš©í•œ ì§ˆë³‘ ì§„ë‹¨ ë°©ë²•\"\n",
    "\n",
    "# ì—¬ê¸°ì— ì½”ë“œë¥¼ ì‘ì„±í•˜ì„¸ìš”"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af439d18",
   "metadata": {},
   "source": [
    "<details>\n",
    "<summary>ğŸ’¡ ì •ë‹µ ë³´ê¸°</summary>\n",
    "\n",
    "```python\n",
    "from langchain_huggingface import HuggingFaceEmbeddings\n",
    "import time\n",
    "import numpy as np\n",
    "from langchain_community.utils.math import cosine_similarity\n",
    "\n",
    "# í…ŒìŠ¤íŠ¸ ë¬¸ì„œì™€ ì¿¼ë¦¬\n",
    "test_docs = [\n",
    "    \"ì˜ë£Œ ì¸ê³µì§€ëŠ¥ì€ ì§ˆë³‘ ì§„ë‹¨ì— í™œìš©ë©ë‹ˆë‹¤.\",\n",
    "    \"ë”¥ëŸ¬ë‹ì€ ì˜ë£Œ ì˜ìƒ ë¶„ì„ì— íš¨ê³¼ì ì…ë‹ˆë‹¤.\",\n",
    "    \"í™˜ì ë°ì´í„° ë³´ì•ˆì€ ë§¤ìš° ì¤‘ìš”í•©ë‹ˆë‹¤.\",\n",
    "    \"ì›ê²© ì§„ë£ŒëŠ” ì˜ë£Œ ì ‘ê·¼ì„±ì„ í–¥ìƒì‹œí‚µë‹ˆë‹¤.\",\n",
    "    \"ìƒëª…ì •ë³´í•™ì€ ìœ ì „ì²´ ë°ì´í„°ë¥¼ ë¶„ì„í•©ë‹ˆë‹¤.\"\n",
    "]\n",
    "\n",
    "test_query = \"AIë¥¼ í™œìš©í•œ ì§ˆë³‘ ì§„ë‹¨ ë°©ë²•\"\n",
    "\n",
    "# ë‘ ê°€ì§€ ì„ë² ë”© ëª¨ë¸ ì´ˆê¸°í™”\n",
    "embedding_models = {\n",
    "    \"BGE-M3\": HuggingFaceEmbeddings(\n",
    "        model_name=\"BAAI/bge-m3\",\n",
    "        model_kwargs={'device': 'cpu'},\n",
    "        encode_kwargs={'normalize_embeddings': True}\n",
    "    ),\n",
    "    \"GTE-multilingual\": HuggingFaceEmbeddings(\n",
    "        model_name=\"Alibaba-NLP/gte-multilingual-base\",\n",
    "        model_kwargs={'device': 'cpu', 'trust_remote_code': True},\n",
    "        encode_kwargs={'normalize_embeddings': True}\n",
    "    )\n",
    "}\n",
    "\n",
    "# ëª¨ë¸ë³„ ì„±ëŠ¥ ë¹„êµ\n",
    "for model_name, embedding_model in embedding_models.items():\n",
    "    print(f\"\\n=== {model_name} ëª¨ë¸ ===\")\n",
    "    \n",
    "    # ì„ë² ë”© ì‹œê°„ ì¸¡ì •\n",
    "    start_time = time.time()\n",
    "    doc_embeddings = embedding_model.embed_documents(test_docs)\n",
    "    query_embedding = embedding_model.embed_query(test_query)\n",
    "    embed_time = time.time() - start_time\n",
    "    \n",
    "    # ìœ ì‚¬ë„ ê³„ì‚°\n",
    "    similarities = cosine_similarity([query_embedding], doc_embeddings)[0]\n",
    "    \n",
    "    # ê²°ê³¼ ì •ë ¬\n",
    "    ranked_results = sorted(\n",
    "        zip(test_docs, similarities), \n",
    "        key=lambda x: x[1], \n",
    "        reverse=True\n",
    "    )\n",
    "    \n",
    "    print(f\"ì„ë² ë”© ì‹œê°„: {embed_time:.4f}ì´ˆ\")\n",
    "    print(f\"ì„ë² ë”© ì°¨ì›: {len(doc_embeddings[0])}\")\n",
    "    print(\"\\nê²€ìƒ‰ ê²°ê³¼ (ìƒìœ„ 3ê°œ):\")\n",
    "    for i, (doc, score) in enumerate(ranked_results[:3], 1):\n",
    "        print(f\"{i}. (ìœ ì‚¬ë„: {score:.4f}) {doc}\")\n",
    "```\n",
    "\n",
    "</details>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fba79aed",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## ë²¡í„° ì €ì¥ì†Œ (Vector Store)\n",
    "\n",
    "- ë²¡í„°í™”ëœ ë°ì´í„°ë¥¼ íš¨ìœ¨ì ìœ¼ë¡œ ì €ì¥í•˜ê³  ê²€ìƒ‰í•˜ê¸° ìœ„í•œ íŠ¹ìˆ˜ ë°ì´í„°ë² ì´ìŠ¤ ì‹œìŠ¤í…œ\n",
    "- í…ìŠ¤íŠ¸ë‚˜ ì´ë¯¸ì§€ ë“±ì˜ ë¹„ì •í˜• ë°ì´í„°ë¥¼ ê³ ì°¨ì› ë²¡í„° ê³µê°„ì— ë§¤í•‘í•˜ì—¬ ì €ì¥\n",
    "- ìœ ì‚¬ë„ ê¸°ë°˜ ê²€ìƒ‰ì„ í†µí•´ ì˜ë¯¸ì ìœ¼ë¡œ ê°€ê¹Œìš´ ë°ì´í„°ë¥¼ ë¹ ë¥´ê²Œ ê²€ìƒ‰ ê°€ëŠ¥ \n",
    "\n",
    "- ì£¼ìš” ê¸°ëŠ¥:\n",
    "    - ë²¡í„° ìƒ‰ì¸í™”: íš¨ìœ¨ì ì¸ ê²€ìƒ‰ì„ ìœ„í•œ ë°ì´í„° êµ¬ì¡°í™”ë¥¼ ìˆ˜í–‰\n",
    "    - ê·¼ì ‘ ì´ì›ƒ ê²€ìƒ‰: ì£¼ì–´ì§„ ì¿¼ë¦¬ì™€ ê°€ì¥ ìœ ì‚¬í•œ ë²¡í„°ë“¤ì„ ê²€ìƒ‰ \n",
    "    - ë©”íƒ€ë°ì´í„° ê´€ë¦¬: ë²¡í„°ì™€ ê´€ë ¨ëœ ë¶€ê°€ ì •ë³´ë¥¼ í•¨ê»˜ ì €ì¥í•˜ê³  ê²€ìƒ‰\n",
    "\n",
    "- ì‚¬ìš© ì‚¬ë¡€:\n",
    "    - ì‹œë§¨í‹± ë¬¸ì„œ ê²€ìƒ‰: ë¬¸ì„œì˜ ì˜ë¯¸ë¥¼ ì´í•´í•˜ì—¬ ê²€ìƒ‰\n",
    "    - ì¶”ì²œ ì‹œìŠ¤í…œ: ìœ ì‚¬í•œ ì•„ì´í…œì„ ì¶”ì²œ\n",
    "    - ì¤‘ë³µ ë°ì´í„° ê°ì§€: ìœ ì‚¬í•œ ì½˜í…ì¸ ë¥¼ ê²€ìƒ‰ \n",
    "    - ì§ˆì˜ì‘ë‹µ ì‹œìŠ¤í…œ: ê´€ë ¨ ë¬¸ì„œì—ì„œ ë‹µë³€ì„ ìƒì„±í•˜ëŠ”ë° í•„ìš”í•œ ê·¼ê±°ë¥¼ ê²€ìƒ‰ \n",
    "\n",
    "\n",
    "- ğŸ“Š ë²¡í„° ì €ì¥ì†Œ ë¹„êµ\n",
    "\n",
    "    | ì¢…ë¥˜ | ì¥ì  | ë‹¨ì  | ì‚¬ìš© ì‚¬ë¡€ |\n",
    "    |------|------|------|----------|\n",
    "    | Chroma | ì„¤ì¹˜ ê°„ë‹¨, ë¡œì»¬ ì¹œí™”ì  | ëŒ€ìš©ëŸ‰ ì²˜ë¦¬ í•œê³„ | ê°œë°œ, í”„ë¡œí† íƒ€ì… |\n",
    "    | FAISS | ë§¤ìš° ë¹ ë¦„, í™•ì¥ì„± ìš°ìˆ˜ | ì„¤ì • ë³µì¡ | ëŒ€ìš©ëŸ‰ ê²€ìƒ‰ |\n",
    "    | Pinecone | ì™„ì „ ê´€ë¦¬í˜•, ê³ ì„±ëŠ¥ | ìœ ë£Œ, í´ë¼ìš°ë“œ ì˜ì¡´ | í”„ë¡œë•ì…˜ |\n",
    "    | Weaviate | GraphQL ì§€ì›, í•˜ì´ë¸Œë¦¬ë“œ ê²€ìƒ‰ | í•™ìŠµ ê³¡ì„  | ë³µí•© ê²€ìƒ‰ |"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f8fed68",
   "metadata": {},
   "source": [
    "### 1. **Chroma**\n",
    "\n",
    "- ì‚¬ìš©ì í¸ì˜ì„±ì´ ìš°ìˆ˜í•œ ì˜¤í”ˆì†ŒìŠ¤ ë²¡í„° ì €ì¥ì†Œ\n",
    "- `langchain-chroma` íŒ¨í‚¤ì§€ ì„¤ì¹˜"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0f7da6e",
   "metadata": {},
   "source": [
    "`(1) ë²¡í„° ì €ì¥ì†Œ ì´ˆê¸°í™”`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ebb3bea0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_community.document_loaders import PyPDFLoader\n",
    "\n",
    "# PDF ë¡œë” ì´ˆê¸°í™” (ê·¼ë¡œê¸°ì¤€ë²• ë¬¸ì„œ)\n",
    "pdf_loader = PyPDFLoader('data/labor_law.pdf', mode='single')\n",
    "\n",
    "# ë™ê¸° ë¡œë”©\n",
    "pdf_docs = pdf_loader.load()\n",
    "print(f'PDF ë¬¸ì„œ ê°œìˆ˜: {len(pdf_docs)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fffc0d7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_text_splitters import RecursiveCharacterTextSplitter\n",
    "\n",
    "# ì¬ê·€ì  í…ìŠ¤íŠ¸ ë¶„í• ê¸° ì´ˆê¸°í™” (í† í° ìˆ˜ ê¸°ì¤€ ë¶„í• )\n",
    "text_splitter = RecursiveCharacterTextSplitter.from_huggingface_tokenizer(\n",
    "    tokenizer=bge_tokenizer,\n",
    "    chunk_size=500, \n",
    "    chunk_overlap=100,\n",
    "    separators=['\\n\\n', '\\n', r'(?<=[.!?])\\s+'],\n",
    ")\n",
    "\n",
    "# split_documents() ë©”ì„œë“œ ì‚¬ìš© : Document ê°ì²´ë¥¼ ì—¬ëŸ¬ ê°œì˜ ì‘ì€ ì²­í¬ ë¬¸ì„œë¡œ ë¶„í• \n",
    "chunks = text_splitter.split_documents(pdf_docs) \n",
    "\n",
    "print(f\"ìƒì„±ëœ ì²­í¬ ìˆ˜: {len(chunks)}\")\n",
    "print(f\"ê° ì²­í¬ì˜ ê¸¸ì´: {list(len(chunk.page_content) for chunk in chunks)}\")\n",
    "\n",
    "# ê° ì²­í¬ì˜ ì‹œì‘ ë¶€ë¶„ê³¼ ë ë¶€ë¶„ í™•ì¸\n",
    "for chunk in chunks[:5]:\n",
    "    print(f\"í† í° ê°œìˆ˜: {len(bge_tokenizer.encode(chunk.page_content))}\")\n",
    "    print(f\"{chunk.page_content[:100]}...{chunk.page_content[-100:]}\")\n",
    "    print(\"=\"*100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa19c207",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_chroma import Chroma\n",
    "from langchain_ollama import OllamaEmbeddings   \n",
    "\n",
    "# Ollama ì„ë² ë”© ëª¨ë¸ ìƒì„±\n",
    "embeddings_ollama = OllamaEmbeddings(\n",
    "    model=\"bge-m3\"\n",
    ")\n",
    "\n",
    "# Chroma ë²¡í„° ì €ì¥ì†Œ ìƒì„±í•˜ê¸°\n",
    "chroma_db = Chroma.from_documents(  \n",
    "    documents=chunks,\n",
    "    embedding=embeddings_ollama,    # ì„ë² ë”© ì‚¬ìš©\n",
    "    collection_name=\"labor_law_rag\",    # ì»¬ë ‰ì…˜ ì´ë¦„\n",
    "    persist_directory=\"./chroma_db\",\n",
    "    collection_metadata = {'hnsw:space': 'cosine'}, # l2, ip, cosine ì¤‘ì—ì„œ ì„ íƒ \n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa705465",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ë¬¸ì„œ ê°œìˆ˜ í™•ì¸\n",
    "chroma_db._collection.count()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3368e198",
   "metadata": {},
   "source": [
    "`(2) ë²¡í„° ì €ì¥ì†Œ ë¡œë“œ`  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c39e5cfb",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_chroma import Chroma\n",
    "\n",
    "# ì €ì¥ëœ ë²¡í„° ì €ì¥ì†Œë¥¼ ê°€ì ¸ì˜¤ê¸°\n",
    "chroma_db = Chroma(\n",
    "    collection_name=\"labor_law_rag\",\n",
    "    embedding_function=embeddings_ollama,\n",
    "    persist_directory=\"./chroma_db\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05e0b822",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ë¬¸ì„œ ê°œìˆ˜ í™•ì¸\n",
    "chroma_db._collection.count()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "04aefca3",
   "metadata": {},
   "source": [
    "`(3) ë¬¸ì„œ ê²€ìƒ‰`  \n",
    "- ìœ ì‚¬ë„ ê²€ìƒ‰\n",
    "    - ì£¼ì–´ì§„ ì¿¼ë¦¬ì™€ ê°€ì¥ ìœ ì‚¬í•œ ë¬¸ì„œë¥¼ ë°˜í™˜\n",
    "    -  k=5ëŠ” ìƒìœ„ 5ê°œì˜ ê²°ê³¼ë¥¼ ë°˜í™˜í•˜ë„ë¡ ì§€ì •\n",
    "    - filterë¥¼ ì‚¬ìš©í•˜ì—¬ íŠ¹ì • ì¶œì²˜ì˜ ë¬¸ì„œë§Œ ê²€ìƒ‰ ê°€ëŠ¥"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90c36347",
   "metadata": {},
   "outputs": [],
   "source": [
    "query = \"íƒ„ë ¥ ê·¼ë¡œì— ëŒ€í•´ì„œ ì„¤ëª…í•´ì£¼ì„¸ìš”\"\n",
    "results = chroma_db.similarity_search(\n",
    "    query,\n",
    "    k=5,\n",
    ")\n",
    "\n",
    "print(\"ìœ ì‚¬ë„ ê²€ìƒ‰ ê²°ê³¼:\")\n",
    "for doc in results:\n",
    "    print(f\"{doc.page_content}\")\n",
    "    print(\"=\" * 100)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7cfc931",
   "metadata": {},
   "source": [
    "- ìœ ì‚¬ë„ ì ìˆ˜ê°€ í¬í•¨ëœ ê²€ìƒ‰\n",
    "    - ìœ ì‚¬ë„ ì ìˆ˜ë¥¼ í•¨ê»˜ ë°˜í™˜\n",
    "    - ì ìˆ˜ê°€ ë‚®ì„ìˆ˜ë¡ ë” ìœ ì‚¬í•œ ê²ƒì„ ì˜ë¯¸ (ê±°ë¦¬ ê¸°ì¤€ìœ¼ë¡œ ì ìˆ˜ê°€ ì‚°ì •ë˜ê¸° ë•Œë¬¸)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66f05840",
   "metadata": {},
   "outputs": [],
   "source": [
    "query = \"íƒ„ë ¥ ê·¼ë¡œì— ëŒ€í•´ì„œ ì„¤ëª…í•´ì£¼ì„¸ìš”\"\n",
    "results = chroma_db.similarity_search_with_score(\n",
    "    query,\n",
    "    k=5,\n",
    ")\n",
    "\n",
    "print(\"ì ìˆ˜ê°€ í¬í•¨ëœ ìœ ì‚¬ë„ ê²€ìƒ‰ ê²°ê³¼:\\n\")\n",
    "for doc, score in results:\n",
    "    print(f\"- ì ìˆ˜: {score:.4f}\")\n",
    "    print(f\"  ë‚´ìš©: {doc.page_content}\")\n",
    "    print(f\" ë©”íƒ€ë°ì´í„°: {doc.metadata}\")\n",
    "    print(\"=\" * 100)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d4f9ab2d",
   "metadata": {},
   "source": [
    "### 2. **FAISS**\n",
    "\n",
    "- ê³ ì„±ëŠ¥ì˜ ìœ ì‚¬ë„ ê²€ìƒ‰ì„ ìœ„í•œ ë¼ì´ë¸ŒëŸ¬ë¦¬\n",
    "- `faiss-cpu` íŒ¨í‚¤ì§€ ì„¤ì¹˜"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69f2a1e0",
   "metadata": {},
   "source": [
    "`(1) ë²¡í„° ì €ì¥ì†Œ ì´ˆê¸°í™”`\n",
    "\n",
    "- uv add faiss-cpu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9e17843",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_community.vectorstores import FAISS\n",
    "\n",
    "# FAISS ë²¡í„° ì €ì¥ì†Œ ìƒì„±\n",
    "faiss_db = FAISS.from_documents(\n",
    "    documents=chunks,\n",
    "    embedding=embeddings_openai,  # OpenAI ì„ë² ë”© ì‚¬ìš©\n",
    ")\n",
    "\n",
    "# ë¡œì»¬ ì €ì¥\n",
    "faiss_db.save_local(\"./faiss_index\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6f46f70",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ì €ì¥ëœ ë¬¸ì„œì˜ ê°œìˆ˜\n",
    "print(f\"FAISS ë²¡í„° ì €ì¥ì†Œì— ì €ì¥ëœ ë¬¸ì„œ ê°œìˆ˜: {faiss_db.index.ntotal}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a677fe75",
   "metadata": {},
   "source": [
    "`(2) ë²¡í„° ì €ì¥ì†Œ ë¡œë“œ`  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b4a1750",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ë¡œë“œ\n",
    "faiss_db = FAISS.load_local(\n",
    "    \"./faiss_index\",\n",
    "    embeddings_openai,\n",
    "    allow_dangerous_deserialization=True\n",
    ")\n",
    "\n",
    "# ë¬¸ì„œ ê°œìˆ˜ í™•ì¸\n",
    "print(f\"ë¡œë“œëœ FAISS ë²¡í„° ì €ì¥ì†Œì˜ ë¬¸ì„œ ê°œìˆ˜: {faiss_db.index.ntotal}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "babcdf27",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ê²€ìƒ‰\n",
    "similar_docs = faiss_db.similarity_search(query, k=5)\n",
    "\n",
    "print(f\"ê²€ìƒ‰ ê²°ê³¼ ìˆ˜: {len(similar_docs)}\")\n",
    "for i, doc in enumerate(similar_docs):\n",
    "    print(f\"ê²°ê³¼ {i+1}: {doc.page_content[:100]}...\")\n",
    "    print(\"-\" * 40)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd1114cf",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## ê²€ìƒ‰ê¸° (Retriever)\n",
    "\n",
    "- ë²¡í„° ì €ì¥ì†Œë¥¼ ê¸°ë°˜ìœ¼ë¡œ ì‚¬ìš©ì ì§ˆì˜ì— ê°€ì¥ ê´€ë ¨ì„± ë†’ì€ ë¬¸ì„œë¥¼ ê²€ìƒ‰í•˜ëŠ” LangChain ì¸í„°í˜ì´ìŠ¤\n",
    "\n",
    "- ğŸ“Š ê²€ìƒ‰ ì „ëµ ë¹„êµ\n",
    "\n",
    "    | ì „ëµ | ì„¤ëª… | ì¥ì  | ë‹¨ì  | ì‚¬ìš© ì‚¬ë¡€ |\n",
    "    |------|------|------|------|----------|\n",
    "    | similarity | ë‹¨ìˆœ ìœ ì‚¬ë„ ê²€ìƒ‰ | ë¹ ë¦„, ì§ê´€ì  | ë‹¤ì–‘ì„± ë¶€ì¡± | ì¼ë°˜ì ì¸ ê²€ìƒ‰ |\n",
    "    | similarity_score_threshold | ì„ê³„ê°’ ê¸°ë°˜ ê²€ìƒ‰ | í’ˆì§ˆ ë³´ì¥ | ê²°ê³¼ ìˆ˜ ë¶ˆì•ˆì • | ê³ í’ˆì§ˆ ê²°ê³¼ í•„ìš” |\n",
    "    | mmr | ìµœëŒ€ í•œê³„ ê´€ë ¨ì„± | ë‹¤ì–‘ì„± ìš°ìˆ˜ | ëŠë¦¼ | í¬ê´„ì  ì •ë³´ í•„ìš” |\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e92955f",
   "metadata": {},
   "source": [
    "### 1. ê¸°ë³¸ ìœ ì‚¬ë„ ê²€ìƒ‰ (similarity)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f0fc76a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ë²¡í„° ì €ì¥ì†Œë¥¼ Retrieverë¡œ ë³€í™˜\n",
    "retriever = chroma_db.as_retriever(\n",
    "    search_type=\"similarity\",\n",
    "    search_kwargs={\"k\": 5}  # ìƒìœ„ 5ê°œ ê²°ê³¼\n",
    ")\n",
    "\n",
    "# ê²€ìƒ‰ ì‹¤í–‰\n",
    "query = \"íƒ„ë ¥ ê·¼ë¡œì— ëŒ€í•´ ì„¤ëª…í•´ì£¼ì„¸ìš”\"\n",
    "retrieved_docs = retriever.invoke(query)\n",
    "\n",
    "print(f\"ê²€ìƒ‰ëœ ë¬¸ì„œ ìˆ˜: {len(retrieved_docs)}\")\n",
    "for i, doc in enumerate(retrieved_docs):\n",
    "    print(f\"ë¬¸ì„œ {i+1}:\")\n",
    "    print(f\"ë‚´ìš©: {doc.page_content[:200]}...\")\n",
    "    print(f\"ì¶œì²˜: {doc.metadata.get('source', 'Unknown')}\")\n",
    "    print(\"-\" * 50)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18e1ad45",
   "metadata": {},
   "source": [
    "### 2. ì„ê³„ê°’ ê¸°ë°˜ ê²€ìƒ‰ (similarity_score_threshold)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba2ea290",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ìœ ì‚¬ë„ ì ìˆ˜ ì„ê³„ê°’ ê¸°ë°˜ ê²€ìƒ‰\n",
    "threshold_retriever = chroma_db.as_retriever(\n",
    "    search_type=\"similarity_score_threshold\",\n",
    "    search_kwargs={\n",
    "        \"score_threshold\": 0.6,  # 0.6 ì´ìƒì˜ ìœ ì‚¬ë„ë§Œ\n",
    "        \"k\": 10                   # ìµœëŒ€ 10ê°œê¹Œì§€\n",
    "    }\n",
    ")\n",
    "\n",
    "retrieved_docs = threshold_retriever.invoke(query)\n",
    "\n",
    "print(\"ìœ ì‚¬ë„ ì ìˆ˜ ì„ê³„ê°’ ê¸°ë°˜ ê²€ìƒ‰ ê²°ê³¼:\")\n",
    "print(f\"ê²€ìƒ‰ëœ ë¬¸ì„œ ìˆ˜: {len(retrieved_docs)}\")\n",
    "for i, doc in enumerate(retrieved_docs):\n",
    "    print(f\"ë¬¸ì„œ {i+1}: {doc.page_content[:150]}...\")\n",
    "    print(\"-\" * 50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8de4f2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ì‹¤ì œ ìœ ì‚¬ë„ ì ìˆ˜ í™•ì¸\n",
    "from langchain_community.utils.math import cosine_similarity\n",
    "\n",
    "for i, doc in enumerate(retrieved_docs):\n",
    "    # ì‹¤ì œ ìœ ì‚¬ë„ ê³„ì‚°\n",
    "    doc_embedding = embeddings_ollama.embed_query(doc.page_content)\n",
    "    query_embedding = embeddings_ollama.embed_query(query)\n",
    "    similarity = cosine_similarity([query_embedding], [doc_embedding])[0][0]\n",
    "    \n",
    "    print(f\"ë¬¸ì„œ {i+1} (ìœ ì‚¬ë„: {similarity:.4f}):\")\n",
    "    print(f\"{doc.page_content[:100]}...\")\n",
    "    print(\"-\" * 50)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e891552c",
   "metadata": {},
   "source": [
    "### 3. MMR (Maximal Marginal Relevance) ê²€ìƒ‰"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bcc00a7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# MMR ê²€ìƒ‰ - ê´€ë ¨ì„±ê³¼ ë‹¤ì–‘ì„±ì˜ ê· í˜•\n",
    "mmr_retriever = chroma_db.as_retriever(\n",
    "    search_type=\"mmr\",\n",
    "    search_kwargs={\n",
    "        \"k\": 5,                # ìµœì¢… ë°˜í™˜í•  ë¬¸ì„œ ìˆ˜\n",
    "        \"fetch_k\": 20,         # ì´ˆê¸° í›„ë³´ ë¬¸ì„œ ìˆ˜\n",
    "        \"lambda_mult\": 0.5     # ê´€ë ¨ì„± vs ë‹¤ì–‘ì„± (0=ìµœëŒ€ ë‹¤ì–‘ì„±, 1=ìµœëŒ€ ê´€ë ¨ì„±)\n",
    "    }\n",
    ")\n",
    "\n",
    "mmr_docs = mmr_retriever.invoke(query)\n",
    "\n",
    "print(f\"MMR ê²€ìƒ‰ ê²°ê³¼ ìˆ˜: {len(mmr_docs)}\")\n",
    "\n",
    "for i, doc in enumerate(mmr_docs):\n",
    "    print(f\"ë¬¸ì„œ {i+1}: {doc.page_content[:150]}...\")\n",
    "    print(\"-\" * 50)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "efc4cc96",
   "metadata": {},
   "source": [
    "#### ğŸ“ ì—°ìŠµ ë¬¸ì œ 4: Chroma ë²¡í„° ì €ì¥ì†Œ êµ¬ì¶•"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b15cf67e",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "ğŸ“Œ ì‹¤ìŠµ: ì˜ë£Œ ë¬¸ì„œë¡œ ë²¡í„° ì €ì¥ì†Œ êµ¬ì¶• (data/personal_info_law.pdf)\n",
    "1. PDF ë¬¸ì„œ ë¡œë“œ ë° ë¶„í• \n",
    "2. Chroma ë²¡í„° ì €ì¥ì†Œ ìƒì„±\n",
    "3. ë©”íƒ€ë°ì´í„° í•„í„°ë§ ê²€ìƒ‰ êµ¬í˜„\n",
    "\"\"\"\n",
    "\n",
    "# ì—¬ê¸°ì— ì½”ë“œë¥¼ ì‘ì„±í•˜ì„¸ìš”"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f33a085",
   "metadata": {},
   "source": [
    "<details>\n",
    "<summary>ğŸ’¡ ì •ë‹µ ë³´ê¸°</summary>\n",
    "\n",
    "```python\n",
    "from langchain_chroma import Chroma\n",
    "from langchain_ollama import OllamaEmbeddings\n",
    "from langchain_text_splitters import RecursiveCharacterTextSplitter\n",
    "import hashlib\n",
    "\n",
    "# 1. ë¬¸ì„œ ì¤€ë¹„\n",
    "pdf_loader = PyPDFLoader('data/personal_info_law.pdf', mode='page')\n",
    "docs = pdf_loader.load()\n",
    "\n",
    "# 2. í…ìŠ¤íŠ¸ ë¶„í•  (ë©”íƒ€ë°ì´í„° ì¶”ê°€)\n",
    "text_splitter = RecursiveCharacterTextSplitter(\n",
    "    chunk_size=1000,\n",
    "    chunk_overlap=200\n",
    ")\n",
    "\n",
    "chunks = text_splitter.split_documents(docs)\n",
    "\n",
    "# 3. ë²¡í„° ì €ì¥ì†Œ ìƒì„±\n",
    "embeddings = OllamaEmbeddings(model=\"bge-m3\")\n",
    "\n",
    "vectorstore = Chroma.from_documents(\n",
    "    documents=chunks,  \n",
    "    embedding=embeddings,\n",
    "    collection_name=\"personal_info_law_rag\",\n",
    "    persist_directory=\"./chroma_practice\"\n",
    ")\n",
    "\n",
    "print(f\"ì €ì¥ëœ ë¬¸ì„œ ìˆ˜: {vectorstore._collection.count()}\")\n",
    "\n",
    "# 4. ë©”íƒ€ë°ì´í„° í•„í„°ë§ ê²€ìƒ‰\n",
    "# íŠ¹ì • í˜ì´ì§€ì—ì„œë§Œ ê²€ìƒ‰\n",
    "results = vectorstore.similarity_search(\n",
    "    \"ì¸ê³µì§€ëŠ¥ ì˜ë£Œ\",\n",
    "    k=3,\n",
    "    filter={\"page\": 0}  # ì²« í˜ì´ì§€ì—ì„œë§Œ ê²€ìƒ‰\n",
    ")\n",
    "\n",
    "print(\"\\nì²« í˜ì´ì§€ì—ì„œ ê²€ìƒ‰í•œ ê²°ê³¼:\")\n",
    "for doc in results:\n",
    "    print(f\"- í˜ì´ì§€ {doc.metadata.get('page')}: {doc.page_content[:100]}...\")\n",
    "```\n",
    "\n",
    "</details>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a12c7b5",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "##  Naive RAG êµ¬í˜„ \n",
    "\n",
    "- ê²€ìƒ‰(Retrieval)ê³¼ ìƒì„±(Generation)ì„ ì—°ê²°í•˜ì—¬ ì™¸ë¶€ ì§€ì‹ì„ ê¸°ë°˜ìœ¼ë¡œ ë‹µë³€ì„ ìƒì„±í•˜ëŠ” íŒŒì´í”„ë¼ì¸\n",
    "\n",
    "- ğŸ”„ RAG ì›Œí¬í”Œë¡œìš°\n",
    "    - ì‚¬ìš©ì ì§ˆë¬¸ â†’ ê´€ë ¨ ë¬¸ì„œ ê²€ìƒ‰ â†’ ì»¨í…ìŠ¤íŠ¸ êµ¬ì„± â†’ LLM í”„ë¡¬í”„íŠ¸ â†’ ë‹µë³€ ìƒì„±"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d70691e",
   "metadata": {},
   "source": [
    "`(1) ë²¡í„° ì €ì¥ì†Œ ë¡œë“œ`\n",
    "- `Chroma` ë²¡í„° ì €ì¥ì†Œë¥¼ ë¡œë“œ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b684474",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_chroma import Chroma\n",
    "from langchain_ollama import OllamaEmbeddings\n",
    "\n",
    "# Ollama ì„ë² ë”© ëª¨ë¸ ìƒì„±\n",
    "embeddings_ollama = OllamaEmbeddings(\n",
    "    model=\"bge-m3\",  # ì‚¬ìš©í•  ëª¨ë¸ ì´ë¦„\n",
    "    )\n",
    "\n",
    "# ì €ì¥ëœ ë²¡í„° ì €ì¥ì†Œë¥¼ ê°€ì ¸ì˜¤ê¸°\n",
    "chroma_db = Chroma(\n",
    "    collection_name=\"labor_law_rag\",\n",
    "    embedding_function=embeddings_ollama,\n",
    "    persist_directory=\"./chroma_db\",\n",
    ")\n",
    "\n",
    "# ë¬¸ì„œ ê°œìˆ˜ í™•ì¸\n",
    "print(f\"ì €ì¥ëœ ë¬¸ì„œ ìˆ˜: {chroma_db._collection.count()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "428b2f7d",
   "metadata": {},
   "source": [
    "`(2) ê²€ìƒ‰ê¸°(Retriever) ì´ˆê¸°í™”`\n",
    "\n",
    "- mmr ê²€ìƒ‰ì„ ì‚¬ìš©í•˜ëŠ” Retriever ì‚¬ìš©\n",
    "- ë‹¤ì–‘ì„±ì„ ë†’ì´ëŠ” ì„¤ì •ì„ ì‚¬ìš©"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad3b280f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# mmr ê²€ìƒ‰ê¸° ìƒì„±\n",
    "retriever = chroma_db.as_retriever(\n",
    "    search_type='mmr',\n",
    "    search_kwargs={\n",
    "        'k': 5,                  # ê²€ìƒ‰í•  ë¬¸ì„œì˜ ìˆ˜\n",
    "        'fetch_k': 10,           # mmr ì•Œê³ ë¦¬ì¦˜ì— ì „ë‹¬í•  ë¬¸ì„œì˜ ìˆ˜ (fetch_k > k)\n",
    "        'lambda_mult': 0.3,      # ë‹¤ì–‘ì„±ì„ ê³ ë ¤í•˜ëŠ” ì •ë„ (1ì€ ìµœì†Œ ë‹¤ì–‘ì„±, 0ì€ ìµœëŒ€ ë‹¤ì–‘ì„±ì„ ì˜ë¯¸. ê¸°ë³¸ê°’ì€ 0.5)\n",
    "        },\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36743877",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ê²€ìƒ‰ í…ŒìŠ¤íŠ¸ \n",
    "query = \"íƒ„ë ¥ ê·¼ë¡œì— ëŒ€í•´ ì„¤ëª…í•´ì£¼ì„¸ìš”\"\n",
    "\n",
    "# ì¿¼ë¦¬ì™€ ìœ ì‚¬í•œ ë¬¸ì„œ ê²€ìƒ‰\n",
    "retrieved_docs = retriever.invoke(query)\n",
    "\n",
    "print(f\"ì¿¼ë¦¬: {query}\")\n",
    "print(\"ê²€ìƒ‰ ê²°ê³¼:\")\n",
    "for i, doc in enumerate(retrieved_docs, 1):\n",
    "    print(f\"-{i}-\\n{doc.page_content}\\n[ì¶œì²˜: {doc.metadata['source']}]\")\n",
    "    print(\"-\" * 100)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3024d5d9",
   "metadata": {},
   "source": [
    "`(3) RAG í”„ë¡¬í”„íŠ¸ êµ¬ì„±`\n",
    "\n",
    "- ì‘ì„± ê¸°ì¤€: \n",
    "    - LangChainì˜ ChatPromptTemplate í´ë˜ìŠ¤ ì‚¬ìš©\n",
    "    - ë³€ìˆ˜ ì²˜ë¦¬ëŠ” {context}, {question} í˜•ì‹ ì‚¬ìš©\n",
    "    - ë‹µë³€ì€ í•œê¸€ë¡œ ì¶œë ¥ë˜ë„ë¡ í”„ë¡¬í”„íŠ¸ ì‘ì„±\n",
    "    \n",
    "- ì•„ë˜ í…œí”Œë¦¿ ì½”ë“œë¥¼ ê¸°ë°˜ìœ¼ë¡œ ë‹¤ìŒ ë‚´ìš©ì„ ì°¸ê³ í•˜ì—¬ ì‘ì„±í•©ë‹ˆë‹¤. \n",
    "\n",
    "    1. í”„ë¡¬í”„íŠ¸ êµ¬ì„±ìš”ì†Œ:\n",
    "        - ì‘ì—… ì§€ì¹¨\n",
    "        - ì»¨í…ìŠ¤íŠ¸ ì˜ì—­\n",
    "        - ì§ˆë¬¸ ì˜ì—­\n",
    "        - ë‹µë³€ í˜•ì‹ ê°€ì´ë“œ\n",
    "\n",
    "    2. ì‘ì—… ì§€ì¹¨:\n",
    "        - ì»¨í…ìŠ¤íŠ¸ ê¸°ë°˜ ë‹µë³€ ì›ì¹™\n",
    "        - ì™¸ë¶€ ì§€ì‹ ì‚¬ìš© ì œí•œ\n",
    "        - ë¶ˆí™•ì‹¤ì„± ì²˜ë¦¬ ë°©ë²•\n",
    "        - ë‹µë³€ ë¶ˆê°€ëŠ¥í•œ ê²½ìš°ì˜ ì²˜ë¦¬ ë°©ë²•\n",
    "\n",
    "    3. ë‹µë³€ í˜•ì‹:\n",
    "        - í•µì‹¬ ë‹µë³€ ì„¹ì…˜\n",
    "        - ê·¼ê±° ì œì‹œ ì„¹ì…˜\n",
    "        - ì¶”ê°€ ì„¤ëª… ì„¹ì…˜ (í•„ìš”ì‹œ)\n",
    "\n",
    "    4. ì œì•½ì‚¬í•­ ë°˜ì˜:\n",
    "        - ë‹µë³€ì€ ì‚¬ì‹¤ì— ê¸°ë°˜í•´ì•¼ í•¨\n",
    "        - ì¶”ì¸¡ì´ë‚˜ ê°€ì •ì„ ìµœì†Œí™”í•´ì•¼ í•¨\n",
    "        - ëª…í™•í•œ ê·¼ê±° ì œì‹œê°€ í•„ìš”í•¨\n",
    "        - êµ¬ì¡°í™”ëœ í˜•íƒœë¡œ ì‘ì„±ë˜ì–´ì•¼ í•¨"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f14c1634",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "\n",
    "# ê¸°ë³¸ RAG í”„ë¡¬í”„íŠ¸ í…œí”Œë¦¿\n",
    "basic_template = \"\"\"ì£¼ì–´ì§„ ì»¨í…ìŠ¤íŠ¸ë¥¼ ê¸°ë°˜ìœ¼ë¡œ ì§ˆë¬¸ì— ë‹µë³€í•˜ì„¸ìš”.\n",
    "\n",
    "<ì»¨í…ìŠ¤íŠ¸>\n",
    "{context}\n",
    "</ì»¨í…ìŠ¤íŠ¸>\n",
    "\n",
    "<ì§ˆë¬¸>\n",
    "{question}\n",
    "</ì§ˆë¬¸>\n",
    "\"\"\"\n",
    "\n",
    "basic_prompt = ChatPromptTemplate.from_template(basic_template)\n",
    "\n",
    "# í…œí”Œë¦¿ ì¶œë ¥\n",
    "basic_prompt.pretty_print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "367b455b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ì»¤ìŠ¤í…€ í”„ë¡¬í”„íŠ¸ í…œí”Œë¦¿\n",
    "advanced_template = \"\"\"ë‹¹ì‹ ì€ ì „ë¬¸ì ì¸ ë¬¸ì„œ ë¶„ì„ AIì…ë‹ˆë‹¤. ì£¼ì–´ì§„ ì»¨í…ìŠ¤íŠ¸ë¥¼ ë°”íƒ•ìœ¼ë¡œ ì •í™•í•˜ê³  ìœ ìš©í•œ ë‹µë³€ì„ ì œê³µí•˜ì„¸ìš”.\n",
    "\n",
    "<ë‹µë³€ ì§€ì¹¨>\n",
    "- ì»¨í…ìŠ¤íŠ¸ì— ìˆëŠ” ì •ë³´ë§Œì„ ì‚¬ìš©í•˜ì—¬ ë‹µë³€í•˜ì„¸ìš”\n",
    "- í™•ì‹¤í•˜ì§€ ì•Šì€ ì •ë³´ëŠ” \"ëª…í™•í•˜ì§€ ì•ŠìŠµë‹ˆë‹¤\"ë¼ê³  ëª…ì‹œí•˜ì„¸ìš”\n",
    "- ë‹µë³€ì€ ë…¼ë¦¬ì ì´ê³  êµ¬ì¡°í™”ëœ í˜•íƒœë¡œ ì œê³µí•˜ì„¸ìš”\n",
    "- ê°€ëŠ¥í•œ ê²½ìš° êµ¬ì²´ì ì¸ ì˜ˆì‹œë‚˜ ìˆ˜ì¹˜ë¥¼ í¬í•¨í•˜ì„¸ìš”\n",
    "</ë‹µë³€ ì§€ì¹¨>\n",
    "\n",
    "<ë‹µë³€ í˜•ì‹>\n",
    "## **í•µì‹¬ ë‹µë³€:** (ì§ˆë¬¸ì— ëŒ€í•œ ì§ì ‘ì ì¸ ë‹µë³€)\n",
    "## **ì„¸ë¶€ ì„¤ëª…:** (ì¶”ê°€ì ì¸ ì„¤ëª…ì´ë‚˜ ë°°ê²½ ì •ë³´)\n",
    "## **ê´€ë ¨ ì •ë³´:** (ì»¨í…ìŠ¤íŠ¸ì—ì„œ ë°œê²¬ëœ ì—°ê´€ ì •ë³´)\n",
    "</ë‹µë³€ í˜•ì‹>\n",
    "\n",
    "<ì»¨í…ìŠ¤íŠ¸>\n",
    "{context}\n",
    "</ì»¨í…ìŠ¤íŠ¸>\n",
    "\n",
    "<ì§ˆë¬¸>\n",
    "{question}\n",
    "</ì§ˆë¬¸>\n",
    "\"\"\"\n",
    "\n",
    "advanced_prompt = ChatPromptTemplate.from_template(advanced_template)\n",
    "\n",
    "# í…œí”Œë¦¿ ì¶œë ¥\n",
    "advanced_prompt.pretty_print()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad0f5cf5",
   "metadata": {},
   "source": [
    "`(4) RAG ì²´ì¸ êµ¬ì„±`\n",
    "- LangChainì˜ LCEL ë¬¸ë²•ì„ ì‚¬ìš©\n",
    "- ê²€ìƒ‰ ê²°ê³¼ë¥¼ í”„ë¡¬í”„íŠ¸ì˜ 'context'ë¡œ ì „ë‹¬í•˜ê³ ,\n",
    "- ì‚¬ìš©ìê°€ ì…ë ¥í•œ ì§ˆë¬¸ì„ ê·¸ë˜ë„ í”„ë¡¬í”„íŠ¸ì˜ 'question'ì— ì „ë‹¬\n",
    "- LLM ì„¤ì •:\n",
    "    - ChatOllama ì‚¬ìš© ('qwen3:4b' ëª¨ë¸)\n",
    "    - temperature: ë‹µë³€ì˜ ì¼ê´€ì„±ì„ ê°€ì ¸ê°€ëŠ” ì„¤ì •ê°’ì„ ì‚¬ìš© \n",
    "    - ê¸°íƒ€ í•„ìš”í•œ ì„¤ì • \n",
    "- ì¶œë ¥ íŒŒì„œ: ë¬¸ìì—´ ë¶€ë¶„ë§Œ ì¶œë ¥ë˜ë„ë¡ êµ¬ì„± "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e4121f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.runnables import RunnableLambda, RunnablePassthrough, RunnableParallel\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "from langchain_openai import ChatOpenAI\n",
    "\n",
    "# LLM ì„¤ì •\n",
    "llm = ChatOpenAI(\n",
    "    model=\"gpt-4.1-mini\",\n",
    "    temperature=0.7,\n",
    "    top_p=0.9,\n",
    ")\n",
    "\n",
    "# ë¬¸ì„œ í¬ë§·íŒ…\n",
    "def format_docs(docs):\n",
    "    return \"\\n\\n\".join([f\"{doc.page_content}\" for doc in docs])\n",
    "\n",
    "# RAG ì²´ì¸ ìƒì„±\n",
    "rag_chain = (\n",
    "    RunnableParallel(\n",
    "        {\n",
    "            \"context\": retriever | RunnableLambda(format_docs), \n",
    "            \"question\": RunnablePassthrough()\n",
    "        }\n",
    "    )\n",
    "    | advanced_prompt\n",
    "    | llm\n",
    "    | StrOutputParser()\n",
    ")\n",
    "\n",
    "# ì²´ì¸ ì‹¤í–‰\n",
    "query = \"íƒ„ë ¥ ê·¼ë¡œì— ëŒ€í•´ì„œ ì„¤ëª…í•´ì£¼ì„¸ìš”\"\n",
    "output = rag_chain.invoke(query)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13ca71e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(output)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea8a1457",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "# ğŸ¯ ì‹¤ìŠµ: RAG ì²´ì¸ êµ¬ì„±\n",
    "\n",
    "- RAG ì²´ì¸ì„ êµ¬ì„±í•˜ì—¬ ì§ˆë¬¸ì— ëŒ€í•œ ë‹µë³€ì„ ìƒì„±í•´ë³´ì„¸ìš”.\n",
    "- ë¬¸ì„œ ë¡œë”©, ì„ë² ë”©, ë²¡í„° ì €ì¥ì†Œ êµ¬ì¶•, ê²€ìƒ‰ê¸° ì„¤ì • ë“±ì„ í¬í•¨í•˜ì—¬ ì „ì²´ RAG íŒŒì´í”„ë¼ì¸ì„ êµ¬í˜„í•©ë‹ˆë‹¤.\n",
    "- ëŒ€ìƒ ë¬¸ì„œ: data/personal_info_law.pdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57c47c33",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ì—¬ê¸°ì— ì½”ë“œë¥¼ ì‘ì„±í•˜ì„¸ìš”"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
