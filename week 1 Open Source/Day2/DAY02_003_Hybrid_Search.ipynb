{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# í•˜ì´ë¸Œë¦¬ë“œ ê²€ìƒ‰(Hybrid Search)\n",
    "\n",
    "---\n",
    "\n",
    "## 1. ê°œë… ì´í•´\n",
    "\n",
    "### 1.1 ê²€ìƒ‰ ë°©ì‹ ë¶„ë¥˜\n",
    "\n",
    "#### ğŸ” **ì˜ë¯¸ë¡ ì  ê²€ìƒ‰ (Semantic Search)**\n",
    "- **ì •ì˜**: ë²¡í„° ì„ë² ë”©ì„ í™œìš©í•œ ì˜ë¯¸ ê¸°ë°˜ ê²€ìƒ‰\n",
    "- **íŠ¹ì§•**: \n",
    "  - ë™ì˜ì–´ì™€ ë¬¸ë§¥ì  ì˜ë¯¸ë¥¼ íŒŒì•…\n",
    "  - ìì—°ì–´ ì§ˆì˜ì— íš¨ê³¼ì \n",
    "  - ìœ ì‚¬ë„ ê¸°ë°˜ ë§¤ì¹­\n",
    "- **ì¥ì **: ì˜ë¯¸ì  ì—°ê´€ì„±ì´ ë†’ì€ ë¬¸ì„œ ê²€ìƒ‰\n",
    "- **ë‹¨ì **: ì •í™•í•œ í‚¤ì›Œë“œ ë§¤ì¹­ ì•½í•¨\n",
    "\n",
    "#### ğŸ” **í‚¤ì›Œë“œ ê²€ìƒ‰ (Keyword Search)**\n",
    "- **ì •ì˜**: BM25 ì•Œê³ ë¦¬ì¦˜ ê¸°ë°˜ í‚¤ì›Œë“œ ë§¤ì¹­ ê²€ìƒ‰\n",
    "- **íŠ¹ì§•**:\n",
    "  - ì§ì ‘ì ì¸ ë‹¨ì–´/êµ¬ë¬¸ ë§¤ì¹­\n",
    "  - ê³„ì‚° íš¨ìœ¨ì„± ë†’ìŒ\n",
    "  - ì „í†µì ì¸ ì •ë³´ê²€ìƒ‰ ë°©ì‹\n",
    "- **ì¥ì **: ì •í™•í•œ í‚¤ì›Œë“œ ë§¤ì¹­, ë¹ ë¥¸ ì²˜ë¦¬ ì†ë„\n",
    "- **ë‹¨ì **: ì˜ë¯¸ì  ìœ ì‚¬ì„± íŒŒì•… ì œí•œì \n",
    "\n",
    "#### ğŸ” **í•˜ì´ë¸Œë¦¬ë“œ ê²€ìƒ‰ (Hybrid Search)**\n",
    "- **ì •ì˜**: í‚¤ì›Œë“œ ê²€ìƒ‰ê³¼ ì˜ë¯¸ë¡ ì  ê²€ìƒ‰ì˜ ê²°í•©\n",
    "- **íŠ¹ì§•**:\n",
    "  - EnsembleRetrieverë¥¼ í†µí•œ êµ¬í˜„\n",
    "  - ê°€ì¤‘ì¹˜ ì¡°ì •ìœ¼ë¡œ ì„±ëŠ¥ ìµœì í™”\n",
    "  - ë‘ ê²€ìƒ‰ ë°©ì‹ì˜ ì‹œë„ˆì§€ íš¨ê³¼\n",
    "- **ì¥ì **: í¬ê´„ì ì´ê³  ì •í™•í•œ ê²€ìƒ‰ ê²°ê³¼\n",
    "- **ë‹¨ì **: êµ¬í˜„ ë³µì¡ë„ ì¦ê°€, ê³„ì‚° ë¹„ìš© ìƒìŠ¹\n",
    "\n",
    "### 1.2 BM25 ì•Œê³ ë¦¬ì¦˜ ì´í•´\n",
    "\n",
    "- BM25ëŠ” TF-IDFì˜ í™•ì¥ëœ ë²„ì „ìœ¼ë¡œ, ë‹¤ìŒ ê³µì‹ì„ ì‚¬ìš©í•©ë‹ˆë‹¤:\n",
    "\n",
    "  ```markdown\n",
    "  BM25(qi, D) = IDF(qi) Ã— (f(qi, D) Ã— (k1 + 1)) / (f(qi, D) + k1 Ã— (1 - b + b Ã— |D| / avgdl))\n",
    "  ```\n",
    "\n",
    "  - `f(qi, D)`: ë¬¸ì„œ Dì—ì„œ ë‹¨ì–´ qiì˜ ë¹ˆë„\n",
    "  - `|D|`: ë¬¸ì„œ Dì˜ ê¸¸ì´\n",
    "  - `avgdl`: í‰ê·  ë¬¸ì„œ ê¸¸ì´\n",
    "  - `k1, b`: ì¡°ì • ë§¤ê°œë³€ìˆ˜"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## 2. í™˜ê²½ ì„¤ì •\n",
    "\n",
    "### 2.1 ë¼ì´ë¸ŒëŸ¬ë¦¬ ì„¤ì¹˜\n",
    "\n",
    "```bash\n",
    "uv pip install ranx-k\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2 í™˜ê²½ ë³€ìˆ˜ ì„¤ì •"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dotenv import load_dotenv\n",
    "\n",
    "# í™˜ê²½ ë³€ìˆ˜ ë¡œë“œ\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.3 ê¸°ë³¸ ë¼ì´ë¸ŒëŸ¬ë¦¬"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "from glob import glob\n",
    "from pprint import pprint\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# # í•œê¸€ í°íŠ¸ ì¸ì‹ - Windows\n",
    "# import matplotlib \n",
    "# font_name = matplotlib.font_manager.FontProperties(fname=\"c:/Windows/Fonts/malgun.ttf\").get_name()\n",
    "# matplotlib.rc('font', family=font_name)\n",
    "\n",
    "# í•œê¸€ í°íŠ¸ ì¸ì‹ - Mac\n",
    "import matplotlib\n",
    "matplotlib.rc('font', family='AppleGothic')\n",
    "\n",
    "# ë§ˆì´ë„ˆìŠ¤ ë¶€í˜¸ ì¸ì‹\n",
    "matplotlib.rc(\"axes\", unicode_minus = False)\n",
    "\n",
    "# LangChain í•µì‹¬\n",
    "from langchain_core.documents import Document\n",
    "from langchain.retrievers import EnsembleRetriever\n",
    "from langchain_community.retrievers import BM25Retriever\n",
    "from langchain_chroma import Chroma\n",
    "from langchain_openai import OpenAIEmbeddings\n",
    "\n",
    "# ë°ì´í„° ì²˜ë¦¬\n",
    "from langchain_community.document_loaders import TextLoader\n",
    "from langchain_text_splitters import RecursiveCharacterTextSplitter\n",
    "\n",
    "# í‰ê°€\n",
    "import ranx_k"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## 3. ë°ì´í„° ì¤€ë¹„\n",
    "\n",
    "### 3.1 í…ìŠ¤íŠ¸ ë°ì´í„° ë¡œë“œ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_text_files(file_patterns):\n",
    "\n",
    "    documents = []\n",
    "    \n",
    "    for pattern in file_patterns:\n",
    "        files = glob(pattern)\n",
    "        for file_path in files:\n",
    "            try:\n",
    "                loader = TextLoader(file_path, encoding='utf-8')\n",
    "                docs = loader.load()\n",
    "                documents.extend(docs)\n",
    "                print(f\"âœ… {file_path} ë¡œë“œ ì™„ë£Œ\")\n",
    "            except Exception as e:\n",
    "                print(f\"âŒ {file_path} ë¡œë“œ ì‹¤íŒ¨: {e}\")\n",
    "    \n",
    "    return documents\n",
    "\n",
    "# ë¡œë“œí•  ë¬¸ì„œì˜ íŒ¨í„´ ì •ì˜\n",
    "# ì˜ˆì‹œ: 'data/*.txt', 'data/*.json' ë“±\n",
    "# í˜„ì¬ëŠ” 'data/*_KR.md' íŒ¨í„´ë§Œ ì‚¬ìš©\n",
    "file_patterns = [\n",
    "    'data/*_KR.md',\n",
    "    # 'data/*.txt',\n",
    "    # 'data/*.json'\n",
    "]\n",
    "raw_documents = load_text_files(file_patterns)\n",
    "print(f\"ì´ {len(raw_documents)}ê°œ ë¬¸ì„œ ë¡œë“œë¨\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.2 ë¬¸ì„œ ë¶„í•  ë° ì „ì²˜ë¦¬"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_documents(documents, company_mapping=None):\n",
    "    \"\"\"\n",
    "    ë¬¸ì„œ ì „ì²˜ë¦¬ ë° ë©”íƒ€ë°ì´í„° ì¶”ê°€\n",
    "    \n",
    "    Args:\n",
    "        documents (list): ì›ë³¸ ë¬¸ì„œ ë¦¬ìŠ¤íŠ¸\n",
    "        company_mapping (dict): íšŒì‚¬ëª… ë§¤í•‘ ì •ë³´\n",
    "    \n",
    "    Returns:\n",
    "        list: ì „ì²˜ë¦¬ëœ Document ê°ì²´ ë¦¬ìŠ¤íŠ¸\n",
    "    \"\"\"\n",
    "    text_splitter = RecursiveCharacterTextSplitter.from_tiktoken_encoder(\n",
    "        encoding_name=\"cl100k_base\",\n",
    "        separators=['\\n\\n', '\\n', r'(?<=[.!?])\\s+'],\n",
    "        chunk_size=300,\n",
    "        chunk_overlap=50,\n",
    "        is_separator_regex=True,\n",
    "        keep_separator=True,\n",
    "    )\n",
    "    chunks = text_splitter.split_documents(documents)\n",
    "    \n",
    "    processed_docs = []\n",
    "    for chunk in chunks:\n",
    "        # ë©”íƒ€ë°ì´í„° ì¶”ê°€\n",
    "        source_file = chunk.metadata.get('source', '')\n",
    "        \n",
    "        # íšŒì‚¬ëª… ì¶”ì¶œ\n",
    "        if company_mapping:\n",
    "            company = 'unknown'\n",
    "            for keyword, name in company_mapping.items():\n",
    "                if keyword in source_file.lower():\n",
    "                    company = name\n",
    "                    break\n",
    "        else:\n",
    "            company = 'default'\n",
    "        \n",
    "        # Document ê°ì²´ ìƒì„±\n",
    "        doc = Document(\n",
    "            page_content=f\"<Document>\\n{chunk.page_content}\\n</Document>\\n<Source>ì´ ë¬¸ì„œëŠ” '{company}'ì— ëŒ€í•œ ë¬¸ì„œì…ë‹ˆë‹¤.</Source>\",\n",
    "            metadata={\n",
    "                **chunk.metadata,\n",
    "                'company': company,\n",
    "                'language': 'ko',\n",
    "                'chunk_length': len(chunk.page_content)\n",
    "            }\n",
    "        )\n",
    "        processed_docs.append(doc)\n",
    "    \n",
    "    return processed_docs\n",
    "\n",
    "# íšŒì‚¬ëª… ë§¤í•‘ ì •ë³´\n",
    "# ì˜ˆì‹œ: 'tesla' -> 'í…ŒìŠ¬ë¼', 'rivian' -> 'ë¦¬ë¹„ì•ˆ'\n",
    "# ì‹¤ì œ ì‚¬ìš© ì‹œì—ëŠ” ë” ë§ì€ íšŒì‚¬ëª…ì„ ì¶”ê°€í•  ìˆ˜ ìˆìŒ\n",
    "company_mapping = {\n",
    "    'á„á…¦á„‰á…³á†¯á„…á…¡': 'í…ŒìŠ¬ë¼(tesla)',\n",
    "    'á„…á…µá„‡á…µá„‹á…¡á†«': 'ë¦¬ë¹„ì•ˆ(rivian)',\n",
    "}\n",
    "\n",
    "processed_docs = preprocess_documents(raw_documents, company_mapping)\n",
    "print(f\"ì´ {len(processed_docs)}ê°œ ì²­í¬ ìƒì„±ë¨\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ê²°ê³¼ í™•ì¸\n",
    "for i, doc in enumerate(processed_docs[:3]+ processed_docs[-3:]):\n",
    "    print(f\"\\n[ì²­í¬ {i+1}]\")\n",
    "    print(f\"íšŒì‚¬: {doc.metadata['company']}\")\n",
    "    print(f\"ë‚´ìš©: {doc.page_content}\")\n",
    "    print(\"-\" * 50)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## 4. ê²€ìƒ‰ ë°©ë²•ë¡ \n",
    "\n",
    "### 4.1 ì˜ë¯¸ë¡ ì  ê²€ìƒ‰ (Semantic Search)\n",
    "\n",
    "#### 4.1.1 ë²¡í„° ì €ì¥ì†Œ ìƒì„±"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from langchain_chroma import Chroma\n",
    "from langchain_openai import OpenAIEmbeddings\n",
    "\n",
    "def create_or_load_vector_store(documents, collection_name=\"hybrid_search_db\"):\n",
    "    \"\"\"\n",
    "    Chroma ë²¡í„° ì €ì¥ì†Œ ìƒì„± (ê¸°ì¡´ ì»¬ë ‰ì…˜ì´ ìˆìœ¼ë©´ ë¡œë“œí•˜ê³ , ì—†ìœ¼ë©´ ìƒˆë¡œ ìƒì„±)\n",
    "    \n",
    "    Args:\n",
    "        documents (list): Document ê°ì²´ ë¦¬ìŠ¤íŠ¸\n",
    "        collection_name (str): ì»¬ë ‰ì…˜ ì´ë¦„\n",
    "    \n",
    "    Returns:\n",
    "        Chroma: ë²¡í„° ì €ì¥ì†Œ ê°ì²´\n",
    "\n",
    "    \"\"\"\n",
    "    embeddings = OpenAIEmbeddings(model=\"text-embedding-3-small\")\n",
    "    persist_directory = \"./local_chroma_db\"\n",
    "    \n",
    "    # ë””ë ‰í† ë¦¬ì™€ ì»¬ë ‰ì…˜ íŒŒì¼ì´ ì¡´ì¬í•˜ëŠ”ì§€ í™•ì¸\n",
    "    if os.path.exists(persist_directory):\n",
    "        try:\n",
    "            # ê¸°ì¡´ ì»¬ë ‰ì…˜ ë¡œë“œ ì‹œë„\n",
    "            vector_store = Chroma(\n",
    "                collection_name=collection_name,\n",
    "                embedding_function=embeddings,\n",
    "                persist_directory=persist_directory\n",
    "            )\n",
    "            \n",
    "            # ì»¬ë ‰ì…˜ì— ë¬¸ì„œê°€ ìˆëŠ”ì§€ í™•ì¸\n",
    "            if vector_store._collection.count() > 0:\n",
    "                print(f\"âœ… ê¸°ì¡´ ë²¡í„° ì €ì¥ì†Œ ë¡œë“œ ì™„ë£Œ: {vector_store._collection.count()}ê°œ ë¬¸ì„œ\")\n",
    "                return vector_store\n",
    "        except Exception as e:\n",
    "            print(f\"ê¸°ì¡´ ì»¬ë ‰ì…˜ ë¡œë“œ ì‹¤íŒ¨: {e}\")\n",
    "    \n",
    "    # ìƒˆë¡œìš´ ë²¡í„° ì €ì¥ì†Œ ìƒì„±\n",
    "    vector_store = Chroma.from_documents(\n",
    "        documents=documents,\n",
    "        embedding=embeddings,\n",
    "        collection_name=collection_name,\n",
    "        persist_directory=persist_directory,\n",
    "        collection_metadata={'hnsw:space': 'cosine'}\n",
    "    )\n",
    "    print(f\"âœ… ìƒˆ ë²¡í„° ì €ì¥ì†Œ ìƒì„± ì™„ë£Œ: {vector_store._collection.count()}ê°œ ë¬¸ì„œ\")\n",
    "    return vector_store\n",
    "\n",
    "# ë²¡í„° ì €ì¥ì†Œ ìƒì„±\n",
    "vector_store = create_or_load_vector_store(processed_docs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4.1.2 ì˜ë¯¸ë¡ ì  ê²€ìƒ‰ ì‹¤í–‰"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def semantic_search(vector_store, query, k=5):\n",
    "    \"\"\"\n",
    "    ì˜ë¯¸ë¡ ì  ê²€ìƒ‰ ì‹¤í–‰\n",
    "    \n",
    "    Args:\n",
    "        vector_store: Chroma ë²¡í„° ì €ì¥ì†Œ\n",
    "        query (str): ê²€ìƒ‰ ì¿¼ë¦¬\n",
    "        k (int): ë°˜í™˜í•  ë¬¸ì„œ ìˆ˜\n",
    "    \n",
    "    Returns:\n",
    "        list: ê²€ìƒ‰ëœ Document ê°ì²´ ë¦¬ìŠ¤íŠ¸\n",
    "    \"\"\"\n",
    "    # ê²€ìƒ‰ê¸° ìƒì„±\n",
    "    retriever = vector_store.as_retriever(search_kwargs={\"k\": k})\n",
    "    \n",
    "    # ê²€ìƒ‰ ì‹¤í–‰\n",
    "    results = retriever.invoke(query)\n",
    "        \n",
    "    return results\n",
    "\n",
    "# ê²€ìƒ‰ í…ŒìŠ¤íŠ¸\n",
    "query = \"ë¦¬ë¹„ì•ˆì€ ì–¸ì œ ì„¤ë¦½ë˜ì—ˆë‚˜ìš”?\"\n",
    "semantic_results = semantic_search(vector_store, query, k=3)\n",
    "\n",
    "print(f\"Query: {query}\")\n",
    "print(f\"ê²€ìƒ‰ ê²°ê³¼ ({len(semantic_results)}ê°œ)\")\n",
    "for i, doc in enumerate(semantic_results, 1):\n",
    "    print(f\"\\n[{i}] íšŒì‚¬: {doc.metadata.get('company', 'N/A')}\")\n",
    "    print(f\"ë‚´ìš©:\\n{doc.page_content}\")\n",
    "    print(\"-\" * 50)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.2 í‚¤ì›Œë“œ ê²€ìƒ‰ (Keyword Search)\n",
    "\n",
    "#### 4.2.1 í•œêµ­ì–´ í† í¬ë‚˜ì´ì € ì„¤ì •"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def setup_korean_tokenizer():\n",
    "    \"\"\"\n",
    "    í•œêµ­ì–´ í† í¬ë‚˜ì´ì € ì„¤ì •\n",
    "    \n",
    "    Returns:\n",
    "        Kiwi: í•œêµ­ì–´ í† í¬ë‚˜ì´ì € ê°ì²´\n",
    "    \"\"\"\n",
    "    from kiwipiepy import Kiwi\n",
    "    kiwi = Kiwi()\n",
    "    \n",
    "    # ì‚¬ìš©ì ì •ì˜ ë‹¨ì–´ ì¶”ê°€\n",
    "    custom_words = [\n",
    "        ('ë¦¬ë¹„ì•ˆ', 'NNP'),  # ê³ ìœ ëª…ì‚¬\n",
    "        ('í…ŒìŠ¬ë¼', 'NNP'),  # ê³ ìœ ëª…ì‚¬\n",
    "        ('ì „ê¸°ì°¨', 'NNG'),  # ì¼ë°˜ëª…ì‚¬\n",
    "    ]\n",
    "    \n",
    "    for word, pos in custom_words:\n",
    "        kiwi.add_user_word(word, pos)\n",
    "        print(f\"âœ… ë‹¨ì–´ ì¶”ê°€: {word} ({pos})\")\n",
    "    \n",
    "    return kiwi\n",
    "\n",
    "def korean_tokenizer(text, kiwi_model):\n",
    "    \"\"\"\n",
    "    í•œêµ­ì–´ í† í¬ë‚˜ì´ì € í•¨ìˆ˜\n",
    "    \n",
    "    Args:\n",
    "        text (str): í† í°í™”í•  í…ìŠ¤íŠ¸\n",
    "        kiwi_model: Kiwi ëª¨ë¸ ê°ì²´\n",
    "    \n",
    "    Returns:\n",
    "        list: í† í° ë¦¬ìŠ¤íŠ¸\n",
    "    \"\"\"\n",
    "    return [token.form for token in kiwi_model.tokenize(text)]\n",
    "\n",
    "# í† í¬ë‚˜ì´ì € ì„¤ì •\n",
    "kiwi_model = setup_korean_tokenizer()\n",
    "\n",
    "# í† í°í™” í…ŒìŠ¤íŠ¸\n",
    "test_text = \"ë¦¬ë¹„ì•ˆì€ ì–¸ì œ ì„¤ë¦½ë˜ì—ˆë‚˜ìš”?\"\n",
    "tokens = korean_tokenizer(test_text, kiwi_model)\n",
    "print(f\"ì›ë¬¸: {test_text}\")\n",
    "print(f\"í† í°: {tokens}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4.2.2 BM25 ê²€ìƒ‰ê¸° ìƒì„±\n",
    "- uv pip install rank_bm25"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# BM25 ê²€ìƒ‰ê¸° ìƒì„± (í•œêµ­ì–´ í† í¬ë‚˜ì´ì € ë¯¸ì ìš©)\n",
    "bm25_retriever = BM25Retriever.from_documents(\n",
    "    documents=processed_docs,\n",
    "    k=5\n",
    ")\n",
    "\n",
    "# ê²€ìƒ‰ í…ŒìŠ¤íŠ¸\n",
    "keyword_results = bm25_retriever.invoke(query)\n",
    "\n",
    "print(f\"Query: {query}\")\n",
    "print(f\"ğŸ” ê²€ìƒ‰ ê²°ê³¼ ({len(keyword_results)}ê°œ)\")\n",
    "for i, doc in enumerate(keyword_results, 1):\n",
    "    print(f\"\\n[{i}] íšŒì‚¬: {doc.metadata.get('company', 'N/A')}\")\n",
    "    print(f\"ë‚´ìš©:\\n{doc.page_content}\")\n",
    "    print(\"-\" * 50)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_bm25_retriever(documents, kiwi_model, k=5):\n",
    "    \"\"\"\n",
    "    BM25 ê²€ìƒ‰ê¸° ìƒì„± (í•œêµ­ì–´ í† í¬ë‚˜ì´ì € ì ìš©)\n",
    "    \n",
    "    Args:\n",
    "        documents (list): Document ê°ì²´ ë¦¬ìŠ¤íŠ¸\n",
    "        kiwi_model: Kiwi í† í¬ë‚˜ì´ì €\n",
    "        k (int): ë°˜í™˜í•  ë¬¸ì„œ ìˆ˜\n",
    "    \n",
    "    Returns:\n",
    "        BM25Retriever: BM25 ê²€ìƒ‰ê¸° ê°ì²´\n",
    "    \"\"\"\n",
    "    \n",
    "    # í•œêµ­ì–´ í† í¬ë‚˜ì´ì € ì ìš©\n",
    "    def preprocess_func(text):\n",
    "        return korean_tokenizer(text, kiwi_model)\n",
    "    \n",
    "    # BM25 ê²€ìƒ‰ê¸° ìƒì„±\n",
    "    bm25_retriever = BM25Retriever.from_documents(\n",
    "        documents=documents,\n",
    "        preprocess_func=preprocess_func,\n",
    "        k=k\n",
    "    )\n",
    "    \n",
    "    print(f\"âœ… BM25 ê²€ìƒ‰ê¸° ìƒì„± ì™„ë£Œ: {len(documents)}ê°œ ë¬¸ì„œ ì¸ë±ì‹±\")\n",
    "    return bm25_retriever\n",
    "\n",
    "# BM25 ê²€ìƒ‰ê¸° ìƒì„±\n",
    "bm25_retriever = create_bm25_retriever(processed_docs, kiwi_model, k=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ê²€ìƒ‰ í…ŒìŠ¤íŠ¸\n",
    "keyword_results = bm25_retriever.invoke(query)\n",
    "\n",
    "print(f\"Query: {query}\")\n",
    "print(f\"ğŸ” ê²€ìƒ‰ ê²°ê³¼ ({len(keyword_results)}ê°œ)\")\n",
    "for i, doc in enumerate(keyword_results, 1):\n",
    "    print(f\"\\n[{i}] íšŒì‚¬: {doc.metadata.get('company', 'N/A')}\")\n",
    "    print(f\"ë‚´ìš©:\\n{doc.page_content}\")\n",
    "    print(\"-\" * 50)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4.2.3 BM25 ì ìˆ˜ í™•ì¸"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def analyze_bm25_scores(bm25_retriever, query, kiwi_model, top_k=5):\n",
    "    \"\"\"\n",
    "    BM25 ì ìˆ˜ ë¶„ì„\n",
    "    \n",
    "    Args:\n",
    "        bm25_retriever: BM25 ê²€ìƒ‰ê¸°\n",
    "        query (str): ê²€ìƒ‰ ì¿¼ë¦¬\n",
    "        kiwi_model: Kiwi í† í¬ë‚˜ì´ì €\n",
    "        top_k (int): ìƒìœ„ kê°œ ê²°ê³¼\n",
    "    \"\"\"\n",
    "    # ì¿¼ë¦¬ í† í°í™”\n",
    "    tokenized_query = korean_tokenizer(query, kiwi_model)\n",
    "    print(f\"ì¿¼ë¦¬ í† í°: {tokenized_query}\")\n",
    "    \n",
    "    # BM25 ì ìˆ˜ ê³„ì‚°\n",
    "    doc_scores = bm25_retriever.vectorizer.get_scores(tokenized_query)\n",
    "    \n",
    "    # ì ìˆ˜ ì •ë ¬\n",
    "    doc_scores_sorted = sorted(\n",
    "        enumerate(doc_scores), \n",
    "        key=lambda x: x[1], \n",
    "        reverse=True\n",
    "    )\n",
    "    \n",
    "    print(f\"\\nğŸ“Š ìƒìœ„ {top_k}ê°œ ë¬¸ì„œì˜ BM25 ì ìˆ˜:\")\n",
    "    print(\"-\" * 80)\n",
    "    \n",
    "    for rank, (idx, score) in enumerate(doc_scores_sorted[:top_k], 1):\n",
    "        doc = bm25_retriever.docs[idx]\n",
    "        print(f\"[{rank}] ì ìˆ˜: {score:.4f}\")\n",
    "        print(f\"    íšŒì‚¬: {doc.metadata.get('company', 'N/A')}\")\n",
    "        print(f\"    ë‚´ìš©: {doc.page_content[:200]}...\")\n",
    "        print(\"-\" * 80)\n",
    "\n",
    "# BM25 ì ìˆ˜ ë¶„ì„\n",
    "analyze_bm25_scores(bm25_retriever, query, kiwi_model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.3 í•˜ì´ë¸Œë¦¬ë“œ ê²€ìƒ‰ (Hybrid Search)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_hybrid_retriever(vector_store, bm25_retriever, weights=None):\n",
    "    \"\"\"\n",
    "    í•˜ì´ë¸Œë¦¬ë“œ ê²€ìƒ‰ê¸° ìƒì„±\n",
    "    \n",
    "    Args:\n",
    "        vector_store: ë²¡í„° ì €ì¥ì†Œ\n",
    "        bm25_retriever: BM25 ê²€ìƒ‰ê¸°\n",
    "        weights (list): ê°€ì¤‘ì¹˜ [ì˜ë¯¸ë¡ ì , í‚¤ì›Œë“œ]\n",
    "    \n",
    "    Returns:\n",
    "        EnsembleRetriever: í•˜ì´ë¸Œë¦¬ë“œ ê²€ìƒ‰ê¸°\n",
    "    \"\"\"\n",
    "    if weights is None:\n",
    "        weights = [0.5, 0.5]  # ê¸°ë³¸ê°’: ë™ì¼í•œ ê°€ì¤‘ì¹˜\n",
    "    \n",
    "    # ì˜ë¯¸ë¡ ì  ê²€ìƒ‰ê¸° ìƒì„±\n",
    "    semantic_retriever = vector_store.as_retriever(search_kwargs={\"k\": 5})\n",
    "    \n",
    "    # ì•™ìƒë¸” ê²€ìƒ‰ê¸° ìƒì„±\n",
    "    ensemble_retriever = EnsembleRetriever(\n",
    "        retrievers=[semantic_retriever, bm25_retriever],\n",
    "        weights=weights\n",
    "    )\n",
    "    \n",
    "    print(f\"âœ… í•˜ì´ë¸Œë¦¬ë“œ ê²€ìƒ‰ê¸° ìƒì„± ì™„ë£Œ\")\n",
    "    print(f\"   ê°€ì¤‘ì¹˜: ì˜ë¯¸ë¡ ì  {weights[0]}, í‚¤ì›Œë“œ {weights[1]}\")\n",
    "    \n",
    "    return ensemble_retriever\n",
    "\n",
    "# í•˜ì´ë¸Œë¦¬ë“œ ê²€ìƒ‰ê¸° ìƒì„±\n",
    "hybrid_retriever = create_hybrid_retriever(vector_store, bm25_retriever)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ê²€ìƒ‰ í…ŒìŠ¤íŠ¸\n",
    "hybrid_results = hybrid_retriever.invoke(query)\n",
    "\n",
    "print(f\"Query: {query}\")\n",
    "print(f\"ğŸ” ê²€ìƒ‰ ê²°ê³¼ ({len(hybrid_results)}ê°œ)\")\n",
    "for i, doc in enumerate(hybrid_results, 1):\n",
    "    print(f\"\\n[{i}] íšŒì‚¬: {doc.metadata.get('company', 'N/A')}\")\n",
    "    print(f\"ë‚´ìš©:\\n{doc.page_content}\")\n",
    "    print(\"-\" * 50)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## 5. í‰ê°€ ë° ë¹„êµ\n",
    "\n",
    "### 5.1 í‰ê°€ ë°ì´í„°ì…‹ ì¤€ë¹„"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_evaluation_dataset(file_path):\n",
    "    \"\"\"\n",
    "    í‰ê°€ ë°ì´í„°ì…‹ ë¡œë“œ\n",
    "    \n",
    "    Args:\n",
    "        file_path (str): í‰ê°€ ë°ì´í„° íŒŒì¼ ê²½ë¡œ\n",
    "    \n",
    "    Returns:\n",
    "        pandas.DataFrame: í‰ê°€ ë°ì´í„°ì…‹\n",
    "    \"\"\"\n",
    "    try:\n",
    "        if file_path.endswith('.xlsx'):\n",
    "            df = pd.read_excel(file_path)\n",
    "        elif file_path.endswith('.csv'):\n",
    "            df = pd.read_csv(file_path)\n",
    "        else:\n",
    "            raise ValueError(\"ì§€ì›í•˜ì§€ ì•ŠëŠ” íŒŒì¼ í˜•ì‹\")\n",
    "        \n",
    "        print(f\"âœ… í‰ê°€ ë°ì´í„°ì…‹ ë¡œë“œ: {len(df)}ê°œ ì§ˆë¬¸\")\n",
    "        return df\n",
    "    except Exception as e:\n",
    "        print(f\"âŒ ë°ì´í„°ì…‹ ë¡œë“œ ì‹¤íŒ¨: {e}\")\n",
    "        return None\n",
    "\n",
    "# í‰ê°€ ë°ì´í„°ì…‹ ë¡œë“œ\n",
    "\n",
    "eval_df = load_evaluation_dataset(\"./data/synthetic_testset.csv\")\n",
    "eval_df.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_evaluation_data(df):\n",
    "    \"\"\"\n",
    "    í‰ê°€ ë°ì´í„° ì „ì²˜ë¦¬\n",
    "    \n",
    "    Args:\n",
    "        df (pandas.DataFrame): ì›ë³¸ ë°ì´í„°í”„ë ˆì„\n",
    "    \n",
    "    Returns:\n",
    "        tuple: (ì§ˆë¬¸ ë¦¬ìŠ¤íŠ¸, ì •ë‹µ ë¬¸ì„œ ë¦¬ìŠ¤íŠ¸)\n",
    "    \"\"\"\n",
    "    questions = df['user_input'].tolist()\n",
    "    \n",
    "    # ì •ë‹µ ë¬¸ì„œ íŒŒì‹±\n",
    "    reference_contexts = []\n",
    "    for contexts in df['reference_contexts']:\n",
    "        if isinstance(contexts, str):\n",
    "            # ë¬¸ìì—´ì„ ë¦¬ìŠ¤íŠ¸ë¡œ ë³€í™˜\n",
    "            context_list = eval(contexts)\n",
    "        else:\n",
    "            context_list = contexts\n",
    "        \n",
    "        # Document ê°ì²´ë¡œ ë³€í™˜\n",
    "        docs = [Document(page_content=ctx) for ctx in context_list]\n",
    "        reference_contexts.append(docs)\n",
    "    \n",
    "    return questions, reference_contexts\n",
    "\n",
    "# í‰ê°€ ë°ì´í„° ì „ì²˜ë¦¬\n",
    "questions, reference_contexts = prepare_evaluation_data(eval_df)\n",
    "\n",
    "# í‰ê°€ ë°ì´í„° í™•ì¸\n",
    "for i, (q, refs) in enumerate(zip(questions[:3], reference_contexts[:3])):\n",
    "    print(f\"\\n[ì§ˆë¬¸ {i+1}]\")\n",
    "    print(f\"ì§ˆë¬¸: {q}\")\n",
    "    print(f\"ì •ë‹µ ë¬¸ì„œ: {len(refs)}ê°œ\")\n",
    "    for j, ref in enumerate(refs):\n",
    "        print(f\"  [{j+1}] ë‚´ìš©: {ref.page_content[:50]}...\")  # ë‚´ìš© ì¼ë¶€ë§Œ ì¶œë ¥\n",
    "    print(\"-\" * 50)\n",
    "\n",
    "# í‰ê°€ ë°ì´í„° í™•ì¸\n",
    "for i, (q, refs) in enumerate(zip(questions[-3:], reference_contexts[-3:])):\n",
    "    print(f\"\\n[ì§ˆë¬¸ {i+1}]\")\n",
    "    print(f\"ì§ˆë¬¸: {q}\")\n",
    "    print(f\"ì •ë‹µ ë¬¸ì„œ: {len(refs)}ê°œ\")\n",
    "    for j, ref in enumerate(refs):\n",
    "        print(f\"  [{j+1}] ë‚´ìš©: {ref.page_content[:50]}...\")  # ë‚´ìš© ì¼ë¶€ë§Œ ì¶œë ¥\n",
    "    print(\"-\" * 50)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.2 ranx-k ë¼ì´ë¸ŒëŸ¬ë¦¬ í™œìš©í•œ í‰ê°€\n",
    "\n",
    "- ROUGE ì ìˆ˜ ê¸°ë°˜ í‰ê°€ \n",
    "- ì•„ì´ë””ì–´: í…ìŠ¤íŠ¸ ì˜¤ë²„ë©ì„ í†µí•œ ì§ì ‘ì  ìœ ì‚¬ë„ ì¸¡ì •\n",
    "\n",
    "- **ranx-k ì„¤ì¹˜ ë°©ë²•**\n",
    "\n",
    "    ```bash\n",
    "    # ranx-k ë¼ì´ë¸ŒëŸ¬ë¦¬ ì„¤ì¹˜\n",
    "    uv pip install ranx-k\n",
    "    ```\n",
    "\n",
    "- **ranx ì´ìŠˆ ì‚¬í•­**\n",
    "\n",
    "    - **ID ë§¤ì¹­ ì˜ì¡´ì„±**: ì •í™•í•œ ë¬¸ì„œ ID ì¼ì¹˜ê°€ í•„ìš”\n",
    "    - **ì˜ë¯¸ì  ìœ ì‚¬ë„ ë¬´ì‹œ**: ë‚´ìš©ì´ ë¹„ìŠ·í•´ë„ IDê°€ ë‹¤ë¥´ë©´ 0ì \n",
    "    - **ì²­í‚¹ ë°©ì‹ ë³€í™” ëŒ€ì‘ ë¶ˆê°€**: ì²­í¬ í¬ê¸°ë‚˜ ë°©ì‹ì´ ë°”ë€Œë©´ í‰ê°€ ë¶ˆê°€ëŠ¥\n",
    "    - **ì‹¤ì œ ì‚¬ìš© í™˜ê²½ê³¼ ê´´ë¦¬**: ì‹¤ì œë¡œëŠ” ì˜ë¯¸ì  ê´€ë ¨ì„±ì´ ì¤‘ìš”"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ranx_k.evaluation import evaluate_with_ranx_similarity\n",
    "\n",
    "# ranx-k í‰ê°€ ì‹¤í–‰ (rouge ì ìˆ˜ê°€ ë†’ì€ ê²½ìš°) -> ë¬¸ìì—´ ìœ ì‚¬ë„ ê¸°ë°˜ í‰ê°€\n",
    "ranx_k_results = evaluate_with_ranx_similarity(\n",
    "    retriever=hybrid_retriever,\n",
    "    questions=questions,\n",
    "    reference_contexts=reference_contexts,\n",
    "    k=5,\n",
    "    method='kiwi_rouge',  \n",
    "    similarity_threshold=0.8,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ranx-k í‰ê°€ ì‹¤í–‰ (embedding ì ìˆ˜ê°€ ë†’ì€ ê²½ìš°) -> ì˜ë¯¸ì  ìœ ì‚¬ë„ ê¸°ë°˜ í‰ê°€\n",
    "ranx_k_results = evaluate_with_ranx_similarity(\n",
    "    retriever=hybrid_retriever,\n",
    "    questions=questions,\n",
    "    reference_contexts=reference_contexts,\n",
    "    k=5,\n",
    "    method='embedding',  \n",
    "    embedding_model=\"BAAI/bge-m3\",\n",
    "    similarity_threshold=0.9\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.4 ê²€ìƒ‰ ë°©ë²• ë¹„êµ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compare_retrieval_methods(vector_store, bm25_retriever, questions, reference_contexts, k=5):\n",
    "    \"\"\"\n",
    "    ë‹¤ì–‘í•œ ê²€ìƒ‰ ë°©ë²• ì„±ëŠ¥ ë¹„êµ\n",
    "    \n",
    "    Args:\n",
    "        vector_store: ë²¡í„° ì €ì¥ì†Œ\n",
    "        bm25_retriever: BM25 ê²€ìƒ‰ê¸°\n",
    "        questions (list): ì§ˆë¬¸ ë¦¬ìŠ¤íŠ¸\n",
    "        reference_contexts (list): ì •ë‹µ ë¬¸ì„œ ë¦¬ìŠ¤íŠ¸\n",
    "        k (int): í‰ê°€í•  ìƒìœ„ kê°œ ê²°ê³¼\n",
    "    \n",
    "    Returns:\n",
    "        pandas.DataFrame: ë¹„êµ ê²°ê³¼\n",
    "    \"\"\"\n",
    "    results = []\n",
    "    \n",
    "    # ê²€ìƒ‰ ë°©ë²•ë“¤ ì •ì˜\n",
    "    bm25_retriever.k = k\n",
    "    retrievers = {\n",
    "        \"ì˜ë¯¸ë¡ ì  ê²€ìƒ‰\": vector_store.as_retriever(search_kwargs={\"k\": k}),\n",
    "        \"í‚¤ì›Œë“œ ê²€ìƒ‰\": bm25_retriever,\n",
    "        \"í•˜ì´ë¸Œë¦¬ë“œ (5:5)\": create_hybrid_retriever(vector_store, bm25_retriever, [0.5, 0.5]),\n",
    "        \"í•˜ì´ë¸Œë¦¬ë“œ (7:3)\": create_hybrid_retriever(vector_store, bm25_retriever, [0.7, 0.3]),\n",
    "        \"í•˜ì´ë¸Œë¦¬ë“œ (3:7)\": create_hybrid_retriever(vector_store, bm25_retriever, [0.3, 0.7]),\n",
    "    }\n",
    "    \n",
    "    for method_name, retriever in retrievers.items():\n",
    "        print(f\"ğŸ”„ {method_name} í‰ê°€ ì¤‘...\")\n",
    "        \n",
    "        # ranx-k í‰ê°€ ì‹¤í–‰ (rouge ì ìˆ˜ê°€ ë†’ì€ ê²½ìš°) -> ë¬¸ìì—´ ìœ ì‚¬ë„ ê¸°ë°˜ í‰ê°€\n",
    "        ranx_k_results = evaluate_with_ranx_similarity(\n",
    "            retriever=retriever,\n",
    "            questions=questions,\n",
    "            reference_contexts=reference_contexts,\n",
    "            k=k,\n",
    "            method='kiwi_rouge',  \n",
    "            similarity_threshold=0.8,\n",
    "        )\n",
    "        \n",
    "        # í‰ê°€ ê²°ê³¼ ì •ë¦¬ \n",
    "        result = {\n",
    "            \"method\": method_name,\n",
    "            \"hit_rate\": ranx_k_results.get(\"hit_rate@5\", 0),\n",
    "            \"ndcg\": ranx_k_results.get(\"ndcg@5\", 0),\n",
    "            \"map\": ranx_k_results.get(\"map@5\", 0),\n",
    "            \"mrr\": ranx_k_results.get(\"mrr\", 0),\n",
    "        }\n",
    "\n",
    "        results.append(result)\n",
    "\n",
    "    # ê²°ê³¼ DataFrame ìƒì„±\n",
    "    results_df = pd.DataFrame(results)\n",
    "    results_df.set_index(\"method\", inplace=True)\n",
    "    results_df.sort_values(by=\"hit_rate\", ascending=False, inplace=True)\n",
    "\n",
    "    return results_df\n",
    "\n",
    "\n",
    "# ê²€ìƒ‰ ë°©ë²• ì„±ëŠ¥ ë¹„êµ\n",
    "comparison_results = compare_retrieval_methods(vector_store, bm25_retriever, questions, reference_contexts, k=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "comparison_results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.5 ì‹œê°í™”"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def visualize_comparison_results(comparison_df):\n",
    "    \"\"\"\n",
    "    ê²€ìƒ‰ ë°©ë²• ë¹„êµ ê²°ê³¼ ì‹œê°í™”\n",
    "    \n",
    "    Args:\n",
    "        comparison_df (pandas.DataFrame): ë¹„êµ ê²°ê³¼ ë°ì´í„°í”„ë ˆì„\n",
    "\n",
    "        result = {\n",
    "            \"method\": method_name,\n",
    "            \"hit_rate\": ranx_k_results.get(\"hit_rate@5\", 0),\n",
    "            \"ndcg\": ranx_k_results.get(\"ndcg@5\", 0),\n",
    "            \"map\": ranx_k_results.get(\"map@5\", 0),\n",
    "            \"mrr\": ranx_k_results.get(\"mrr\", 0),\n",
    "        }\n",
    "\n",
    "    \"\"\"\n",
    "    \n",
    "    # ê·¸ë˜í”„ ìƒì„±\n",
    "    fig, ax = plt.subplots(1, 4, figsize=(12, 8))\n",
    "    sns.barplot(x=comparison_df.index, y='hit_rate', data=comparison_df, ax=ax[0])\n",
    "    ax[0].set_title('Hit Rate@5')\n",
    "    ax[0].set_ylabel('Hit Rate')\n",
    "    ax[0].set_xlabel('Retrieval Method')        \n",
    "    ax[0].tick_params(axis='x', rotation=45)\n",
    "\n",
    "    sns.barplot(x=comparison_df.index, y='ndcg', data=comparison_df, ax=ax[1])\n",
    "    ax[1].set_title('NDCG@5')\n",
    "    ax[1].set_ylabel('NDCG')\n",
    "    ax[1].set_xlabel('Retrieval Method')\n",
    "    ax[1].tick_params(axis='x', rotation=45)                \n",
    "\n",
    "    sns.barplot(x=comparison_df.index, y='map', data=comparison_df, ax=ax[2])\n",
    "    ax[2].set_title('MAP@5')\n",
    "    ax[2].set_ylabel('MAP')         \n",
    "    ax[2].set_xlabel('Retrieval Method')\n",
    "    ax[2].tick_params(axis='x', rotation=45)    \n",
    "\n",
    "    sns.barplot(x=comparison_df.index, y='mrr', data=comparison_df, ax=ax[3])\n",
    "    ax[3].set_title('MRR')\n",
    "    ax[3].set_ylabel('MRR')\n",
    "    ax[3].set_xlabel('Retrieval Method')\n",
    "    ax[3].tick_params(axis='x', rotation=45)\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "    # ê·¸ë˜í”„ ì¶œë ¥\n",
    "    plt.savefig(\"retrieval_comparison_results.png\")\n",
    "\n",
    "# ê²€ìƒ‰ ë°©ë²• ë¹„êµ ê²°ê³¼ ì‹œê°í™”\n",
    "visualize_comparison_results(comparison_results)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## 6. ì‹¤ìŠµ ë¬¸ì œ\n",
    "\n",
    "**ëª©í‘œ**: ê¸°ë³¸ì ì¸ í•˜ì´ë¸Œë¦¬ë“œ ê²€ìƒ‰ ì‹œìŠ¤í…œì„ êµ¬ì¶•í•˜ê³  í…ŒìŠ¤íŠ¸í•´ë³´ì„¸ìš”.\n",
    "\n",
    "**ë¬¸ì œ**:\n",
    "1. ì œê³µëœ í…ìŠ¤íŠ¸ ë°ì´í„°ë¥¼ ì‚¬ìš©í•˜ì—¬ ë²¡í„° ì €ì¥ì†Œì™€ BM25 ê²€ìƒ‰ê¸°ë¥¼ ìƒì„±í•˜ì„¸ìš”.\n",
    "2. ë™ì¼í•œ ê°€ì¤‘ì¹˜(0.5, 0.5)ë¡œ í•˜ì´ë¸Œë¦¬ë“œ ê²€ìƒ‰ê¸°ë¥¼ ë§Œë“œì„¸ìš”.\n",
    "3. ë‹¤ìŒ ì§ˆë¬¸ë“¤ì— ëŒ€í•´ ê²€ìƒ‰ì„ ìˆ˜í–‰í•˜ê³  ê²°ê³¼ë¥¼ ë¹„êµí•˜ì„¸ìš”:\n",
    "   - \"í…ŒìŠ¬ë¼ì˜ ì „ê¸°ì°¨ ëª¨ë¸ì€ ì–´ë–¤ ê²ƒë“¤ì´ ìˆë‚˜ìš”?\"\n",
    "   - \"ë¦¬ë¹„ì•ˆì˜ ê²½ìŸë ¥ì€ ë¬´ì—‡ì¸ê°€ìš”?\"\n",
    "   - \"í…ŒìŠ¬ë¼ì™€ ë¦¬ë¹„ì•ˆì´ ê²½ìŸí•˜ëŠ” ë¶„ì•¼ëŠ” ë¬´ì—‡ì¸ê°€ìš”?\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ì—¬ê¸°ì— ì½”ë“œë¥¼ ì‘ì„±í•˜ì„¸ìš”\n",
    "\n",
    "# 1. ë°ì´í„° ë¡œë“œ ë° ì „ì²˜ë¦¬\n",
    "\n",
    "# 2. ë²¡í„° ì €ì¥ì†Œ ìƒì„±\n",
    "\n",
    "# 3. BM25 ê²€ìƒ‰ê¸° ìƒì„±\n",
    "\n",
    "# 4. í•˜ì´ë¸Œë¦¬ë“œ ê²€ìƒ‰ê¸° ìƒì„±\n",
    "\n",
    "# 5. ê²€ìƒ‰ í…ŒìŠ¤íŠ¸\n",
    "queries = [\n",
    "    \"í…ŒìŠ¬ë¼ì˜ ì „ê¸°ì°¨ ëª¨ë¸ì€ ì–´ë–¤ ê²ƒë“¤ì´ ìˆë‚˜ìš”?\",\n",
    "    \"ë¦¬ë¹„ì•ˆì˜ ê²½ìŸë ¥ì€ ë¬´ì—‡ì¸ê°€ìš”?\",\n",
    "    \"í…ŒìŠ¬ë¼ì™€ ë¦¬ë¹„ì•ˆì´ ê²½ìŸí•˜ëŠ” ë¶„ì•¼ëŠ” ë¬´ì—‡ì¸ê°€ìš”?\"\n",
    "]\n",
    "\n",
    "for query in queries:\n",
    "    print(f\"ì§ˆë¬¸: {query}\")\n",
    "    # ê²€ìƒ‰ ìˆ˜í–‰ ë° ê²°ê³¼ ì¶œë ¥\n",
    "    pass"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
