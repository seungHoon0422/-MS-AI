{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#  RAG ì„±ëŠ¥ í‰ê°€\n",
    "\n",
    "---\n",
    "\n",
    "\n",
    "## 1. ê°œìš” ë° í™˜ê²½ ì„¤ì •\n",
    "\n",
    "### 1.1 RAG í‰ê°€ê°€ ì¤‘ìš”í•œ ì´ìœ \n",
    "\n",
    "- **RAG(Retrieval-Augmented Generation)** ì‹œìŠ¤í…œì€ ì™¸ë¶€ ì§€ì‹ì„ ê²€ìƒ‰í•˜ì—¬ LLMì˜ ì‘ë‹µ í’ˆì§ˆì„ í–¥ìƒì‹œí‚¤ëŠ” ê¸°ìˆ \n",
    "- RAG ì‹œìŠ¤í…œì˜ ì„±ëŠ¥ì„ ê°ê´€ì ìœ¼ë¡œ ì¸¡ì •í•˜ê³  ê°œì„ í•˜ê¸° ìœ„í•´ì„œëŠ” ì²´ê³„ì ì¸ í‰ê°€ê°€ í•„ìš”\n",
    "\n",
    "<center>\n",
    "<img src=\"https://raw.githubusercontent.com/tsdata/image_files/main/202505/rag_evaluation.png\" alt=\"rag\" align=\"center\" border=\"0\"  width=\"1000\" height=auto>\n",
    "</center>\n",
    "\n",
    "[ì¶œì²˜] https://arxiv.org/abs/2405.07437\n",
    "\n",
    "### 1.2 í™˜ê²½ ì„¤ì •\n",
    "\n",
    "- uv add seaborn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# í™˜ê²½ë³€ìˆ˜ ì„¤ì •\n",
    "from dotenv import load_dotenv\n",
    "import os\n",
    "load_dotenv()\n",
    "\n",
    "# ê¸°ë³¸ ë¼ì´ë¸ŒëŸ¬ë¦¬\n",
    "import json\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from pprint import pprint\n",
    "from glob import glob\n",
    "\n",
    "# LangSmith ì¶”ì  ì„¤ì • (ì„ íƒì‚¬í•­)\n",
    "print(f\"LangSmith ì¶”ì : {os.getenv('LANGSMITH_TRACING')}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## 2. RAG í‰ê°€ì˜ í•µì‹¬ ê°œë…\n",
    "\n",
    "- **í‰ê°€ ì§€í‘œ**\n",
    "\n",
    "   | í‰ê°€ ì˜ì—­ | ì„¸ë¶€ ì§€í‘œ | ì„¤ëª… |\n",
    "   |-----------|-----------|------|\n",
    "   | **ê²€ìƒ‰ (Retrieval)** | Context Relevancy | ê²€ìƒ‰ëœ ë¬¸ì„œê°€ ì§ˆë¬¸ê³¼ ì–¼ë§ˆë‚˜ ê´€ë ¨ìˆëŠ”ê°€? |\n",
    "   |  | Context Recall | ì •ë‹µì— í•„ìš”í•œ ëª¨ë“  ì •ë³´ê°€ ê²€ìƒ‰ë˜ì—ˆëŠ”ê°€? |\n",
    "   | **ìƒì„± (Generation)** | Faithfulness | ìƒì„±ëœ ë‹µë³€ì´ ê²€ìƒ‰ëœ ë¬¸ì„œì— ì¶©ì‹¤í•œê°€? |\n",
    "   |  | Answer Relevancy | ìƒì„±ëœ ë‹µë³€ì´ ì§ˆë¬¸ê³¼ ê´€ë ¨ìˆëŠ”ê°€? |\n",
    "   | **ì¢…í•©** | Answer Correctness | ìƒì„±ëœ ë‹µë³€ì´ ì •ë‹µê³¼ ì¼ì¹˜í•˜ëŠ”ê°€? |\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- **í‰ê°€ ë°©ë²•ë¡ **\n",
    "\n",
    "   1. Reference-Free í‰ê°€\n",
    "      - **ì¥ì **: ì •ë‹µ ë°ì´í„° ì—†ì´ë„ í‰ê°€ ê°€ëŠ¥\n",
    "      - **ë°©ë²•**: LLM-as-Judge ë°©ì‹ í™œìš©\n",
    "      - **ë„êµ¬**: RAGAS, LangSmith ë“±\n",
    "\n",
    "   1. Reference-Based í‰ê°€\n",
    "      - **ì¥ì **: ê°ê´€ì ì´ê³  ì¼ê´€ëœ í‰ê°€\n",
    "      - **ë°©ë²•**: ì •ë‹µê³¼ ë¹„êµí•˜ì—¬ í‰ê°€\n",
    "      - **ì§€í‘œ**: BLEU, ROUGE, Semantic Similarity ë“±"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## 3. í‰ê°€ ëŒ€ìƒ: ê¸°ë³¸ RAG ì‹œìŠ¤í…œ êµ¬ì¶•\n",
    "\n",
    "### 3.1 ë¬¸ì„œ ì¤€ë¹„ ë° ì²˜ë¦¬"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_community.document_loaders import TextLoader\n",
    "from langchain_text_splitters import RecursiveCharacterTextSplitter\n",
    "\n",
    "def load_documents(file_paths):\n",
    "    \"\"\"í…ìŠ¤íŠ¸ íŒŒì¼ë“¤ì„ ë¡œë“œí•˜ëŠ” í•¨ìˆ˜\"\"\"\n",
    "    documents = []\n",
    "    for path in file_paths:\n",
    "        try:\n",
    "            loader = TextLoader(path, encoding='utf-8')\n",
    "            documents.extend(loader.load())\n",
    "        except Exception as e:\n",
    "            print(f\"íŒŒì¼ ë¡œë“œ ì‹¤íŒ¨ {path}: {e}\")\n",
    "    return documents\n",
    "\n",
    "# ì˜ˆì‹œ: í•œêµ­ì–´ ë¬¸ì„œ ë¡œë“œ\n",
    "korean_files = glob('./data/*_KR.md')\n",
    "documents = load_documents(korean_files)\n",
    "\n",
    "print(f\"ë¡œë“œëœ ë¬¸ì„œ ìˆ˜: {len(documents)}\")\n",
    "if documents:\n",
    "    print(f\"ì²« ë²ˆì§¸ ë¬¸ì„œ ë¯¸ë¦¬ë³´ê¸°:\\n{documents[0].page_content[:200]}...\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.2 ë¬¸ì„œ ë¶„í•  (Text Splitting)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# í•œêµ­ì–´ í…ìŠ¤íŠ¸ì— ìµœì í™”ëœ ë¶„í• ê¸° ì„¤ì •\n",
    "text_splitter = RecursiveCharacterTextSplitter.from_tiktoken_encoder(\n",
    "    encoding_name=\"cl100k_base\",\n",
    "    separators=['\\n\\n', '\\n', r'(?<=[.!?])\\s+'],  # ë¬¸ì¥ ë‹¨ìœ„ ë¶„í• \n",
    "    chunk_size=300,           # ì²­í¬ í¬ê¸°\n",
    "    chunk_overlap=0,         # ì¤‘ë³µ ì˜ì—­\n",
    "    is_separator_regex=True,  # ì •ê·œì‹ ì‚¬ìš©\n",
    "    keep_separator=True       # êµ¬ë¶„ì ìœ ì§€\n",
    ")\n",
    "\n",
    "# ë¬¸ì„œ ë¶„í•  ì‹¤í–‰\n",
    "split_docs = text_splitter.split_documents(documents)\n",
    "\n",
    "print(f\"ë¶„í• ëœ ì²­í¬ ìˆ˜: {len(split_docs)}\")\n",
    "print(f\"\\nì²« ë²ˆì§¸ ì²­í¬:\")\n",
    "print(f\"ë©”íƒ€ë°ì´í„°: {split_docs[0].metadata}\")\n",
    "print(f\"ë‚´ìš©: {split_docs[0].page_content}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.3 ë²¡í„° ìŠ¤í† ì–´ ìƒì„±"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_chroma import Chroma\n",
    "from langchain_openai import OpenAIEmbeddings\n",
    "\n",
    "# ì„ë² ë”© ëª¨ë¸ ì´ˆê¸°í™”\n",
    "embedding_model = OpenAIEmbeddings(\n",
    "    model=\"text-embedding-3-small\",\n",
    "    dimensions=1536  # ì„ íƒì‚¬í•­: ì°¨ì› ì¶•ì†Œë¡œ ì„±ëŠ¥ í–¥ìƒ\n",
    ")\n",
    "\n",
    "# Chroma ë²¡í„° ìŠ¤í† ì–´ ìƒì„±\n",
    "vector_store = Chroma.from_documents(\n",
    "    documents=split_docs,\n",
    "    embedding=embedding_model,\n",
    "    collection_name=\"rag_evaluation_demo\",\n",
    "    persist_directory=\"./local_chroma_db\",\n",
    "    collection_metadata={'hnsw:space': 'cosine'}  # ì½”ì‚¬ì¸ ìœ ì‚¬ë„ ì‚¬ìš©\n",
    ")\n",
    "\n",
    "print(f\"ë²¡í„° ìŠ¤í† ì–´ì— ì €ì¥ëœ ë¬¸ì„œ ìˆ˜: {vector_store._collection.count()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.4 RAG ì²´ì¸ êµ¬ì„±\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_openai import ChatOpenAI, OpenAIEmbeddings\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "from langchain_chroma import Chroma\n",
    "\n",
    "# LLM ì´ˆê¸°í™”\n",
    "llm = ChatOpenAI(\n",
    "    model=\"gpt-4.1-mini\",  # ë¹„ìš© íš¨ìœ¨ì ì¸ ëª¨ë¸\n",
    "    temperature=0,        # ì¼ê´€ëœ ê²°ê³¼ë¥¼ ìœ„í•´ 0ìœ¼ë¡œ ì„¤ì •\n",
    ")\n",
    "\n",
    "# ì„ë² ë”© ëª¨ë¸ ì´ˆê¸°í™”\n",
    "embedding_model = OpenAIEmbeddings(\n",
    "    model=\"text-embedding-3-small\",\n",
    "    dimensions=1536  # ì„ íƒì‚¬í•­: ì°¨ì› ì¶•ì†Œë¡œ ì„±ëŠ¥ í–¥ìƒ\n",
    ")\n",
    "\n",
    "# Chroma ë²¡í„° ìŠ¤í† ì–´ ë¡œë“œ\n",
    "vector_store = Chroma(\n",
    "    collection_name=\"rag_evaluation_demo\",\n",
    "    persist_directory=\"./local_chroma_db\",\n",
    "    embedding_function=embedding_model\n",
    ")\n",
    "\n",
    "print(f\"ë²¡í„° ìŠ¤í† ì–´ì— ì €ì¥ëœ ë¬¸ì„œ ìˆ˜: {vector_store._collection.count()}\")\n",
    "\n",
    "# ê²€ìƒ‰ê¸° ì„¤ì •\n",
    "retriever = vector_store.as_retriever(\n",
    "    search_type=\"similarity\",\n",
    "    search_kwargs={\"k\": 5}  # ìƒìœ„ 5ê°œ ë¬¸ì„œ ê²€ìƒ‰\n",
    ")\n",
    "\n",
    "# í”„ë¡¬í”„íŠ¸ í…œí”Œë¦¿\n",
    "prompt_template = ChatPromptTemplate.from_template(\"\"\"\n",
    "ë‹¤ìŒ ì»¨í…ìŠ¤íŠ¸ë¥¼ ë°”íƒ•ìœ¼ë¡œ ì§ˆë¬¸ì— ë‹µí•˜ì„¸ìš”. \n",
    "ì»¨í…ìŠ¤íŠ¸ì— ì—†ëŠ” ì •ë³´ëŠ” ì¶”ì¸¡í•˜ì§€ ë§ˆì„¸ìš”.\n",
    "\n",
    "<context>\n",
    "{context}\n",
    "</context>\n",
    "\n",
    "<question>\n",
    "{question}\n",
    "</question>\n",
    "\"\"\")\n",
    "\n",
    "# RAG ì²´ì¸ êµ¬ì„±\n",
    "def format_docs(docs):\n",
    "    \"\"\"ë¬¸ì„œ ë¦¬ìŠ¤íŠ¸ë¥¼ ë¬¸ìì—´ë¡œ ë³€í™˜\"\"\"\n",
    "    return \"\\n\\n\".join(doc.page_content for doc in docs)\n",
    "\n",
    "def rag_chain(question: str) -> dict:\n",
    "    \"\"\"RAG ì²´ì¸ ì‹¤í–‰ í•¨ìˆ˜\"\"\"\n",
    "\n",
    "    # ë¬¸ì„œ ê²€ìƒ‰\n",
    "    retrieved_docs = retriever.invoke(question)\n",
    "    \n",
    "    # ì»¨í…ìŠ¤íŠ¸ ì¤€ë¹„\n",
    "    context = format_docs(retrieved_docs)\n",
    "    \n",
    "    # LLMìœ¼ë¡œ ë‹µë³€ ìƒì„±\n",
    "    response = llm.invoke(\n",
    "        prompt_template.format_prompt(\n",
    "            context=context, \n",
    "            question=question\n",
    "        )\n",
    "    ).content\n",
    "    \n",
    "    return {\n",
    "        \"question\": question,\n",
    "        \"context\": context,\n",
    "        \"answer\": response,\n",
    "        \"retrieved_docs\": retrieved_docs\n",
    "    }\n",
    "\n",
    "# í…ŒìŠ¤íŠ¸ ì‹¤í–‰\n",
    "test_question = \"ë¦¬ë¹„ì•ˆì˜ ì„¤ë¦½ìëŠ” ëˆ„êµ¬ì¸ê°€ìš”?\"\n",
    "result = rag_chain(test_question)\n",
    "\n",
    "print(f\"ì§ˆë¬¸: {result['question']}\")\n",
    "print(f\"ë‹µë³€: {result['answer']}\")\n",
    "print(f\"ê²€ìƒ‰ëœ ë¬¸ì„œ ìˆ˜: {len(result['retrieved_docs'])}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## 4. í‰ê°€ ë°ì´í„°ì…‹ í•©ì„±"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.1 RAGAS ì‚¬ìš© ë°ì´í„° í•©ì„±\n",
    "\n",
    "- uv add ragas==0.3.1 rapidfuzz\n",
    "\n",
    "- RAGAS í”„ë ˆì„ì›Œí¬ ì†Œê°œ\n",
    "\n",
    "    - **RAGAS (Retrieval-Augmented Generation Assessment)** ëŠ” RAG ì‹œìŠ¤í…œì„ ìœ„í•œ ì˜¤í”ˆì†ŒìŠ¤ í‰ê°€ í”„ë ˆì„ì›Œí¬\n",
    "    - **ì£¼ìš” íŠ¹ì§•**\n",
    "        - âœ… **Reference-Free**: ì •ë‹µ ì—†ì´ë„ í‰ê°€ ê°€ëŠ¥\n",
    "        - âœ… **LLM-as-Judge**: GPT-4 ë“±ì„ í™œìš©í•œ ìë™ í‰ê°€\n",
    "        - âœ… **êµ¬ì„±ìš”ì†Œë³„ í‰ê°€**: ê²€ìƒ‰ê³¼ ìƒì„±ì„ ê°œë³„ì ìœ¼ë¡œ í‰ê°€\n",
    "        - âœ… **LangChain í†µí•©**: ê¸°ì¡´ RAG íŒŒì´í”„ë¼ì¸ê³¼ ì‰½ê²Œ ì—°ë™\n",
    "\n",
    "    - ì£¼ìš” ì§€í‘œ\n",
    "        - **Context Relevancy**: ê²€ìƒ‰ëœ ë¬¸ì„œê°€ ì§ˆë¬¸ê³¼ ì–¼ë§ˆë‚˜ ê´€ë ¨ìˆëŠ”ì§€ ì¸¡ì •\n",
    "        - **Context Recall**: ì •ë‹µ ìƒì„±ì— í•„ìš”í•œ ì •ë³´ê°€ ì–¼ë§ˆë‚˜ ê²€ìƒ‰ë˜ì—ˆëŠ”ì§€ ì¸¡ì •\n",
    "        - **Faithfulness**: ìƒì„±ëœ ë‹µë³€ì´ ê²€ìƒ‰ëœ ë¬¸ì„œì— ì–¼ë§ˆë‚˜ ì¶©ì‹¤í•œì§€ ì¸¡ì •\n",
    "        - **Answer Relevancy**: ìƒì„±ëœ ë‹µë³€ì´ ì§ˆë¬¸ê³¼ ì–¼ë§ˆë‚˜ ê´€ë ¨ìˆëŠ”ì§€ ì¸¡ì •\n",
    "        - **Answer Correctness**: ìƒì„±ëœ ë‹µë³€ì´ ì •ë‹µê³¼ ì–¼ë§ˆë‚˜ ì¼ì¹˜í•˜ëŠ”ì§€ ì¸¡ì •\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ragas.testset import TestsetGenerator\n",
    "from ragas.testset.persona import Persona\n",
    "from ragas.llms import LangchainLLMWrapper\n",
    "from ragas.embeddings import LangchainEmbeddingsWrapper\n",
    "\n",
    "# LLMê³¼ ì„ë² ë”© ë˜í¼ ì„¤ì •\n",
    "generator_llm = LangchainLLMWrapper(\n",
    "    ChatOpenAI(model=\"gpt-4.1-mini\", temperature=0.2)\n",
    ")\n",
    "generator_embeddings = LangchainEmbeddingsWrapper(\n",
    "    OpenAIEmbeddings(model=\"text-embedding-3-small\")\n",
    ")\n",
    "\n",
    "# í•œêµ­ì–´ í˜ë¥´ì†Œë‚˜ ì •ì˜ \n",
    "personas = [\n",
    "    Persona(\n",
    "        name=\"graduate_researcher\",\n",
    "        role_description=\"\"\"ë¯¸êµ­ ì „ê¸°ì°¨ ì‹œì¥ì„ ì—°êµ¬í•˜ëŠ” í•œêµ­ì¸ ë°•ì‚¬ê³¼ì • ì—°êµ¬ì›ì…ë‹ˆë‹¤. \n",
    "        ì „ê¸°ì°¨ ì •ì±…, ì‹œì¥ ë™í–¥, ê¸°ìˆ ì  ì„¸ë¶€ì‚¬í•­ì— ëŒ€í•´ ê¹Šì´ ìˆëŠ” ë¶„ì„ì  ì§ˆë¬¸ì„ í•©ë‹ˆë‹¤. \n",
    "        í•™ìˆ ì  ìš©ì–´ë¥¼ ì‚¬ìš©í•˜ë©° ë°ì´í„°ì™€ ê·¼ê±°ë¥¼ ì¤‘ìš”í•˜ê²Œ ìƒê°í•©ë‹ˆë‹¤. í•œêµ­ì–´ë§Œ ì‚¬ìš©í•©ë‹ˆë‹¤.\"\"\",\n",
    "    ),\n",
    "    Persona(\n",
    "        name=\"masters_student\",\n",
    "        role_description=\"\"\"ì „ê¸°ì°¨ ì‚°ì—…ì„ ê³µë¶€í•˜ëŠ” í•œêµ­ì¸ ì„ì‚¬ê³¼ì • í•™ìƒì…ë‹ˆë‹¤. \n",
    "        ë¯¸êµ­ ì „ê¸°ì°¨ ì‹œì¥ì˜ ê¸°ì´ˆ ê°œë…ê³¼ íŠ¸ë Œë“œë¥¼ ì´í•´í•˜ë ¤ ë…¸ë ¥í•˜ë©°, \n",
    "        ëª…í™•í•˜ê³  ì´í•´í•˜ê¸° ì‰¬ìš´ ì„¤ëª…ì„ ì„ í˜¸í•©ë‹ˆë‹¤. í•œêµ­ì–´ë§Œ ì‚¬ìš©í•©ë‹ˆë‹¤.\"\"\",\n",
    "    ),\n",
    "    Persona(\n",
    "        name=\"industry_analyst\",\n",
    "        role_description=\"\"\"í•œêµ­ ìë™ì°¨ íšŒì‚¬ì—ì„œ ë¯¸êµ­ ì „ê¸°ì°¨ ì‹œì¥ì„ ë¶„ì„í•˜ëŠ” ì£¼ë‹ˆì–´ ì—°êµ¬ì›ì…ë‹ˆë‹¤. \n",
    "        ì‹¤ë¬´ì ì¸ ì‹œì¥ ë°ì´í„°, ê²½ìŸì‚¬ ë™í–¥, ë¹„ì¦ˆë‹ˆìŠ¤ ì¸ì‚¬ì´íŠ¸ì— ê´€ì‹¬ì´ ë§ìœ¼ë©°, \n",
    "        ì‹¤í–‰ ê°€ëŠ¥í•œ ì •ë³´ë¥¼ ì¤‘ìš”í•˜ê²Œ ìƒê°í•©ë‹ˆë‹¤. í•œêµ­ì–´ë§Œ ì‚¬ìš©í•©ë‹ˆë‹¤.\"\"\",\n",
    "    ),\n",
    "    Persona(\n",
    "        name=\"policy_researcher\",\n",
    "        role_description=\"\"\"í•œêµ­ ì •ë¶€ê¸°ê´€ì—ì„œ ì „ê¸°ì°¨ ì •ì±…ì„ ì—°êµ¬í•˜ëŠ” ì—°êµ¬ì›ì…ë‹ˆë‹¤. \n",
    "        ë¯¸êµ­ì˜ ì „ê¸°ì°¨ ê´€ë ¨ ì •ì±…, ì¸ì„¼í‹°ë¸Œ, ê·œì œì— ëŒ€í•´ ê´€ì‹¬ì´ ë§ìœ¼ë©°, \n",
    "        í•œêµ­ ì •ì±…ì— ì ìš© ê°€ëŠ¥í•œ ì‹œì‚¬ì ì„ ì°¾ê³  ìˆìŠµë‹ˆë‹¤. í•œêµ­ì–´ë§Œ ì‚¬ìš©í•©ë‹ˆë‹¤.\"\"\",\n",
    "    )\n",
    "]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ragas.testset.synthesizers.single_hop.specific import SingleHopSpecificQuerySynthesizer\n",
    "\n",
    "# ê¸°ë³¸ í”„ë¡¬í”„íŠ¸ (ì˜ì–´ ë²„ì „) í™•ì¸\n",
    "synthesizer = SingleHopSpecificQuerySynthesizer(llm=generator_llm)\n",
    "\n",
    "synthesizer.get_prompts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# í•œêµ­ì–´ í”„ë¡¬í”„íŠ¸ë¡œ ë³€í™˜\n",
    "korean_prompts = await synthesizer.adapt_prompts(\n",
    "    language=\"korean\", \n",
    "    llm=generator_llm\n",
    ")\n",
    "synthesizer.set_prompts(**korean_prompts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(korean_prompts['query_answer_generation_prompt'].instruction)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "synthesizer.get_prompts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ragas.testset.synthesizers.single_hop.specific import SingleHopSpecificQuerySynthesizer\n",
    "from ragas.testset.synthesizers.multi_hop.specific import MultiHopSpecificQuerySynthesizer\n",
    "from ragas.testset.synthesizers.multi_hop.abstract import MultiHopAbstractQuerySynthesizer\n",
    "\n",
    "\n",
    "async def create_korean_query_distribution():\n",
    "    \"\"\"í•œêµ­ì–´ ìµœì í™”ëœ Query Distribution ìƒì„±\"\"\"\n",
    "    \n",
    "    # Query Synthesizerë“¤ì„ í•œêµ­ì–´ë¡œ ì ì‘\n",
    "    synthesizers = [\n",
    "        (SingleHopSpecificQuerySynthesizer(llm=generator_llm), 0.6),\n",
    "        (MultiHopSpecificQuerySynthesizer(llm=generator_llm), 0.2),\n",
    "        (MultiHopAbstractQuerySynthesizer(llm=generator_llm), 0.2)\n",
    "    ]\n",
    "    \n",
    "    # ê° synthesizerì˜ í”„ë¡¬í”„íŠ¸ë¥¼ í•œêµ­ì–´ë¡œ ì ì‘\n",
    "    korean_query_distribution = []\n",
    "    for synthesizer, weight in synthesizers:\n",
    "\n",
    "        # í•œêµ­ì–´ í”„ë¡¬í”„íŠ¸ ì ì‘\n",
    "        korean_prompts = await synthesizer.adapt_prompts(\n",
    "            language=\"korean\", \n",
    "            llm=generator_llm\n",
    "        )\n",
    "        synthesizer.set_prompts(**korean_prompts)\n",
    "        print(f\"{synthesizer.__class__.__name__} í•œêµ­ì–´ ì ì‘ ì™„ë£Œ\")\n",
    "        korean_query_distribution.append((synthesizer, weight))\n",
    "\n",
    "    return korean_query_distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# í•©ì„± ë°ì´í„°ì…‹ ìƒì„±\n",
    "async def generate_korean_testset(split_docs, testset_size=60):\n",
    "    \"\"\"í•œêµ­ì–´ í…ŒìŠ¤íŠ¸ì…‹ ìƒì„±\"\"\"\n",
    "    \n",
    "    # 1. í•œêµ­ì–´ ì ì‘ëœ Query Distribution ìƒì„±\n",
    "    korean_query_distribution = await create_korean_query_distribution()\n",
    "    \n",
    "    # 2. TestsetGenerator ìƒì„±\n",
    "    testset_generator = TestsetGenerator(\n",
    "        llm=generator_llm,\n",
    "        embedding_model=generator_embeddings,\n",
    "        persona_list=personas\n",
    "    )\n",
    "    \n",
    "    # 3. í…ŒìŠ¤íŠ¸ì…‹ ìƒì„± (query_distribution ë§¤ê°œë³€ìˆ˜ ì‚¬ìš©)\n",
    "    synthetic_dataset = testset_generator.generate_with_langchain_docs(\n",
    "        documents=split_docs,\n",
    "        testset_size=testset_size,\n",
    "        query_distribution=korean_query_distribution  # ì˜¬ë°”ë¥¸ ë§¤ê°œë³€ìˆ˜\n",
    "    )\n",
    "    \n",
    "    return synthetic_dataset\n",
    "\n",
    "\n",
    "synthetic_dataset = await generate_korean_testset(split_docs, testset_size=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ê²°ê³¼ í™•ì¸\n",
    "df = synthetic_dataset.to_pandas()\n",
    "print(f\"ìƒì„±ëœ í•©ì„± ë°ì´í„°ì…‹ í¬ê¸°: {len(df)}\")\n",
    "print(f\"\\nì»¬ëŸ¼: {list(df.columns)}\")\n",
    "print(f\"\\nì²« ë²ˆì§¸ ìƒ˜í”Œ:\")\n",
    "print(f\"ì§ˆë¬¸: {df.iloc[0]['user_input']}\")\n",
    "print(f\"ì •ë‹µ: {df.iloc[0]['reference']}\")\n",
    "\n",
    "# CSVë¡œ ì €ì¥\n",
    "df.to_csv('./data/synthetic_testset.csv', index=False, encoding='utf-8')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.2 í‰ê°€ìš© ë°ì´í„°ì…‹ ì¤€ë¹„"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ragas import EvaluationDataset\n",
    "\n",
    "def create_evaluation_dataset(questions_data, rag_chain_func):\n",
    "    \"\"\"í‰ê°€ìš© ë°ì´í„°ì…‹ì„ ìƒì„±í•˜ëŠ” í•¨ìˆ˜\"\"\"\n",
    "    \n",
    "    evaluation_data = []\n",
    "    \n",
    "    # ê° ì§ˆë¬¸ì— ëŒ€í•´ RAG ì²´ì¸ì„ ì‹¤í–‰í•˜ê³  í‰ê°€ ë°ì´í„° êµ¬ì„±\n",
    "    for item in questions_data:\n",
    "\n",
    "        question = item[\"user_input\"]\n",
    "        ground_truth = item[\"reference\"]\n",
    "\n",
    "        # RAG ì²´ì¸ ì‹¤í–‰\n",
    "        result = rag_chain_func(question)\n",
    "        \n",
    "        # í‰ê°€ ë°ì´í„° êµ¬ì„±\n",
    "        eval_sample = {\n",
    "            \"user_input\": question,\n",
    "            \"response\": result[\"answer\"],\n",
    "            \"retrieved_contexts\": [doc.page_content for doc in result[\"retrieved_docs\"]],\n",
    "            \"reference\": ground_truth\n",
    "        }\n",
    "        \n",
    "        evaluation_data.append(eval_sample)\n",
    "    \n",
    "    return EvaluationDataset.from_list(evaluation_data)\n",
    "\n",
    "\n",
    "# í‰ê°€ ë°ì´í„°ì…‹ ì¤€ë¹„\n",
    "evaluation_questions = synthetic_dataset.to_list()  # í•©ì„± ë°ì´í„°ì…‹ì„ í‰ê°€ ì§ˆë¬¸ìœ¼ë¡œ ì‚¬ìš©\n",
    "\n",
    "print(f\"ì´ {len(evaluation_questions)}ê°œì˜ í‰ê°€ ì§ˆë¬¸ì´ ìˆìŠµë‹ˆë‹¤.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# í‰ê°€ ë°ì´í„°ì…‹ ìƒì„±\n",
    "eval_dataset = create_evaluation_dataset(evaluation_questions, rag_chain) \n",
    "\n",
    "# ë°ì´í„°í”„ë ˆì„ìœ¼ë¡œ í™•ì¸\n",
    "eval_df = eval_dataset.to_pandas()\n",
    "print(f\"\\ní‰ê°€ ë°ì´í„°ì…‹ ìƒì„± ì™„ë£Œ:\")\n",
    "print(f\"- ìƒ˜í”Œ ìˆ˜: {len(eval_df)}\")\n",
    "print(f\"- ì»¬ëŸ¼: {list(eval_df.columns)}\")\n",
    "\n",
    "# ì €ì¥\n",
    "eval_df.to_csv('./data/evaluation_dataset.csv', index=False, encoding='utf-8')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "eval_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## 5. RAGAS í‰ê°€ ìˆ˜í–‰\n",
    "\n",
    "- **RAG í‰ê°€ ì§€í‘œ (ì˜ˆì‹œ)**\n",
    "\n",
    "    ```python\n",
    "    from ragas.metrics import (\n",
    "        context_relevancy,      # ì»¨í…ìŠ¤íŠ¸ ê´€ë ¨ì„±\n",
    "        context_recall,         # ì»¨í…ìŠ¤íŠ¸ íšŒìƒë¥ \n",
    "        faithfulness,          # ì¶©ì‹¤ë„\n",
    "        answer_relevancy,      # ë‹µë³€ ê´€ë ¨ì„±\n",
    "        answer_correctness     # ë‹µë³€ ì •í™•ì„±\n",
    "    )\n",
    "    ```\n",
    "\n",
    "- **ì§€í‘œë³„ ìƒì„¸ ì„¤ëª…**\n",
    "\n",
    "    1. **Context Relevancy (ì»¨í…ìŠ¤íŠ¸ ê´€ë ¨ì„±)**\n",
    "        - ê²€ìƒ‰ëœ ë¬¸ì„œê°€ ì§ˆë¬¸ê³¼ ì–¼ë§ˆë‚˜ ê´€ë ¨ìˆëŠ”ì§€ ì¸¡ì •\n",
    "        - ê³„ì‚°ì‹: `ê´€ë ¨ ë¬¸ì¥ ìˆ˜ / ì „ì²´ ë¬¸ì¥ ìˆ˜`\n",
    "\n",
    "    2. **Context Recall (ì»¨í…ìŠ¤íŠ¸ ê²€ì¶œë¥ )**\n",
    "        - ì •ë‹µ ìƒì„±ì— í•„ìš”í•œ ì •ë³´ê°€ ì–¼ë§ˆë‚˜ ê²€ìƒ‰ë˜ì—ˆëŠ”ì§€ ì¸¡ì •\n",
    "        - ì •ë‹µ(ground truth) í•„ìš”\n",
    "\n",
    "    3. **Faithfulness (ì¶©ì‹¤ë„)**\n",
    "        - ìƒì„±ëœ ë‹µë³€ì´ ê²€ìƒ‰ëœ ë¬¸ì„œì— ì–¼ë§ˆë‚˜ ì¶©ì‹¤í•œì§€ ì¸¡ì •\n",
    "        - í™˜ê°(hallucination) ê²€ì¶œì— ì¤‘ìš”\n",
    "\n",
    "    4. **Answer Relevancy (ë‹µë³€ ê´€ë ¨ì„±)**\n",
    "        - ìƒì„±ëœ ë‹µë³€ì´ ì§ˆë¬¸ê³¼ ì–¼ë§ˆë‚˜ ê´€ë ¨ìˆëŠ”ì§€ ì¸¡ì •\n",
    "\n",
    "    5. **Answer Correctness (ë‹µë³€ ì •í™•ì„±)**\n",
    "        - ìƒì„±ëœ ë‹µë³€ì´ ì •ë‹µê³¼ ì–¼ë§ˆë‚˜ ì¼ì¹˜í•˜ëŠ”ì§€ ì¸¡ì •"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.1 ê¸°ë³¸ í‰ê°€ ì‹¤í–‰"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ragas import evaluate\n",
    "from ragas.metrics import (\n",
    "    LLMContextRecall,\n",
    "    Faithfulness, \n",
    "    AnswerRelevancy,\n",
    "    ContextPrecision,\n",
    "    FactualCorrectness\n",
    ")\n",
    "\n",
    "# í‰ê°€ìš© LLM ì„¤ì •\n",
    "evaluator_llm = LangchainLLMWrapper(\n",
    "    ChatOpenAI(model=\"gpt-4.1-mini\", temperature=0)\n",
    ")\n",
    "\n",
    "# í‰ê°€ ì§€í‘œ ì„ íƒ\n",
    "metrics = [\n",
    "    LLMContextRecall(llm=evaluator_llm),           # ì»¨í…ìŠ¤íŠ¸ ê²€ì¶œìœ¨\n",
    "    Faithfulness(llm=evaluator_llm),               # ì¶©ì‹¤ë„\n",
    "    AnswerRelevancy(llm=evaluator_llm),            # ë‹µë³€ ê´€ë ¨ì„±\n",
    "    ContextPrecision(llm=evaluator_llm),           # ì»¨í…ìŠ¤íŠ¸ ì •ë°€ë„\n",
    "    FactualCorrectness(llm=evaluator_llm)          # ì‚¬ì‹¤ì  ì •í™•ì„±\n",
    "]\n",
    "\n",
    "print(\"RAGAS í‰ê°€ ì‹œì‘...\")\n",
    "\n",
    "# í‰ê°€ ì‹¤í–‰\n",
    "results = evaluate(\n",
    "    dataset=eval_dataset[:10],  # ì²˜ìŒ 10ê°œ ìƒ˜í”Œë¡œ í‰ê°€ (í…ŒìŠ¤íŠ¸ ëª©ì )\n",
    "    metrics=metrics,\n",
    "    llm=evaluator_llm,\n",
    "    embeddings=generator_embeddings\n",
    ")\n",
    "\n",
    "print(\"í‰ê°€ ì™„ë£Œ!\")\n",
    "print(f\"\\nì „ì²´ í‰ê°€ ê²°ê³¼:\")\n",
    "print(results)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.2 ìƒì„¸ ê²°ê³¼ ë¶„ì„\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ê²°ê³¼ë¥¼ DataFrameìœ¼ë¡œ ë³€í™˜\n",
    "results_df = results.to_pandas()\n",
    "\n",
    "print(f\"\\nìƒì„¸ í‰ê°€ ê²°ê³¼:\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "# ê° ìƒ˜í”Œë³„ ìƒì„¸ ê²°ê³¼\n",
    "for idx, row in results_df.iterrows():\n",
    "    print(f\"\\n[ìƒ˜í”Œ {idx+1}]\")\n",
    "    print(f\"ì§ˆë¬¸: {row['user_input'][:100]}...\")\n",
    "    print(f\"ë‹µë³€: {row['response'][:100]}...\")\n",
    "    \n",
    "    # ì§€í‘œë³„ ì ìˆ˜ ì¶œë ¥\n",
    "    for col in results_df.columns:\n",
    "        if col not in ['user_input', 'response', 'retrieved_contexts', 'reference']:\n",
    "            if pd.notna(row[col]):\n",
    "                print(f\"  {col}: {row[col]:.3f}\")\n",
    "    print(\"-\" * 50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# í†µê³„ ìš”ì•½\n",
    "print(f\"\\nğŸ“Š í‰ê°€ ì§€í‘œ í†µê³„:\")\n",
    "print(\"=\"*50)\n",
    "\n",
    "numeric_columns = results_df.select_dtypes(include=[np.number]).columns \n",
    "summary_stats = results_df[numeric_columns].describe()\n",
    "\n",
    "for metric in numeric_columns:\n",
    "    mean_score = summary_stats.loc['mean', metric]\n",
    "    std_score = summary_stats.loc['std', metric]\n",
    "    print(f\"{metric}:\")\n",
    "    print(f\"  í‰ê· : {mean_score:.3f} (Â±{std_score:.3f})\")\n",
    "    print(f\"  ë²”ìœ„: {summary_stats.loc['min', metric]:.3f} ~ {summary_stats.loc['max', metric]:.3f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## [ì°¸ê³ ] ë©”íŠ¸ë¦­ë³„ í•µì‹¬ í‰ê°€ ìš”ì†Œ\n",
    "\n",
    "| ë©”íŠ¸ë¦­ | í‰ê°€ ëŒ€ìƒ | í•µì‹¬ ì§ˆë¬¸ | ì •ì˜ |\n",
    "|--------|-----------|-----------|------|\n",
    "| **LLMContextRecall** | ê²€ìƒ‰ í’ˆì§ˆ | \"í•„ìš”í•œ ì •ë³´ê°€ ì˜ ê²€ìƒ‰ë˜ì—ˆëŠ”ê°€?\" | ì°¸ì¡° ë‹µë³€(reference)ì˜ ì£¼ì¥ë“¤ì´ ê²€ìƒ‰ëœ ì»¨í…ìŠ¤íŠ¸ì— ì˜í•´ ì–¼ë§ˆë‚˜ ì˜ ì§€ì›ë˜ëŠ”ì§€ë¥¼ ì¸¡ì •í•˜ëŠ” ì§€í‘œ |\n",
    "| **Faithfulness** | ìƒì„± í’ˆì§ˆ | \"ë‹µë³€ì´ ì»¨í…ìŠ¤íŠ¸ì— ì¶©ì‹¤í•œê°€?\" | ìƒì„±ëœ ë‹µë³€ì´ ê²€ìƒ‰ëœ ì»¨í…ìŠ¤íŠ¸ì— ì–¼ë§ˆë‚˜ ì¶©ì‹¤í•œì§€(ì¼ì¹˜í•˜ëŠ”ì§€) ì¸¡ì •í•˜ëŠ” ì§€í‘œ |\n",
    "| **AnswerRelevancy** | ë‹µë³€ í’ˆì§ˆ | \"ë‹µë³€ì´ ì§ˆë¬¸ê³¼ ê´€ë ¨ì´ ìˆëŠ”ê°€?\" | ìƒì„±ëœ ë‹µë³€ì´ ì‚¬ìš©ìì˜ ì§ˆë¬¸ê³¼ ì–¼ë§ˆë‚˜ ê´€ë ¨ì„±ì´ ìˆëŠ”ì§€ ì¸¡ì •í•˜ëŠ” ì§€í‘œ |\n",
    "| **ContextPrecision** | ê²€ìƒ‰ ì •ë°€ë„ | \"ê²€ìƒ‰ëœ ê²ƒë“¤ì´ ì‹¤ì œë¡œ ìœ ìš©í•œê°€?\" | ê²€ìƒ‰ëœ ì»¨í…ìŠ¤íŠ¸ ì¤‘ ì§ˆë¬¸ê³¼ ì‹¤ì œë¡œ ê´€ë ¨ëœ ê²ƒë“¤ì˜ ë¹„ìœ¨ì„ ì¸¡ì •í•˜ëŠ” ì§€í‘œ |\n",
    "| **FactualCorrectness** | ì‚¬ì‹¤ ì •í™•ì„± | \"ë‹µë³€ì´ ì‚¬ì‹¤ì ìœ¼ë¡œ ì •í™•í•œê°€?\" | ìƒì„±ëœ ì‘ë‹µê³¼ ì°¸ì¡° ë‹µë³€ ê°„ì˜ ì‚¬ì‹¤ì  ì •í™•ì„±ì„ ì¸¡ì •í•˜ëŠ” ì§€í‘œ |"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ê²°ê³¼ ì €ì¥\n",
    "results_df.to_csv('./data/ragas_evaluation_results.csv', index=False, encoding='utf-8')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
