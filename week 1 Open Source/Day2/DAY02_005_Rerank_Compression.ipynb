{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#  ì¬ìˆœìœ„í™”(Re-rank) ê¸°ë²•, ë§¥ë½ ì••ì¶•(Contextual Compression) ê¸°ë²•\n",
    "\n",
    "---\n",
    "\n",
    "## 1. ê°œë… ì´í•´\n",
    "\n",
    "### 1.1 RAG íŒŒì´í”„ë¼ì¸ì˜ í•œê³„ì \n",
    "\n",
    "ê¸°ë³¸ì ì¸ RAG ì‹œìŠ¤í…œì—ì„œëŠ” ë²¡í„° ìœ ì‚¬ë„ë§Œìœ¼ë¡œ ë¬¸ì„œë¥¼ ê²€ìƒ‰í•˜ê³  ë°˜í™˜í•˜ëŠ”ë°, ì´ ê³¼ì •ì—ì„œ ë‹¤ìŒê³¼ ê°™ì€ ë¬¸ì œì ë“¤ì´ ë°œìƒí•©ë‹ˆë‹¤:\n",
    "\n",
    "#### ğŸš¨ **ì£¼ìš” ë¬¸ì œì ë“¤**\n",
    "\n",
    "1. **ì˜ë¯¸ì  ìœ ì‚¬ë„ì˜ í•œê³„**: ë²¡í„° ìœ ì‚¬ë„ê°€ í•­ìƒ ì‹¤ì œ ê´€ë ¨ì„±ê³¼ ì¼ì¹˜í•˜ì§€ ì•ŠìŒ\n",
    "2. **ìˆœìœ„ ì •í™•ë„ ë¬¸ì œ**: ê°€ì¥ ê´€ë ¨ì„± ë†’ì€ ë¬¸ì„œê°€ ìƒìœ„ì— ì˜¤ì§€ ì•Šì„ ìˆ˜ ìˆìŒ\n",
    "3. **ë…¸ì´ì¦ˆ ì •ë³´ í¬í•¨**: ê²€ìƒ‰ëœ ë¬¸ì„œì— ë¶ˆí•„ìš”í•œ ì •ë³´ê°€ ë§ì´ í¬í•¨ë¨\n",
    "4. **ì»¨í…ìŠ¤íŠ¸ ê¸¸ì´ ì œí•œ**: LLMì˜ ì»¨í…ìŠ¤íŠ¸ ìœˆë„ìš° í•œê³„ë¡œ ì¸í•œ ì •ë³´ ì†ì‹¤\n",
    "5. **ë¹„ìš© íš¨ìœ¨ì„±**: ë¶ˆí•„ìš”í•œ í† í°ìœ¼ë¡œ ì¸í•œ API ë¹„ìš© ì¦ê°€\n",
    "\n",
    "### 1.2 í•´ê²°ì±…: ì´ì¤‘ ë‹¨ê³„ ì²˜ë¦¬\n",
    "\n",
    "#### ğŸ”„ **Two-Stage Retrieval Process**\n",
    "\n",
    "```mermaid\n",
    "graph LR\n",
    "    A[Query] --> B[1ì°¨ ê²€ìƒ‰<br/>ë²¡í„° ìœ ì‚¬ë„]\n",
    "    B --> C[ëŒ€ëŸ‰ì˜ í›„ë³´ ë¬¸ì„œ<br/>k=50~100ê°œ]\n",
    "    C --> D[2ì°¨ ì²˜ë¦¬<br/>Re-ranking/Compression]\n",
    "    D --> E[ì •ì œëœ ê²°ê³¼<br/>k=3~10ê°œ]\n",
    "    E --> F[LLM]\n",
    "```\n",
    "\n",
    "### 1.3 ì¬ìˆœìœ„í™” vs ë§¥ë½ ì••ì¶•\n",
    "\n",
    "| íŠ¹ì§• | ì¬ìˆœìœ„í™” (Re-ranking) | ë§¥ë½ ì••ì¶• (Contextual Compression) |\n",
    "|------|----------------------|-----------------------------------|\n",
    "| **ëª©ì ** | ê²€ìƒ‰ ê²°ê³¼ì˜ ìˆœì„œ ìµœì í™” | ê´€ë ¨ ì •ë³´ë§Œ ì„ ë³„ì  ì¶”ì¶œ |\n",
    "| **ì²˜ë¦¬ ë°©ì‹** | ë¬¸ì„œ ì „ì²´ ìˆœìœ„ ì¬ì •ë ¬ | ë¬¸ì„œ ë‚´ìš© í•„í„°ë§/ì••ì¶• |\n",
    "| **ì¶œë ¥** | ìˆœì„œê°€ ë°”ë€ ë™ì¼í•œ ë¬¸ì„œë“¤ | ì••ì¶•ë˜ê±°ë‚˜ í•„í„°ë§ëœ ë¬¸ì„œë“¤ |\n",
    "| **ì£¼ìš” ì¥ì ** | ì •í™•ë„ í–¥ìƒ | ë¹„ìš© ì ˆê°, ë…¸ì´ì¦ˆ ì œê±° |\n",
    "| **ì‚¬ìš© ì‹œì ** | ê²€ìƒ‰ ì§í›„ | ê²€ìƒ‰ í›„ ë˜ëŠ” ì¬ìˆœìœ„í™” í›„ |"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## 2. í™˜ê²½ ì„¤ì •\n",
    "\n",
    "### 2.1 í•„ìˆ˜ ë¼ì´ë¸ŒëŸ¬ë¦¬ ì„¤ì¹˜\n",
    "\n",
    "```bash\n",
    "# ê¸°ë³¸ LangChain ë° RAG êµ¬ì„± ìš”ì†Œ\n",
    "pip install langchain langchain-community langchain-openai\n",
    "pip install langchain-chroma\n",
    "```\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2 í™˜ê²½ ë³€ìˆ˜ ì„¤ì •"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import warnings\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "# í™˜ê²½ ë³€ìˆ˜ ë¡œë“œ\n",
    "load_dotenv()\n",
    "\n",
    "# ê²½ê³  ë©”ì‹œì§€ ìˆ¨ê¸°ê¸°\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "# Langsmith tracing ì—¬ë¶€ë¥¼ í™•ì¸ (true: langsmith ì¶”ì  í™œì„±í™”, false: langsmith ì¶”ì  ë¹„í™œì„±í™”)\n",
    "print(os.getenv('LANGSMITH_TRACING'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.3 ê¸°ë³¸ ë¼ì´ë¸ŒëŸ¬ë¦¬ Import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import time\n",
    "from typing import List, Dict, Any, Optional\n",
    "from pprint import pprint\n",
    "\n",
    "# LangChain í•µì‹¬\n",
    "from langchain_core.documents import Document\n",
    "from langchain_core.retrievers import BaseRetriever\n",
    "from langchain_openai import ChatOpenAI, OpenAIEmbeddings\n",
    "\n",
    "# ê²€ìƒ‰ ë° ì••ì¶•\n",
    "from langchain.retrievers import ContextualCompressionRetriever\n",
    "from langchain.retrievers.document_compressors import (\n",
    "    CrossEncoderReranker,\n",
    "    LLMListwiseRerank,\n",
    "    LLMChainFilter,\n",
    "    LLMChainExtractor,\n",
    "    EmbeddingsFilter,\n",
    "    DocumentCompressorPipeline\n",
    ")\n",
    "\n",
    "# ì™¸ë¶€ ëª¨ë¸\n",
    "from langchain_community.cross_encoders import HuggingFaceCrossEncoder\n",
    "from langchain_community.document_transformers import EmbeddingsRedundantFilter\n",
    "\n",
    "# ë²¡í„° ì €ì¥ì†Œ\n",
    "from langchain_chroma import Chroma\n",
    "\n",
    "# ë°ì´í„° ë¶„ì„ ë° ì‹œê°í™”\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# # í•œê¸€ í°íŠ¸ ì¸ì‹ - Windows\n",
    "# import matplotlib \n",
    "# font_name = matplotlib.font_manager.FontProperties(fname=\"c:/Windows/Fonts/malgun.ttf\").get_name()\n",
    "# matplotlib.rc('font', family=font_name)\n",
    "\n",
    "# í•œê¸€ í°íŠ¸ ì¸ì‹ - Mac\n",
    "import matplotlib\n",
    "matplotlib.rc('font', family='AppleGothic')\n",
    "\n",
    "# ë§ˆì´ë„ˆìŠ¤ ë¶€í˜¸ ì¸ì‹\n",
    "matplotlib.rc(\"axes\", unicode_minus = False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.4 ë²¡í„° ì €ì¥ì†Œ ë° ê¸°ë³¸ ê²€ìƒ‰ê¸° ì„¤ì •"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def initialize_vector_store(embeddings = OpenAIEmbeddings(model=\"text-embedding-3-small\"), collection_name=\"hybrid_search_db\", persist_directory = \"./local_chroma_db\"):\n",
    "    \"\"\"\n",
    "    ê¸°ì¡´ ë²¡í„° ì €ì¥ì†Œë¥¼ ë¡œë“œí•˜ê±°ë‚˜ ìƒˆë¡œ ìƒì„±\n",
    "    \n",
    "    Returns:\n",
    "        Chroma: ë²¡í„° ì €ì¥ì†Œ ê°ì²´\n",
    "    \"\"\"\n",
    "    try:\n",
    "        \n",
    "        # ê¸°ì¡´ ë²¡í„° ì €ì¥ì†Œ ë¡œë“œ ì‹œë„\n",
    "        vector_store = Chroma(\n",
    "            collection_name=collection_name,\n",
    "            embedding_function=embeddings,\n",
    "            persist_directory=persist_directory,\n",
    "        )\n",
    "        \n",
    "        doc_count = vector_store._collection.count()\n",
    "        if doc_count > 0:\n",
    "            print(f\"âœ… ê¸°ì¡´ ë²¡í„° ì €ì¥ì†Œ ë¡œë“œ: {doc_count}ê°œ ë¬¸ì„œ\")\n",
    "            return vector_store\n",
    "        else:\n",
    "            print(\"âš ï¸ ë¹ˆ ë²¡í„° ì €ì¥ì†Œì…ë‹ˆë‹¤. ë°ì´í„°ë¥¼ ì¶”ê°€í•´ì£¼ì„¸ìš”.\")\n",
    "            return vector_store\n",
    "            \n",
    "    except Exception as e:\n",
    "        print(f\"âŒ ë²¡í„° ì €ì¥ì†Œ ë¡œë“œ ì‹¤íŒ¨: {e}\")\n",
    "        return None\n",
    "\n",
    "# ë²¡í„° ì €ì¥ì†Œ ì´ˆê¸°í™”\n",
    "vector_store = initialize_vector_store()\n",
    "\n",
    "if vector_store:\n",
    "    # ê¸°ë³¸ ê²€ìƒ‰ê¸° ìƒì„±\n",
    "    base_retriever = vector_store.as_retriever(search_kwargs={\"k\": 5})\n",
    "    print(\"âœ… ê¸°ë³¸ ê²€ìƒ‰ê¸° ìƒì„± ì™„ë£Œ\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ê¸°ë³¸ retriever í…ŒìŠ¤íŠ¸ \n",
    "\n",
    "query = \"ë¦¬ë¹„ì•ˆì˜ ì‚¬ì—… ê²½ìŸë ¥ì€ ì–´ë””ì„œ ë‚˜ì˜¤ë‚˜ìš”?\"\n",
    "retrieved_docs = base_retriever.invoke(query)\n",
    "\n",
    "for doc in retrieved_docs:\n",
    "    print(f\"{doc.page_content} [ì¶œì²˜: {doc.metadata['source']}]\")\n",
    "    print(\"=\"*200)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## 3. ì¬ìˆœìœ„í™”(Re-ranking) ê¸°ë²•\n",
    "\n",
    "### 3.1 ì¬ìˆœìœ„í™”ì˜ í•µì‹¬ ê°œë…\n",
    "\n",
    "ì¬ìˆœìœ„í™”ëŠ” 1ì°¨ ê²€ìƒ‰ìœ¼ë¡œ ì–»ì€ ë¬¸ì„œë“¤ì„ ë” ì •êµí•œ ê¸°ì¤€ìœ¼ë¡œ ì¬í‰ê°€í•˜ì—¬ ìˆœì„œë¥¼ ì¬ì •ë ¬í•˜ëŠ” ê¸°ë²•ì…ë‹ˆë‹¤.\n",
    "\n",
    "#### ğŸ¯ **ì¬ìˆœìœ„í™”ì˜ ì‘ë™ ì›ë¦¬**\n",
    "\n",
    "1. **1ì°¨ ê²€ìƒ‰**: ë²¡í„° ìœ ì‚¬ë„ë¡œ ë§ì€ í›„ë³´ ë¬¸ì„œ ê²€ìƒ‰ (k=50~100)\n",
    "2. **ì •ë°€ ë¶„ì„**: ê° ë¬¸ì„œì™€ ì¿¼ë¦¬ ê°„ì˜ ì„¸ë°€í•œ ê´€ë ¨ì„± í‰ê°€\n",
    "3. **ìˆœìœ„ ì¬ì •ë ¬**: ê´€ë ¨ì„± ì ìˆ˜ì— ë”°ë¼ ë¬¸ì„œ ìˆœì„œ ì¬ë°°ì¹˜\n",
    "4. **ìƒìœ„ ì„ íƒ**: ê°€ì¥ ê´€ë ¨ì„± ë†’ì€ ìƒìœ„ kê°œ ë¬¸ì„œ ë°˜í™˜\n",
    "\n",
    "### 3.2 Cross-Encoder ì¬ìˆœìœ„í™”\n",
    "\n",
    "Cross-EncoderëŠ” ì¿¼ë¦¬ì™€ ë¬¸ì„œë¥¼ í•¨ê»˜ ì…ë ¥ë°›ì•„ ì§ì ‘ì ì¸ ê´€ë ¨ì„± ì ìˆ˜ë¥¼ ê³„ì‚°í•˜ëŠ” ëª¨ë¸ì…ë‹ˆë‹¤.\n",
    "\n",
    "- **Cross-Encoder** ëª¨ë¸ì„ í™œìš©í•˜ì—¬ ê²€ìƒ‰ ê²°ê³¼ì˜ ì •ë°€í•œ ì¬ì •ë ¬ì„ ìˆ˜í–‰í•¨\n",
    "- ê²€ìƒ‰ ì¿¼ë¦¬ì™€ ê²€ìƒ‰ëœ ë¬¸ì„œ ê°„ ìœ ì‚¬ë„ë¥¼ ë” ì •í™•í•˜ê²Œ ê³„ì‚°í•¨\n",
    "\n",
    "- ì°¸ê³ : https://www.sbert.net/examples/applications/cross-encoder/README.html\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_cross_encoder_reranker(model_name=\"BAAI/bge-reranker-v2-m3\", top_n=5):\n",
    "    \"\"\"\n",
    "    Cross-Encoder ì¬ìˆœìœ„í™” ì‹œìŠ¤í…œ ìƒì„±\n",
    "    \n",
    "    Args:\n",
    "        model_name (str): ì‚¬ìš©í•  Cross-Encoder ëª¨ë¸\n",
    "        top_n (int): ë°˜í™˜í•  ìƒìœ„ ë¬¸ì„œ ìˆ˜\n",
    "    \n",
    "    Returns:\n",
    "        ContextualCompressionRetriever: ì¬ìˆœìœ„í™” ê²€ìƒ‰ê¸°\n",
    "    \"\"\"\n",
    "    print(f\"ğŸ”„ Cross-Encoder ì¬ìˆœìœ„í™” ì‹œìŠ¤í…œ ì´ˆê¸°í™”\")\n",
    "    print(f\"   ëª¨ë¸: {model_name}\")\n",
    "    print(f\"   ìƒìœ„ {top_n}ê°œ ë¬¸ì„œ ë°˜í™˜\")\n",
    "    \n",
    "    try:\n",
    "        # Cross-Encoder ëª¨ë¸ ë¡œë“œ\n",
    "        cross_encoder_model = HuggingFaceCrossEncoder(model_name=model_name)\n",
    "        \n",
    "        # ì¬ìˆœìœ„í™” ì»´í”„ë ˆì„œ ìƒì„±\n",
    "        reranker = CrossEncoderReranker(\n",
    "            model=cross_encoder_model, \n",
    "            top_n=top_n\n",
    "        )\n",
    "        \n",
    "        # ì»¨í…ìŠ¤íŠ¸ ì••ì¶• ê²€ìƒ‰ê¸° ìƒì„±\n",
    "        compression_retriever = ContextualCompressionRetriever(\n",
    "            base_compressor=reranker,\n",
    "            base_retriever=base_retriever,\n",
    "        )\n",
    "        \n",
    "        print(\"âœ… Cross-Encoder ì¬ìˆœìœ„í™” ì‹œìŠ¤í…œ ìƒì„± ì™„ë£Œ\")\n",
    "        return compression_retriever\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"âŒ Cross-Encoder ì´ˆê¸°í™” ì‹¤íŒ¨: {e}\")\n",
    "        return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ì¬ìˆœìœ„í™” ì‹œìŠ¤í…œ ìƒì„±\n",
    "cross_encoder_retriever = create_cross_encoder_reranker(top_n=5)\n",
    "\n",
    "# CrossEncoderRerankerë¥¼ ì‚¬ìš©í•œ retrieverë¥¼ ì‚¬ìš©í•˜ì—¬ ê²€ìƒ‰\n",
    "query = \"í…ŒìŠ¬ë¼ íŠ¸ëŸ­ ëª¨ë¸ì´ ìˆë‚˜ìš”?\"\n",
    "retrieved_docs = cross_encoder_retriever.invoke(query) \n",
    "\n",
    "# ê²€ìƒ‰ ê²°ê³¼ ì¶œë ¥\n",
    "print(\"\\nğŸ”„ Cross-Encoder ì¬ìˆœìœ„í™” ê²€ìƒ‰ ê²°ê³¼:\")\n",
    "print(\"-\"*200)\n",
    "\n",
    "for doc in retrieved_docs:\n",
    "    print(f\"{doc.page_content} [ì¶œì²˜: {doc.metadata['source']}]\")\n",
    "    print(\"=\"*200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_evaluation_dataset(file_path):\n",
    "    \"\"\"\n",
    "    í‰ê°€ ë°ì´í„°ì…‹ ë¡œë“œ\n",
    "    \n",
    "    Args:\n",
    "        file_path (str): í‰ê°€ ë°ì´í„° íŒŒì¼ ê²½ë¡œ\n",
    "    \n",
    "    Returns:\n",
    "        pandas.DataFrame: í‰ê°€ ë°ì´í„°ì…‹\n",
    "    \"\"\"\n",
    "    try:\n",
    "        if file_path.endswith('.xlsx'):\n",
    "            df = pd.read_excel(file_path)\n",
    "        elif file_path.endswith('.csv'):\n",
    "            df = pd.read_csv(file_path)\n",
    "        else:\n",
    "            raise ValueError(\"ì§€ì›í•˜ì§€ ì•ŠëŠ” íŒŒì¼ í˜•ì‹\")\n",
    "        \n",
    "        print(f\"âœ… í‰ê°€ ë°ì´í„°ì…‹ ë¡œë“œ: {len(df)}ê°œ ì§ˆë¬¸\")\n",
    "        return df\n",
    "    except Exception as e:\n",
    "        print(f\"âŒ ë°ì´í„°ì…‹ ë¡œë“œ ì‹¤íŒ¨: {e}\")\n",
    "        return None\n",
    "\n",
    "# í‰ê°€ ë°ì´í„°ì…‹ ë¡œë“œ\n",
    "\n",
    "eval_df = load_evaluation_dataset(\"./data/synthetic_testset.csv\")\n",
    "eval_df.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_evaluation_data(df):\n",
    "    \"\"\"\n",
    "    í‰ê°€ ë°ì´í„° ì „ì²˜ë¦¬\n",
    "    \n",
    "    Args:\n",
    "        df (pandas.DataFrame): ì›ë³¸ ë°ì´í„°í”„ë ˆì„\n",
    "    \n",
    "    Returns:\n",
    "        tuple: (ì§ˆë¬¸ ë¦¬ìŠ¤íŠ¸, ì •ë‹µ ë¬¸ì„œ ë¦¬ìŠ¤íŠ¸)\n",
    "    \"\"\"\n",
    "    questions = df['user_input'].tolist()\n",
    "    \n",
    "    # ì •ë‹µ ë¬¸ì„œ íŒŒì‹±\n",
    "    reference_contexts = []\n",
    "    for contexts in df['reference_contexts']:\n",
    "        if isinstance(contexts, str):\n",
    "            # ë¬¸ìì—´ì„ ë¦¬ìŠ¤íŠ¸ë¡œ ë³€í™˜\n",
    "            context_list = eval(contexts)\n",
    "        else:\n",
    "            context_list = contexts\n",
    "        \n",
    "        # Document ê°ì²´ë¡œ ë³€í™˜\n",
    "        docs = [Document(page_content=ctx) for ctx in context_list]\n",
    "        reference_contexts.append(docs)\n",
    "    \n",
    "    return questions, reference_contexts\n",
    "\n",
    "# í‰ê°€ ë°ì´í„° ì „ì²˜ë¦¬\n",
    "questions, reference_contexts = prepare_evaluation_data(eval_df)\n",
    "\n",
    "# í‰ê°€ ë°ì´í„° í™•ì¸\n",
    "for i, (q, refs) in enumerate(zip(questions[:3], reference_contexts[:3])):\n",
    "    print(f\"\\n[ì§ˆë¬¸ {i+1}]\")\n",
    "    print(f\"ì§ˆë¬¸: {q}\")\n",
    "    print(f\"ì •ë‹µ ë¬¸ì„œ: {len(refs)}ê°œ\")\n",
    "    for j, ref in enumerate(refs):\n",
    "        print(f\"  [{j+1}] ë‚´ìš©: {ref.page_content[:50]}...\")  # ë‚´ìš© ì¼ë¶€ë§Œ ì¶œë ¥\n",
    "    print(\"-\" * 50)\n",
    "\n",
    "# í‰ê°€ ë°ì´í„° í™•ì¸\n",
    "for i, (q, refs) in enumerate(zip(questions[-3:], reference_contexts[-3:])):\n",
    "    print(f\"\\n[ì§ˆë¬¸ {i+1}]\")\n",
    "    print(f\"ì§ˆë¬¸: {q}\")\n",
    "    print(f\"ì •ë‹µ ë¬¸ì„œ: {len(refs)}ê°œ\")\n",
    "    for j, ref in enumerate(refs):\n",
    "        print(f\"  [{j+1}] ë‚´ìš©: {ref.page_content[:50]}...\")  # ë‚´ìš© ì¼ë¶€ë§Œ ì¶œë ¥\n",
    "    print(\"-\" * 50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ranx-k ë¼ì´ë¸ŒëŸ¬ë¦¬ ì‚¬ìš©í•´ì„œ ê²€ìƒ‰ ê²°ê³¼ í‰ê°€\n",
    "from ranx_k.evaluation import evaluate_with_ranx_similarity\n",
    "\n",
    "# ranx-k í‰ê°€ ì‹¤í–‰ (rouge ì ìˆ˜ê°€ ë†’ì€ ê²½ìš°) -> ë¬¸ìì—´ ìœ ì‚¬ë„ ê¸°ë°˜ í‰ê°€\n",
    "base_results = evaluate_with_ranx_similarity(\n",
    "    retriever=base_retriever,\n",
    "    questions=questions, \n",
    "    reference_contexts=reference_contexts,\n",
    "    k=5,\n",
    "    method='kiwi_rouge',  \n",
    "    similarity_threshold=0.8,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rerank_results = evaluate_with_ranx_similarity(\n",
    "    retriever=cross_encoder_retriever,\n",
    "    questions=questions, \n",
    "    reference_contexts=reference_contexts,\n",
    "    k=5,\n",
    "    method='kiwi_rouge',  \n",
    "    similarity_threshold=0.8,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.3 LLM ê¸°ë°˜ ì¬ìˆœìœ„í™”\n",
    "\n",
    "- **ëŒ€ê·œëª¨ ì–¸ì–´ ëª¨ë¸**ì„ í™œìš©í•˜ì—¬ ê²€ìƒ‰ ê²°ê³¼ì˜ ì¬ìˆœìœ„í™”ë¥¼ ìˆ˜í–‰í•¨\n",
    "- ì¿¼ë¦¬ì™€ ë¬¸ì„œ ê°„ì˜ **ê´€ë ¨ì„± ë¶„ì„**ì„ í†µí•´ ìµœì ì˜ ìˆœì„œë¥¼ ë„ì¶œí•¨\n",
    "- **LLMListwiseRerank**ì™€ ê°™ì€ ì „ë¬¸í™”ëœ ì¬ìˆœìœ„í™” ëª¨ë¸ì„ ì ìš©í•¨"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_llm_reranker(model_name=\"gpt-4.1-mini\", top_n=5):\n",
    "    \"\"\"\n",
    "    LLM ê¸°ë°˜ ì¬ìˆœìœ„í™” ì‹œìŠ¤í…œ ìƒì„±\n",
    "    \n",
    "    Args:\n",
    "        model_name (str): ì‚¬ìš©í•  LLM ëª¨ë¸\n",
    "        top_n (int): ë°˜í™˜í•  ìƒìœ„ ë¬¸ì„œ ìˆ˜\n",
    "    \n",
    "    Returns:\n",
    "        ContextualCompressionRetriever: LLM ì¬ìˆœìœ„í™” ê²€ìƒ‰ê¸°\n",
    "    \"\"\"\n",
    "    print(f\"ğŸ¤– LLM ì¬ìˆœìœ„í™” ì‹œìŠ¤í…œ ì´ˆê¸°í™”\")\n",
    "    print(f\"   ëª¨ë¸: {model_name}\")\n",
    "    print(f\"   ìƒìœ„ {top_n}ê°œ ë¬¸ì„œ ë°˜í™˜\")\n",
    "    \n",
    "    try:\n",
    "        # LLM ì´ˆê¸°í™”\n",
    "        llm = ChatOpenAI(model=model_name, temperature=0)\n",
    "        \n",
    "        # LLM ê¸°ë°˜ ì¬ìˆœìœ„í™” ì»´í”„ë ˆì„œ ìƒì„±\n",
    "        llm_reranker = LLMListwiseRerank.from_llm(llm, top_n=top_n)\n",
    "        \n",
    "        # ì»¨í…ìŠ¤íŠ¸ ì••ì¶• ê²€ìƒ‰ê¸° ìƒì„±\n",
    "        llm_compression_retriever = ContextualCompressionRetriever(\n",
    "            base_compressor=llm_reranker,\n",
    "            base_retriever=base_retriever,\n",
    "        )\n",
    "        \n",
    "        print(\"âœ… LLM ì¬ìˆœìœ„í™” ì‹œìŠ¤í…œ ìƒì„± ì™„ë£Œ\")\n",
    "        return llm_compression_retriever\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"âŒ LLM ì¬ìˆœìœ„í™” ì´ˆê¸°í™” ì‹¤íŒ¨: {e}\")\n",
    "        return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# LLM ì¬ìˆœìœ„í™” ì‹œìŠ¤í…œ ìƒì„±\n",
    "llm_retriever = create_llm_reranker(top_n=3)\n",
    "\n",
    "# LLM ì¬ìˆœìœ„í™” ê²€ìƒ‰ê¸° ì‚¬ìš©í•˜ì—¬ ê²€ìƒ‰\n",
    "query = \"í…ŒìŠ¬ë¼ íŠ¸ëŸ­ ëª¨ë¸ì´ ìˆë‚˜ìš”?\"\n",
    "retrieved_docs = llm_retriever.invoke(query)\n",
    "\n",
    "# ê²€ìƒ‰ ê²°ê³¼ ì¶œë ¥\n",
    "print(\"\\nğŸ¤– LLM ì¬ìˆœìœ„í™” ê²€ìƒ‰ ê²°ê³¼:\")\n",
    "print(\"-\"*200)\n",
    "\n",
    "for doc in retrieved_docs:\n",
    "    print(f\"{doc.page_content} [ì¶œì²˜: {doc.metadata['source']}]\")\n",
    "    print(\"=\"*200)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## 4. ë§¥ë½ ì••ì¶•(Contextual Compression) ê¸°ë²•\n",
    "\n",
    "### 4.1 ë§¥ë½ ì••ì¶•ì˜ í•µì‹¬ ê°œë…\n",
    "\n",
    "ë§¥ë½ ì••ì¶•ì€ ê²€ìƒ‰ëœ ë¬¸ì„œì—ì„œ ì¿¼ë¦¬ì™€ ê´€ë ¨ëœ í•µì‹¬ ì •ë³´ë§Œì„ ì„ ë³„ì ìœ¼ë¡œ ì¶”ì¶œí•˜ëŠ” ê¸°ë²•ì…ë‹ˆë‹¤.\n",
    "\n",
    "#### ğŸ¯ **ë§¥ë½ ì••ì¶•ì˜ ì´ì **\n",
    "\n",
    "1. **ë¹„ìš© ì ˆê°**: ë¶ˆí•„ìš”í•œ í† í° ì œê±°ë¡œ LLM API ë¹„ìš© ì ˆì•½\n",
    "2. **ì„±ëŠ¥ í–¥ìƒ**: í•µì‹¬ ì •ë³´ë§Œ ì œê³µí•˜ì—¬ ë‹µë³€ í’ˆì§ˆ í–¥ìƒ\n",
    "3. **ë…¸ì´ì¦ˆ ì œê±°**: ê´€ë ¨ ì—†ëŠ” ì •ë³´ í•„í„°ë§\n",
    "4. **ì»¨í…ìŠ¤íŠ¸ íš¨ìœ¨ì„±**: ì œí•œëœ ì»¨í…ìŠ¤íŠ¸ ìœˆë„ìš° ìµœì  í™œìš©\n",
    "\n",
    "### 4.2 LLM ê¸°ë°˜ í•„í„°ë§\n",
    "\n",
    "#### 4.2.1 LLMChainFilter êµ¬í˜„\n",
    "\n",
    "\n",
    "- **LLM ê¸°ë°˜ í•„í„°ë§**ìœ¼ë¡œ ê²€ìƒ‰ëœ ë¬¸ì„œì˜ í¬í•¨ ì—¬ë¶€ë¥¼ ê²°ì •í•¨\n",
    "- **ì›ë³¸ ìœ ì§€ ë°©ì‹**ìœ¼ë¡œ ë¬¸ì„œ ë‚´ìš©ì˜ ë³€ê²½ ì—†ì´ ì„ ë³„ ì‘ì—…ì„ ìˆ˜í–‰í•¨\n",
    "- **ì„ íƒì  í•„í„°ë§**ì„ í†µí•´ ê´€ë ¨ì„± ë†’ì€ ë¬¸ì„œë§Œì„ ìµœì¢… ë°˜í™˜í•¨\n",
    "- ë¬¸ì„œ ì›ë³¸ì„ ë³´ì¡´í•˜ë©´ì„œ ê´€ë ¨ì„± ê¸°ë°˜ì˜ ìŠ¤ë§ˆíŠ¸í•œ ì„ ë³„ì„ ìˆ˜í–‰í•˜ëŠ” ë°©ì‹"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_llm_filter(model_name=\"gpt-4.1-mini\"):\n",
    "    \"\"\"\n",
    "    LLM ê¸°ë°˜ ë¬¸ì„œ í•„í„°ë§ ì‹œìŠ¤í…œ ìƒì„±\n",
    "    \n",
    "    Args:\n",
    "        model_name (str): ì‚¬ìš©í•  LLM ëª¨ë¸\n",
    "    \n",
    "    Returns:\n",
    "        ContextualCompressionRetriever: LLM í•„í„°ë§ ê²€ìƒ‰ê¸°\n",
    "    \"\"\"\n",
    "    print(f\"ğŸ” LLM ë¬¸ì„œ í•„í„°ë§ ì‹œìŠ¤í…œ ì´ˆê¸°í™”\")\n",
    "    print(f\"   ëª¨ë¸: {model_name}\")\n",
    "    \n",
    "    try:\n",
    "        # LLM ì´ˆê¸°í™”\n",
    "        llm = ChatOpenAI(model=model_name, temperature=0)\n",
    "        \n",
    "        # LLM ì²´ì¸ í•„í„° ìƒì„±\n",
    "        llm_filter = LLMChainFilter.from_llm(llm)\n",
    "        \n",
    "        # ì»¨í…ìŠ¤íŠ¸ ì••ì¶• ê²€ìƒ‰ê¸° ìƒì„±\n",
    "        filter_retriever = ContextualCompressionRetriever(\n",
    "            base_compressor=llm_filter,\n",
    "            base_retriever=base_retriever,\n",
    "        )\n",
    "        \n",
    "        print(\"âœ… LLM í•„í„°ë§ ì‹œìŠ¤í…œ ìƒì„± ì™„ë£Œ\")\n",
    "        return filter_retriever\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"âŒ LLM í•„í„°ë§ ì´ˆê¸°í™” ì‹¤íŒ¨: {e}\")\n",
    "        return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# LLM í•„í„°ë§ ì‹œìŠ¤í…œ ìƒì„±\n",
    "filter_retriever = create_llm_filter()\n",
    "\n",
    "# LLM í•„í„°ë§ ê²€ìƒ‰ê¸° ì‚¬ìš©í•˜ì—¬ ê²€ìƒ‰\n",
    "query = \"í…ŒìŠ¬ë¼ íŠ¸ëŸ­ ëª¨ë¸ì´ ìˆë‚˜ìš”?\"\n",
    "retrieved_docs = filter_retriever.invoke(query)\n",
    "\n",
    "# ê²€ìƒ‰ ê²°ê³¼ ì¶œë ¥\n",
    "print(\"\\nğŸ” LLM í•„í„°ë§ ê²€ìƒ‰ ê²°ê³¼:\")\n",
    "for doc in retrieved_docs:\n",
    "    print(f\"{doc.page_content} [ì¶œì²˜: {doc.metadata['source']}]\")\n",
    "    print(\"=\"*200)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4.2.2 LLMChainExtractor êµ¬í˜„\n",
    "\n",
    "- **LLM ê¸°ë°˜ ì¶”ì¶œ**ë¡œ ë¬¸ì„œì—ì„œ ì¿¼ë¦¬ ê´€ë ¨ í•µì‹¬ ë‚´ìš©ë§Œì„ ì„ ë³„í•¨\n",
    "- **ìˆœì°¨ì  ì²˜ë¦¬ ë°©ì‹**ìœ¼ë¡œ ê° ë¬¸ì„œë¥¼ ê²€í† í•˜ì—¬ ê´€ë ¨ ì •ë³´ë¥¼ ì¶”ì¶œí•¨\n",
    "- **ë§ì¶¤í˜• ìš”ì•½**ì„ í†µí•´ ì¿¼ë¦¬ì— ìµœì í™”ëœ ì••ì¶• ê²°ê³¼ë¥¼ ìƒì„±í•¨\n",
    "- ì¿¼ë¦¬ ë§¥ë½ì— ë”°ë¥¸ ì„ ë³„ì  ì •ë³´ ì¶”ì¶œë¡œ íš¨ìœ¨ì ì¸ ë¬¸ì„œ ì••ì¶•ì„ ì‹¤í˜„"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_llm_extractor(model_name=\"gpt-4.1-mini\"):\n",
    "    \"\"\"\n",
    "    LLM ê¸°ë°˜ ì •ë³´ ì¶”ì¶œ ì‹œìŠ¤í…œ ìƒì„±\n",
    "    \n",
    "    Args:\n",
    "        model_name (str): ì‚¬ìš©í•  LLM ëª¨ë¸\n",
    "    \n",
    "    Returns:\n",
    "        ContextualCompressionRetriever: LLM ì¶”ì¶œ ê²€ìƒ‰ê¸°\n",
    "    \"\"\"\n",
    "    print(f\"ğŸ“ LLM ì •ë³´ ì¶”ì¶œ ì‹œìŠ¤í…œ ì´ˆê¸°í™”\")\n",
    "    print(f\"   ëª¨ë¸: {model_name}\")\n",
    "    \n",
    "    try:\n",
    "        # LLM ì´ˆê¸°í™”\n",
    "        llm = ChatOpenAI(model=model_name, temperature=0)\n",
    "        \n",
    "        # LLM ì²´ì¸ ì¶”ì¶œê¸° ìƒì„±\n",
    "        llm_extractor = LLMChainExtractor.from_llm(llm)\n",
    "        \n",
    "        # ì»¨í…ìŠ¤íŠ¸ ì••ì¶• ê²€ìƒ‰ê¸° ìƒì„±\n",
    "        extractor_retriever = ContextualCompressionRetriever(\n",
    "            base_compressor=llm_extractor,\n",
    "            base_retriever=base_retriever,\n",
    "        )\n",
    "        \n",
    "        print(\"âœ… LLM ì¶”ì¶œ ì‹œìŠ¤í…œ ìƒì„± ì™„ë£Œ\")\n",
    "        return extractor_retriever\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"âŒ LLM ì¶”ì¶œ ì´ˆê¸°í™” ì‹¤íŒ¨: {e}\")\n",
    "        return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# LLM ì¶”ì¶œ ì‹œìŠ¤í…œ ìƒì„±\n",
    "extractor_retriever = create_llm_extractor()\n",
    "\n",
    "# LLM ì¶”ì¶œ ê²€ìƒ‰ê¸° ì‚¬ìš©í•˜ì—¬ ê²€ìƒ‰\n",
    "query = \"í…ŒìŠ¬ë¼ íŠ¸ëŸ­ ëª¨ë¸ì´ ìˆë‚˜ìš”?\"\n",
    "retrieved_docs = extractor_retriever.invoke(query)\n",
    "\n",
    "# ê²€ìƒ‰ ê²°ê³¼ ì¶œë ¥\n",
    "print(\"\\nğŸ“ LLM ì¶”ì¶œ ê²€ìƒ‰ ê²°ê³¼:\")\n",
    "for doc in retrieved_docs:\n",
    "    print(f\"{doc.page_content} [ì¶œì²˜: {doc.metadata['source']}]\")\n",
    "    print(\"=\"*200)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.3 ì„ë² ë”© ê¸°ë°˜ í•„í„°ë§ (EmbeddingsFilter)\n",
    "\n",
    "- **ì„ë² ë”© ê¸°ë°˜ í•„í„°ë§**ìœ¼ë¡œ ë¬¸ì„œì™€ ì¿¼ë¦¬ ê°„ ìœ ì‚¬ë„ë¥¼ ê³„ì‚°í•¨\n",
    "- **LLM ë¯¸ì‚¬ìš© ë°©ì‹**ìœ¼ë¡œ ë¹ ë¥¸ ì²˜ë¦¬ ì†ë„ì™€ ë¹„ìš© íš¨ìœ¨ì„±ì„ í™•ë³´í•¨ (LLM í˜¸ì¶œë³´ë‹¤ ì €ë ´í•˜ê³  ë¹ ë¥¸ ì˜µì…˜)\n",
    "- **ìœ ì‚¬ë„ ê¸°ì¤€ ì„ ë³„**ì„ í†µí•´ ê´€ë ¨ì„± ë†’ì€ ë¬¸ì„œë§Œì„ íš¨ê³¼ì ìœ¼ë¡œ ì¶”ì¶œí•¨\n",
    "- ê²½ì œì ì´ê³  ì‹ ì†í•œ ì„ë² ë”© ê¸°ë°˜ì˜ ë¬¸ì„œ í•„í„°ë§ ê¸°ë²• "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_embeddings_filter(similarity_threshold=0.1):\n",
    "    \"\"\"\n",
    "    ì„ë² ë”© ê¸°ë°˜ ìœ ì‚¬ë„ í•„í„°ë§ ì‹œìŠ¤í…œ ìƒì„±\n",
    "    \n",
    "    Args:\n",
    "        similarity_threshold (float): ìœ ì‚¬ë„ ì„ê³„ê°’ (0~1)\n",
    "    \n",
    "    Returns:\n",
    "        ContextualCompressionRetriever: ì„ë² ë”© í•„í„°ë§ ê²€ìƒ‰ê¸°\n",
    "    \"\"\"\n",
    "    print(f\"ğŸ§® ì„ë² ë”© ê¸°ë°˜ í•„í„°ë§ ì‹œìŠ¤í…œ ì´ˆê¸°í™”\")\n",
    "    print(f\"   ìœ ì‚¬ë„ ì„ê³„ê°’: {similarity_threshold}\")\n",
    "    \n",
    "    try:\n",
    "        # ì„ë² ë”© ëª¨ë¸ ì´ˆê¸°í™”\n",
    "        embeddings = OpenAIEmbeddings(model=\"text-embedding-3-small\")\n",
    "        \n",
    "        # ì„ë² ë”© í•„í„° ìƒì„±\n",
    "        embeddings_filter = EmbeddingsFilter(\n",
    "            embeddings=embeddings, \n",
    "            similarity_threshold=similarity_threshold\n",
    "        )\n",
    "        \n",
    "        # ì»¨í…ìŠ¤íŠ¸ ì••ì¶• ê²€ìƒ‰ê¸° ìƒì„±\n",
    "        embedding_filter_retriever = ContextualCompressionRetriever(\n",
    "            base_compressor=embeddings_filter,\n",
    "            base_retriever=base_retriever,\n",
    "        )\n",
    "        \n",
    "        print(\"âœ… ì„ë² ë”© í•„í„°ë§ ì‹œìŠ¤í…œ ìƒì„± ì™„ë£Œ\")\n",
    "        return embedding_filter_retriever\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"âŒ ì„ë² ë”© í•„í„°ë§ ì´ˆê¸°í™” ì‹¤íŒ¨: {e}\")\n",
    "        return None\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_embeddings_filter_thresholds():\n",
    "    \"\"\"ë‹¤ì–‘í•œ ì„ê³„ê°’ì—ì„œ ì„ë² ë”© í•„í„° ì„±ëŠ¥ í…ŒìŠ¤íŠ¸\"\"\"\n",
    "    if not base_retriever:\n",
    "        print(\"âŒ ê¸°ë³¸ ê²€ìƒ‰ê¸°ê°€ ì´ˆê¸°í™”ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.\")\n",
    "        return\n",
    "    \n",
    "    print(\"ğŸ§® ì„ë² ë”© í•„í„° ì„ê³„ê°’ë³„ ì„±ëŠ¥ í…ŒìŠ¤íŠ¸\")\n",
    "    print(\"=\" * 80)\n",
    "    \n",
    "    # ë‹¤ì–‘í•œ ì„ê³„ê°’ ì„¤ì •\n",
    "    thresholds = [0.2, 0.4, 0.6, 0.8]\n",
    "    test_query = \"í…ŒìŠ¬ë¼ íŠ¸ëŸ­ ëª¨ë¸ì´ ìˆë‚˜ìš”?\"\n",
    "    \n",
    "    print(f\"í…ŒìŠ¤íŠ¸ ì§ˆë¬¸: {test_query}\\n\")\n",
    "    \n",
    "    threshold_results = {}\n",
    "    \n",
    "    for threshold in thresholds:\n",
    "        print(f\"ğŸ” ì„ê³„ê°’ {threshold} í…ŒìŠ¤íŠ¸:\")\n",
    "        \n",
    "        try:\n",
    "            # ì„ë² ë”© í•„í„° ìƒì„±\n",
    "            filter_retriever = create_embeddings_filter(\n",
    "                similarity_threshold=threshold\n",
    "            )\n",
    "            \n",
    "            if filter_retriever:\n",
    "                start_time = time.time()\n",
    "                \n",
    "                # í•„í„°ë§ ì‹¤í–‰\n",
    "                filtered_docs = filter_retriever.invoke(test_query)\n",
    "                \n",
    "                end_time = time.time()\n",
    "                processing_time = end_time - start_time\n",
    "                \n",
    "                threshold_results[threshold] = {\n",
    "                    \"filtered_count\": len(filtered_docs),\n",
    "                    \"processing_time\": processing_time\n",
    "                }\n",
    "                \n",
    "                print(f\"   âœ… í•„í„°ë§ëœ ë¬¸ì„œ ìˆ˜: {len(filtered_docs)}ê°œ\")\n",
    "                print(f\"   â±ï¸ ì²˜ë¦¬ ì‹œê°„: {processing_time:.3f}ì´ˆ\")\n",
    "                \n",
    "                # ìƒìœ„ ê²°ê³¼ ë¯¸ë¦¬ë³´ê¸°\n",
    "                if filtered_docs:\n",
    "                    print(f\"   ğŸ“„ ìƒìœ„ ê²°ê³¼: {filtered_docs[0].page_content[:80]}...\")\n",
    "                else:\n",
    "                    print(\"   âŒ ì„ê³„ê°’ ì¡°ê±´ì„ ë§Œì¡±í•˜ëŠ” ë¬¸ì„œ ì—†ìŒ\")\n",
    "            else:\n",
    "                print(\"   âŒ í•„í„° ìƒì„± ì‹¤íŒ¨\")\n",
    "                \n",
    "        except Exception as e:\n",
    "            print(f\"   âŒ ì˜¤ë¥˜ ë°œìƒ: {e}\")\n",
    "        \n",
    "        print(\"-\" * 50)\n",
    "    \n",
    "    # ê²°ê³¼ ì‹œê°í™”\n",
    "    if threshold_results:\n",
    "        print(\"\\nğŸ“Š ì„ê³„ê°’ë³„ ê²°ê³¼ ìš”ì•½:\")\n",
    "        \n",
    "        # DataFrame ìƒì„±\n",
    "        df = pd.DataFrame(threshold_results).T\n",
    "        df.index.name = 'Threshold'\n",
    "        df = df.round(3)\n",
    "        print(df.to_string())\n",
    "        \n",
    "        # ì‹œê°í™”\n",
    "        fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(12, 5))\n",
    "        \n",
    "        # í•„í„°ë§ëœ ë¬¸ì„œ ìˆ˜\n",
    "        ax1.bar(df.index, df['filtered_count'], color='skyblue')\n",
    "        ax1.set_title('ì„ê³„ê°’ë³„ í•„í„°ë§ëœ ë¬¸ì„œ ìˆ˜')\n",
    "        ax1.set_xlabel('ìœ ì‚¬ë„ ì„ê³„ê°’')\n",
    "        ax1.set_ylabel('ë¬¸ì„œ ìˆ˜')\n",
    "        ax1.grid(True, alpha=0.3)\n",
    "        \n",
    "        # ì²˜ë¦¬ ì‹œê°„\n",
    "        ax2.bar(df.index, df['processing_time'], color='lightcoral')\n",
    "        ax2.set_title('ì„ê³„ê°’ë³„ ì²˜ë¦¬ ì‹œê°„')\n",
    "        ax2.set_xlabel('ìœ ì‚¬ë„ ì„ê³„ê°’')\n",
    "        ax2.set_ylabel('ì²˜ë¦¬ ì‹œê°„ (ì´ˆ)')\n",
    "        ax2.grid(True, alpha=0.3)\n",
    "        \n",
    "        plt.tight_layout()\n",
    "        plt.show()\n",
    "    \n",
    "    return threshold_results\n",
    "\n",
    "# ì„ë² ë”© í•„í„° ì„ê³„ê°’ í…ŒìŠ¤íŠ¸\n",
    "threshold_test_results = test_embeddings_filter_thresholds()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## 5. íŒŒì´í”„ë¼ì¸ ìµœì í™” (DocumentCompressorPipeline)\n",
    "\n",
    "ì—¬ëŸ¬ ì••ì¶• ê¸°ë²•ì„ ìˆœì°¨ì ìœ¼ë¡œ ì—°ê²°í•˜ì—¬ ìµœì ì˜ ê²°ê³¼ë¥¼ ì–»ëŠ” ë°©ë²•ì…ë‹ˆë‹¤.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.retrievers.document_compressors import DocumentCompressorPipeline\n",
    "from langchain_community.document_transformers import EmbeddingsRedundantFilter\n",
    "\n",
    "\n",
    "def create_comprehensive_pipeline():\n",
    "    \"\"\"\n",
    "    í¬ê´„ì ì¸ ë¬¸ì„œ ì••ì¶• íŒŒì´í”„ë¼ì¸ ìƒì„±\n",
    "    \n",
    "    Returns:\n",
    "        ContextualCompressionRetriever: ë‹¤ë‹¨ê³„ ì••ì¶• ê²€ìƒ‰ê¸°\n",
    "    \"\"\"\n",
    "    print(\"ğŸ”§ í¬ê´„ì ì¸ ë¬¸ì„œ ì••ì¶• íŒŒì´í”„ë¼ì¸ êµ¬ì„±\")\n",
    "    \n",
    "    try:\n",
    "        # ì„ë² ë”© ëª¨ë¸ ì´ˆê¸°í™”\n",
    "        embeddings = OpenAIEmbeddings(model=\"text-embedding-3-small\")\n",
    "        \n",
    "        # LLM ì´ˆê¸°í™”\n",
    "        llm = ChatOpenAI(model=\"gpt-4.1-mini\", temperature=0)\n",
    "        \n",
    "        # íŒŒì´í”„ë¼ì¸ êµ¬ì„± ìš”ì†Œë“¤\n",
    "        print(\"   1ï¸âƒ£ ì¤‘ë³µ ì œê±° í•„í„° ì¶”ê°€\")\n",
    "        redundant_filter = EmbeddingsRedundantFilter(embeddings=embeddings)\n",
    "        \n",
    "        print(\"   2ï¸âƒ£ ìœ ì‚¬ë„ ê¸°ë°˜ í•„í„° ì¶”ê°€ (ì„ê³„ê°’: 0.4)\")\n",
    "        similarity_filter = EmbeddingsFilter(\n",
    "            embeddings=embeddings, \n",
    "            similarity_threshold=0.4\n",
    "        )\n",
    "        \n",
    "        print(\"   3ï¸âƒ£ LLM ê¸°ë°˜ ì¬ìˆœìœ„í™” ì¶”ê°€\")\n",
    "        llm_reranker = LLMListwiseRerank.from_llm(llm, top_n=5)\n",
    "        \n",
    "        # íŒŒì´í”„ë¼ì¸ ìƒì„±\n",
    "        pipeline_compressor = DocumentCompressorPipeline(\n",
    "            transformers=[\n",
    "                redundant_filter,    # 1ë‹¨ê³„: ì¤‘ë³µ ì œê±°\n",
    "                similarity_filter,   # 2ë‹¨ê³„: ìœ ì‚¬ë„ í•„í„°ë§\n",
    "                llm_reranker        # 3ë‹¨ê³„: LLM ì¬ìˆœìœ„í™”\n",
    "            ]\n",
    "        )\n",
    "        \n",
    "        # ìµœì¢… ì••ì¶• ê²€ìƒ‰ê¸° ìƒì„±\n",
    "        pipeline_retriever = ContextualCompressionRetriever(\n",
    "            base_compressor=pipeline_compressor,\n",
    "            base_retriever=base_retriever,\n",
    "        )\n",
    "        \n",
    "        print(\"âœ… í¬ê´„ì ì¸ ì••ì¶• íŒŒì´í”„ë¼ì¸ ìƒì„± ì™„ë£Œ\")\n",
    "        return pipeline_retriever\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"âŒ íŒŒì´í”„ë¼ì¸ ìƒì„± ì‹¤íŒ¨: {e}\")\n",
    "        return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# íŒŒì´í”„ë¼ì¸ ìƒì„±\n",
    "pipeline_retriever = create_comprehensive_pipeline()\n",
    "\n",
    "# íŒŒì´í”„ë¼ì¸ ê²€ìƒ‰ê¸° ì‚¬ìš©í•˜ì—¬ ê²€ìƒ‰\n",
    "query = \"í…ŒìŠ¬ë¼ íŠ¸ëŸ­ ëª¨ë¸ì´ ìˆë‚˜ìš”?\"\n",
    "retrieved_docs = pipeline_retriever.invoke(query)\n",
    "\n",
    "# ê²€ìƒ‰ ê²°ê³¼ ì¶œë ¥\n",
    "print(\"\\nğŸ”„ í¬ê´„ì ì¸ ë¬¸ì„œ ì••ì¶• íŒŒì´í”„ë¼ì¸ ê²€ìƒ‰ ê²°ê³¼:\")\n",
    "print(f\"   í•„í„°ë§ëœ ë¬¸ì„œ ìˆ˜: {len(retrieved_docs)}ê°œ\")\n",
    "for doc in retrieved_docs:\n",
    "    print(f\"{doc.page_content} [ì¶œì²˜: {doc.metadata['source']}]\")\n",
    "    print(\"=\"*200)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "skt-llm",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
