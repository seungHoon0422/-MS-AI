{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ì›¹ ê²€ìƒ‰ ê¸°ë°˜ ë¦¬ì„œì¹˜ ì‹œìŠ¤í…œ - LangGraph HITL (Human-in-the-Loop) í™œìš©\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## í™˜ê²½ ì„¤ì • ë° ì¤€ë¹„"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`(1) Env í™˜ê²½ë³€ìˆ˜`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dotenv import load_dotenv\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`(2) ê¸°ë³¸ ë¼ì´ë¸ŒëŸ¬ë¦¬`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from glob import glob\n",
    "from pprint import pprint\n",
    "import json\n",
    "from datetime import datetime"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`(3) Langsmith tracing ì„¤ì •`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Langsmith tracing ì—¬ë¶€ í™•ì¸\n",
    "print(f\"LangSmith ì¶”ì  ìƒíƒœ: {os.getenv('LANGSMITH_TRACING')}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## **Human-in-the-Loop (ì‚¬ìš©ì ê°œì…)**\n",
    "\n",
    "- **HITL**ëŠ” AI ì‹œìŠ¤í…œì— ì¸ê°„ì˜ íŒë‹¨ê³¼ ì „ë¬¸ì„±ì„ í†µí•©\n",
    "\n",
    "- **Breakpoints**ë¡œ íŠ¹ì • ë‹¨ê³„ì—ì„œ ì‹¤í–‰ ì¤‘ì§€ ê°€ëŠ¥\n",
    "    - **Breakpoint**ëŠ” LangGraphì˜ **ì²´í¬í¬ì¸íŠ¸ ê¸°ëŠ¥** ê¸°ë°˜ìœ¼ë¡œ ì‘ë™í•˜ëŠ” ì‹œìŠ¤í…œ\n",
    "    - ê° ë…¸ë“œ ì‹¤í–‰ í›„ ê·¸ë˜í”„ì˜ ìƒíƒœë¥¼ **ìŠ¤ë ˆë“œì— ì €ì¥**í•˜ì—¬ ë‚˜ì¤‘ì—ë„ ì ‘ê·¼ ê°€ëŠ¥\n",
    "    - ê·¸ë˜í”„ ì‹¤í–‰ì„ íŠ¹ì • ì§€ì ì—ì„œ **ì¼ì‹œ ì¤‘ì§€**í•˜ê³  ì‚¬ìš©ì ìŠ¹ì¸ í›„ ì¬ê°œ ê°€ëŠ¥\n",
    "\n",
    "- ì‚¬ìš©ìì˜ **ì…ë ¥**ì´ë‚˜ **ìŠ¹ì¸**ì„ ê¸°ë‹¤ë¦¬ëŠ” íŒ¨í„´ìœ¼ë¡œ ì‘ë™\n",
    "\n",
    "- ì‹œìŠ¤í…œ ê²°ì •ì— ëŒ€í•œ **ì¸ê°„ì˜ í†µì œ**ì™€ **ê²€ì¦** ë³´ì¥"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **ì›¹ ê²€ìƒ‰ ê¸°ë°˜ ë¦¬ì„œì¹˜ ì‹œìŠ¤í…œ êµ¬í˜„**\n",
    "\n",
    "- **ì£¼ì œ ë¶„ì„**: ì‚¬ìš©ìê°€ ì œê³µí•œ ì£¼ì œë¥¼ ë¶„ì„í•˜ì—¬ ê²€ìƒ‰ í‚¤ì›Œë“œ ìƒì„± (ì‚¬ìš©ìê°€ ì§ì ‘ ê²€í†  ë° ìˆ˜ì • ê°€ëŠ¥)\n",
    "- **ì›¹ ê²€ìƒ‰**: ë‹¤ì–‘í•œ ì†ŒìŠ¤ì—ì„œ ê´€ë ¨ ì •ë³´ ìˆ˜ì§‘\n",
    "- **ë³´ê³ ì„œ ì‘ì„±**: AIê°€ ì¢…í•©ì ì¸ ë¦¬ì„œì¹˜ ë³´ê³ ì„œ ì´ˆì•ˆ ìƒì„±\n",
    "- **ì‚¬ìš©ì ê²€í† **: ì‚¬ìš©ìê°€ ë³´ê³ ì„œ ë‚´ìš©ì„ ê²€í† í•˜ê³  ìˆ˜ì • ìš”ì²­\n",
    "- **ìµœì¢… ì™„ì„±**: í”¼ë“œë°±ì„ ë°˜ì˜í•œ ìµœì¢… ë³´ê³ ì„œ ìƒì„±"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### (1) ìƒíƒœ ì •ì˜ ë° ë„êµ¬ ì„¤ì •"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import List, Dict, Annotated, Optional\n",
    "from pydantic import BaseModel, Field\n",
    "from langgraph.graph import StateGraph, START, END, MessagesState\n",
    "from langgraph.checkpoint.memory import InMemorySaver\n",
    "from langgraph.types import interrupt, Command, Send\n",
    "from langchain_openai import ChatOpenAI\n",
    "from langchain_tavily import TavilySearch\n",
    "from langchain_core.messages import BaseMessage, AIMessage, HumanMessage\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from IPython.display import Image, display\n",
    "import operator\n",
    "\n",
    "# ========================================\n",
    "# State ì •ì˜ (Reducer í¬í•¨)\n",
    "# ========================================\n",
    "\n",
    "class ResearchState(MessagesState):\n",
    "    topic: str                  # ì—°êµ¬ ì£¼ì œ\n",
    "    keywords: List[str]         # ê²€ìƒ‰ í‚¤ì›Œë“œ\n",
    "\n",
    "    ready_for_search: bool      # ê²€ìƒ‰ ì¤€ë¹„ ì™„ë£Œ ì—¬ë¶€\n",
    "    search_results: Annotated[List[Dict], operator.add]  # Reducerë¡œ Send ê²°ê³¼ ìë™ ë³‘í•©\n",
    "    report: str                 # ìµœì¢… ë³´ê³ ì„œ\n",
    "\n",
    "    feedback: str               # í”¼ë“œë°±\n",
    "\n",
    "# ========================================\n",
    "# LLM, ë„êµ¬ ì„¤ì •\n",
    "# ========================================\n",
    "\n",
    "llm = ChatOpenAI(model=\"gpt-4.1-mini\", temperature=0.7)\n",
    "search_tool = TavilySearch(max_results=3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### (2) ê·¸ë˜í”„ ë…¸ë“œ ì •ì˜ ë° ì—°ê²°"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- **ì£¼ì œ ë¶„ì„**: ì‚¬ìš©ìê°€ ì œê³µí•œ ì£¼ì œë¥¼ ë¶„ì„í•˜ì—¬ ê²€ìƒ‰ í‚¤ì›Œë“œ ìƒì„±"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pydantic ëª¨ë¸ (êµ¬ì¡°í™”ëœ ì¶œë ¥ìš©)\n",
    "class Keywords(BaseModel):\n",
    "    \"\"\"í‚¤ì›Œë“œ ìƒì„± ê²°ê³¼\"\"\"\n",
    "    keywords: List[str] = Field(description=\"ìƒì„±ëœ í‚¤ì›Œë“œ ëª©ë¡\")\n",
    "    confidence: float = Field(description=\"í‚¤ì›Œë“œ ì‹ ë¢°ë„\")\n",
    "\n",
    "\n",
    "def generate_keywords(state: ResearchState) -> ResearchState:\n",
    "    \"\"\"Pydanticìœ¼ë¡œ êµ¬ì¡°í™”ëœ í‚¤ì›Œë“œ ìƒì„±\"\"\"\n",
    "    prompt = ChatPromptTemplate.from_messages([\n",
    "        (\"system\", \"ì „ë¬¸ ë¦¬ì„œì¹˜ ë¶„ì„ê°€ë¡œì„œ íš¨ê³¼ì ì¸ ê²€ìƒ‰ í‚¤ì›Œë“œë¥¼ ìƒì„±í•˜ì„¸ìš”.\"),\n",
    "        (\"human\", \"ì£¼ì œ: {topic}\\n3-7ê°œ í‚¤ì›Œë“œì™€ ì‹ ë¢°ë„(0-1)ë¥¼ ìƒì„±í•˜ì„¸ìš”.\")\n",
    "    ])\n",
    "    # êµ¬ì¡°í™”ëœ ì¶œë ¥\n",
    "    chain = prompt | llm.with_structured_output(Keywords)\n",
    "    result = chain.invoke({\"topic\": state[\"topic\"]})\n",
    "    \n",
    "    if result.keywords is None or len(result.keywords) == 0:\n",
    "        return {\n",
    "            \"keywords\": [],\n",
    "            \"messages\": [AIMessage(\"í‚¤ì›Œë“œ ìƒì„±ì— ì‹¤íŒ¨í–ˆìŠµë‹ˆë‹¤.\")]\n",
    "        } # type: ignore\n",
    "    \n",
    "    return {\n",
    "        \"keywords\": result.keywords,\n",
    "        \"messages\": [AIMessage(f\"í‚¤ì›Œë“œ {len(result.keywords)}ê°œ ìƒì„± (ì‹ ë¢°ë„: {result.confidence:.0%})\")]\n",
    "    } # type: ignore\n",
    "\n",
    "def review_keywords(state: ResearchState) -> ResearchState:\n",
    "    \"\"\"Human-in-the-loop: í‚¤ì›Œë“œ ê²€í† \"\"\"\n",
    "    keywords_list = \"\\n\".join([f\"{i+1}. {k}\" for i, k in enumerate(state[\"keywords\"])])\n",
    "\n",
    "    # interrupt ì‚¬ìš©ì ì…ë ¥ ëŒ€ê¸° (HITL) -> ì‚¬ìš©ìì—ê²Œ ìš”ì²­ (ì‚¬ìš©ìê°€ ì…ë ¥í•œ ë‚´ìš©ì€ user_inputì— ì €ì¥)\n",
    "    user_input = interrupt({\n",
    "        \"keywords\": state[\"keywords\"],\n",
    "        \"question\": f\"í‚¤ì›Œë“œ ê²€í† :\\n{keywords_list}\\n\\nì˜µì…˜:\\n- 'ìŠ¹ì¸': í˜„ì¬ í‚¤ì›Œë“œ ì‚¬ìš©\\n- 'ì¬ìƒì„±': ìƒˆ í‚¤ì›Œë“œ ìƒì„±\\n- 'ìˆ˜ì •: í‚¤ì›Œë“œ1,í‚¤ì›Œë“œ2,...': ì§ì ‘ ìˆ˜ì •\"\n",
    "    })\n",
    "\n",
    "    # ì‚¬ìš©ìê°€ ì…ë ¥í•œ í”¼ë“œë°± ì €ì¥\n",
    "    return {\"feedback\": user_input}\n",
    "\n",
    "def process_keyword_feedback(state: ResearchState) -> ResearchState:\n",
    "    \"\"\"í‚¤ì›Œë“œ í”¼ë“œë°± ì²˜ë¦¬ - í‚¤ì›Œë“œ ì§ì ‘ ìˆ˜ì •\"\"\"\n",
    "    feedback = state.get(\"feedback\", \"\").strip()\n",
    "    \n",
    "    if not feedback or \"ìŠ¹ì¸\" in feedback.lower():\n",
    "        # ìŠ¹ì¸ëœ ê²½ìš°\n",
    "        return {\n",
    "            \"keywords\": state[\"keywords\"], \n",
    "            \"messages\": [AIMessage(\"í‚¤ì›Œë“œê°€ ìŠ¹ì¸ë˜ì—ˆìŠµë‹ˆë‹¤.\")]\n",
    "        }  # type: ignore\n",
    "\n",
    "    elif \"ìˆ˜ì •:\" in feedback:\n",
    "        # ì§ì ‘ ìˆ˜ì •ëœ í‚¤ì›Œë“œ ì¶”ì¶œ\n",
    "        try:\n",
    "            new_keywords_str = feedback.split(\"ìˆ˜ì •:\", 1)[1].strip()\n",
    "            new_keywords = [kw.strip() for kw in new_keywords_str.split(\",\") if kw.strip()]\n",
    "            return {\n",
    "                \"keywords\": new_keywords,\n",
    "                \"messages\": [AIMessage(f\"í‚¤ì›Œë“œê°€ ìˆ˜ì •ë˜ì—ˆìŠµë‹ˆë‹¤: {', '.join(new_keywords)}\")]\n",
    "            }  # type: ignore\n",
    "        except:\n",
    "            return {\n",
    "                \"keywords\": [],\n",
    "                \"messages\": [AIMessage(\"í‚¤ì›Œë“œ í˜•ì‹ì´ ì˜¬ë°”ë¥´ì§€ ì•ŠìŠµë‹ˆë‹¤. ì¬ìƒì„±í•©ë‹ˆë‹¤.\")]\n",
    "            }  # type: ignore\n",
    "\n",
    "    else:\n",
    "        # ì¬ìƒì„± ë˜ëŠ” ê¸°íƒ€ ê²½ìš°\n",
    "        return {\n",
    "            \"keywords\": [],\n",
    "            \"messages\": [AIMessage(\"í‚¤ì›Œë“œë¥¼ ì¬ìƒì„±í•©ë‹ˆë‹¤.\")]\n",
    "        }  # type: ignore"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`(1) ì£¼ì œ ë¶„ì„ í…ŒìŠ¤íŠ¸ë¥¼ ìœ„í•œ ì›Œí¬í”Œë¡œìš° ì •ì˜`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ===== ì›Œí¬í”Œë¡œìš° ê·¸ë˜í”„ êµ¬ì„± =====\n",
    "def should_continue_after_review(state: ResearchState) -> str:\n",
    "    \"\"\"ê²€í†  í›„ ë‹¤ìŒ ë‹¨ê³„ ê²°ì •\"\"\"\n",
    "    feedback = state.get(\"feedback\", \"\").strip().lower()\n",
    "\n",
    "    # í”¼ë“œë°± ìœ í˜•ì— ë”°ë¥¸ ë‹¤ìŒ ë‹¨ê³„ ê²°ì •\n",
    "    if not feedback or \"ìŠ¹ì¸\" in feedback:\n",
    "        return \"approved\"    # ìŠ¹ì¸ëœ ê²½ìš°\n",
    "\n",
    "    elif \"ìˆ˜ì •:\" in feedback:\n",
    "        return \"process_feedback\"    # ì§ì ‘ ìˆ˜ì •ëœ í‚¤ì›Œë“œ ì²˜ë¦¬\n",
    "\n",
    "    else:\n",
    "        return \"regenerate\"  # ì¬ìƒì„±\n",
    "\n",
    "# StateGraph ìƒì„±\n",
    "workflow = StateGraph(ResearchState)\n",
    "\n",
    "# ë…¸ë“œ ì¶”ê°€\n",
    "workflow.add_node(\"analyze_topic\", generate_keywords)\n",
    "workflow.add_node(\"review_keywords\", review_keywords)\n",
    "workflow.add_node(\"process_feedback\", process_keyword_feedback)\n",
    "\n",
    "# ì—£ì§€ ì—°ê²°\n",
    "workflow.add_edge(START, \"analyze_topic\")\n",
    "workflow.add_edge(\"analyze_topic\", \"review_keywords\")\n",
    "\n",
    "# ì¡°ê±´ë¶€ ì—£ì§€\n",
    "workflow.add_conditional_edges(\n",
    "    \"review_keywords\",\n",
    "    should_continue_after_review,\n",
    "    {\n",
    "        \"process_feedback\": \"process_feedback\",\n",
    "        \"regenerate\": \"analyze_topic\",  # ì¬ìƒì„±ì‹œ ë‹¤ì‹œ í‚¤ì›Œë“œ ìƒì„±ìœ¼ë¡œ\n",
    "        \"approved\": END\n",
    "    }\n",
    ")\n",
    "\n",
    "# í”¼ë“œë°± ì²˜ë¦¬ í›„ ì¢…ë£Œ\n",
    "workflow.add_edge(\"process_feedback\", END)\n",
    "\n",
    "# ê·¸ë˜í”„ ì»´íŒŒì¼\n",
    "graph = workflow.compile(checkpointer=InMemorySaver())\n",
    "\n",
    "# ìƒíƒœ ê·¸ë˜í”„ ì‹œê°í™”\n",
    "display(Image(graph.get_graph().draw_mermaid_png()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`(2) ì›Œí¬í”Œë¡œìš° ì‹œì‘`\n",
    "\n",
    "- **interrupt**ê¹Œì§€ ì‹¤í–‰"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ì´ˆê¸° ìƒíƒœ ì„¤ì •\n",
    "initial_state = {\n",
    "    \"topic\": \"ì¸ê³µì§€ëŠ¥ ê¸°ìˆ  ë°œì „\"\n",
    "}\n",
    "\n",
    "# ìŠ¤ë ˆë“œ ì„¤ì •\n",
    "config = {\"configurable\": {\"thread_id\": f\"test_thread_1\"}}\n",
    "\n",
    "\n",
    "# ì›Œí¬í”Œë¡œìš° ì‹¤í–‰\n",
    "# ì²« ë²ˆì§¸ ì‹¤í–‰ - ì¤‘ë‹¨ì ì—ì„œ ì‹¤í–‰ì„ ë©ˆì¶¤\n",
    "for event in graph.stream(initial_state, config=config):\n",
    "    print(f\"Event: {event}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`(3) í˜„ì¬ ìƒíƒœ í™•ì¸`\n",
    "\n",
    "- **get_state** í•¨ìˆ˜ë¡œ í˜„ì¬ ìƒíƒœ í™•ì¸ ê°€ëŠ¥\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# í˜„ì¬ ìƒíƒœ - ê·¸ë˜í”„ ì²´í¬í¬ì¸íŠ¸ í™•ì¸\n",
    "current_state = graph.get_state(config)\n",
    "\n",
    "print(f\"\\ní˜„ì¬ ìƒíƒœ: {current_state.values}\")\n",
    "print(f\"ëŒ€ê¸° ì¤‘ì¸ interrupt: {current_state.tasks}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ë‹¤ìŒì— ì‹¤í–‰ë  ë…¸ë“œë¥¼ í™•ì¸ \n",
    "current_state.next"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ëŒ€ê¸° ì¤‘ì¸ interrupt í™•ì¸\n",
    "task = current_state.tasks[0]\n",
    "print(task.id)\n",
    "print(task.name)\n",
    "pprint(task.interrupts[0].value)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`(4) ì‚¬ìš©ì ê°œì… (HITL): ê±°ë¶€`\n",
    "\n",
    "- ì‚¬ìš©ìê°€ ìŠ¹ì¸ì„ í•´ì£¼ì§€ ì•ŠëŠ” ê²½ìš°, í”¼ë“œë°±ì„ í†µí•´ ë‹¤ì‹œ ìƒì„±\n",
    "- **Command** í•¨ìˆ˜ë¡œ ì‚¬ìš©ì í”¼ë“œë°± ì „ë‹¬"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langgraph.types import Command\n",
    "\n",
    "# ì‚¬ìš©ì í”¼ë“œë°± ì œê³µ (ê±°ë¶€: ì¬ìƒì„± ìš”ì²­)\n",
    "human_feedback = \"ì¬ìƒì„±\"\n",
    "\n",
    "print(f\"config: \", config)\n",
    "\n",
    "# ì‚¬ìš©ì ì…ë ¥ìœ¼ë¡œ ê·¸ë˜í”„ ì¬ê°œ (Command ì‚¬ìš©)\n",
    "for event in graph.stream(Command(resume=human_feedback), config=config):\n",
    "    print(f\"Event: {event}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# í˜„ì¬ ìƒíƒœ - ê·¸ë˜í”„ ì²´í¬í¬ì¸íŠ¸ í™•ì¸\n",
    "current_state = graph.get_state(config)\n",
    "\n",
    "print(f\"\\ní˜„ì¬ ìƒíƒœ: {current_state.values}\")\n",
    "print(f\"ëŒ€ê¸° ì¤‘ì¸ interrupt: {current_state.tasks}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ë‹¤ìŒì— ì‹¤í–‰ë  ë…¸ë“œë¥¼ í™•ì¸ \n",
    "current_state.next"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ëŒ€ê¸° ì¤‘ì¸ interrupt í™•ì¸\n",
    "task = current_state.tasks[0]\n",
    "print(task.id)\n",
    "print(task.name)\n",
    "pprint(task.interrupts[0].value)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`(5) ì‚¬ìš©ì ê°œì… (HITL): ìˆ˜ì •`\n",
    "\n",
    "- ì‚¬ìš©ìê°€ ìŠ¹ì¸ì„ í•´ì£¼ì§€ ì•ŠëŠ” ê²½ìš°, í”¼ë“œë°±ì„ í†µí•´ ë‹¤ì‹œ ìƒì„±\n",
    "- **Command** í•¨ìˆ˜ë¡œ ì‚¬ìš©ì í”¼ë“œë°± ì „ë‹¬"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langgraph.types import Command\n",
    "\n",
    "# ì‚¬ìš©ì í”¼ë“œë°± ì œê³µ (ê±°ë¶€: ì§ì ‘ í‚¤ì›Œë“œ ìˆ˜ì •)\n",
    "human_feedback = \"ìˆ˜ì •: ìƒì„±í˜• AI, LLM ë°œì „\"\n",
    "\n",
    "print(f\"config: \", config)\n",
    "\n",
    "# ì‚¬ìš©ì ì…ë ¥ìœ¼ë¡œ ê·¸ë˜í”„ ì¬ê°œ (Command ì‚¬ìš©)\n",
    "for event in graph.stream(Command(resume=human_feedback), config=config):\n",
    "    print(f\"Event: {event}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# í˜„ì¬ ìƒíƒœ - ê·¸ë˜í”„ ì²´í¬í¬ì¸íŠ¸ í™•ì¸\n",
    "current_state = graph.get_state(config)\n",
    "\n",
    "print(f\"\\ní˜„ì¬ ìƒíƒœ: {current_state.values}\")\n",
    "print(f\"ëŒ€ê¸° ì¤‘ì¸ interrupt: {current_state.tasks}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ë‹¤ìŒì— ì‹¤í–‰ë  ë…¸ë“œë¥¼ í™•ì¸ \n",
    "current_state.next"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`(5) ì‚¬ìš©ì ê°œì… (HITL): ìŠ¹ì¸`\n",
    "\n",
    "- ì‚¬ìš©ìê°€ 'ìŠ¹ì¸'ì„ í•´ì„œ ìµœì¢… ë‹µë³€ì„ ìƒì„±í•˜ê³  ì¢…ë£Œ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ì´ˆê¸° ìƒíƒœ ì„¤ì •\n",
    "initial_state = {\n",
    "    \"topic\": \"ê¸°í›„ë³€í™” ìœ„ê¸°\"\n",
    "}\n",
    "\n",
    "# ìŠ¤ë ˆë“œ ì„¤ì •\n",
    "config = {\"configurable\": {\"thread_id\": f\"test_thread_2\"}}\n",
    "\n",
    "\n",
    "# ì›Œí¬í”Œë¡œìš° ì‹¤í–‰\n",
    "# ì²« ë²ˆì§¸ ì‹¤í–‰ - ì¤‘ë‹¨ì ì—ì„œ ì‹¤í–‰ì„ ë©ˆì¶¤\n",
    "for event in graph.stream(initial_state, config=config):\n",
    "    print(f\"Event: {event}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# í˜„ì¬ ìƒíƒœ - ê·¸ë˜í”„ ì²´í¬í¬ì¸íŠ¸ í™•ì¸\n",
    "current_state = graph.get_state(config)\n",
    "\n",
    "print(f\"\\ní˜„ì¬ ìƒíƒœ: {current_state.values}\")\n",
    "print(f\"ëŒ€ê¸° ì¤‘ì¸ interrupt: {current_state.tasks}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# í”¼ë“œë°± ìš”ì²­ ë©”ì‹œì§€ ì¶œë ¥\n",
    "print(current_state.tasks[0].interrupts[0].value.get(\"question\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langgraph.types import Command\n",
    "\n",
    "# ì‚¬ìš©ì í”¼ë“œë°± ì œê³µ (ìŠ¹ì¸ ë¬¸ìì—´ì„ ì‚¬ìš©)\n",
    "human_feedback = \"ìŠ¹ì¸\"\n",
    "\n",
    "# ì‚¬ìš©ì ì…ë ¥ìœ¼ë¡œ ê·¸ë˜í”„ ì¬ê°œ\n",
    "for event in graph.stream(Command(resume=human_feedback), config=config):\n",
    "    print(f\"Event: {event}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# í˜„ì¬ ìƒíƒœ - ê·¸ë˜í”„ ì²´í¬í¬ì¸íŠ¸ í™•ì¸\n",
    "current_state = graph.get_state(config)\n",
    "\n",
    "print(f\"\\ní˜„ì¬ ìƒíƒœ: {current_state.values}\")\n",
    "print(f\"ëŒ€ê¸° ì¤‘ì¸ interrupt: {current_state.tasks}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ë‹¤ìŒ ë…¸ë“œ í™•ì¸\n",
    "current_state.next"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# í˜„ì¬ ìƒíƒœ ì¶œë ¥\n",
    "pprint(current_state.values)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- **ì›¹ ê²€ìƒ‰**: ë‹¤ì–‘í•œ ì†ŒìŠ¤ì—ì„œ ê´€ë ¨ ì •ë³´ ìˆ˜ì§‘\n",
    "\n",
    "    - ë§µ-ë¦¬ë“€ìŠ¤ íŒ¨í„´ìœ¼ë¡œ ë³‘ë ¬ ê²€ìƒ‰ ìˆ˜í–‰\n",
    "    - `Send` ì‚¬ìš©"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = search_tool.invoke(\"ê¸°í›„ë³€í™”\")\n",
    "results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ===== ê²€ìƒ‰ ë…¸ë“œ =====\n",
    "def ready_to_search(state: ResearchState) -> ResearchState:\n",
    "    \"\"\"ê²€ìƒ‰ ì¤€ë¹„\"\"\"\n",
    "    return {\"ready_for_search\": True}\n",
    "\n",
    "def dispatch_searches(state: ResearchState) -> List[Send]:\n",
    "    \"\"\"ë³‘ë ¬ ê²€ìƒ‰ ë””ìŠ¤íŒ¨ì¹˜\"\"\"\n",
    "    return [Send(\"search_one\", {\"keyword\": kw}) for kw in state[\"keywords\"]]\n",
    "\n",
    "def search_one(state: Dict) -> ResearchState:\n",
    "    \"\"\"ê°œë³„ ê²€ìƒ‰ ì‹¤í–‰\"\"\"\n",
    "    keyword = state[\"keyword\"]\n",
    "    try:\n",
    "        results = search_tool.invoke(keyword)\n",
    "        data = results.get(\"results\", results) if isinstance(results, dict) else results\n",
    "        return {\n",
    "            \"search_results\": [{\n",
    "                \"keyword\": keyword,\n",
    "                \"data\": data if isinstance(data, list) else [],\n",
    "                \"success\": True\n",
    "            }]\n",
    "        }  # type: ignore\n",
    "    except Exception as e:\n",
    "        return {\n",
    "            \"search_results\": [{\n",
    "                \"keyword\": keyword,\n",
    "                \"error\": str(e),\n",
    "                \"success\": False\n",
    "            }]\n",
    "        } # type: ignore\n",
    "\n",
    "\n",
    "# ===== ë³´ê³ ì„œ ìƒì„±  =====\n",
    "class Report(BaseModel):\n",
    "    \"\"\"ë³´ê³ ì„œ ëª¨ë¸\"\"\"\n",
    "    summary: str = Field(description=\"ì£¼ì œ ìš”ì•½\")\n",
    "    findings: List[str] = Field(description=\"ì£¼ìš” ë°œê²¬ì‚¬í•­ ë¦¬ìŠ¤íŠ¸ (ì¶œì²˜ëª…, ë§í¬ ë“±ì„ í¬í•¨)\")\n",
    "    recommendations: List[str] = Field(description=\"ì œì–¸ ë¦¬ìŠ¤íŠ¸\")\n",
    "\n",
    "def generate_report(state: ResearchState) -> ResearchState:\n",
    "    \"\"\"LLMì„ ì‚¬ìš©í•œ ë³´ê³ ì„œ ìƒì„±\"\"\"\n",
    "\n",
    "    results = state.get(\"search_results\", [])\n",
    "\n",
    "    if not results:\n",
    "        return {\"report\": f\"# {state['topic']}\\n\\nâŒ ê²€ìƒ‰ ê²°ê³¼ê°€ ì—†ìŠµë‹ˆë‹¤.\"}\n",
    "\n",
    "    prompt = ChatPromptTemplate.from_messages([\n",
    "        (\"system\", \"ë‹¹ì‹ ì€ ë¦¬ì„œì¹˜ ì „ë¬¸ê°€ì…ë‹ˆë‹¤. ê²€ìƒ‰ ê²°ê³¼ë¥¼ ë¶„ì„í•´ ê°„ê²°í•œ ë³´ê³ ì„œë¥¼ ì‘ì„±í•˜ì„¸ìš”. ë°˜ë“œì‹œ ì¶œì²˜ëª…ê³¼ ë§í¬ë¥¼ ëª…í™•íˆ í‘œê¸°í•˜ê³ , ì‹ ë¢°í•  ìˆ˜ ì—†ëŠ” ì •ë³´ëŠ” í¬í•¨í•˜ì§€ ë§ˆì„¸ìš”.\"),\n",
    "        (\"human\", \"ì£¼ì œ: {topic}\\n\\nê²€ìƒ‰ ê²°ê³¼:\\n{content}\")\n",
    "    ])\n",
    "    \n",
    "    try:\n",
    "        chain = prompt | llm.with_structured_output(Report)\n",
    "        report = chain.invoke({\n",
    "            \"topic\": state[\"topic\"],\n",
    "            \"content\": str(results)[:12000]  # í† í° ì œí•œ\n",
    "        })\n",
    "        \n",
    "        # ì¸ë¼ì¸ ë§ˆí¬ë‹¤ìš´ ìƒì„±\n",
    "        markdown = f\"\"\"# {state[\"topic\"]}\n",
    "\n",
    "## ğŸ“Œ ìš”ì•½\n",
    "{report.summary}\n",
    "\n",
    "## ğŸ” ì£¼ìš” ë°œê²¬ì‚¬í•­\n",
    "{chr(10).join(f\"{i}. {finding}\" for i, finding in enumerate(report.findings, 1))}\n",
    "\n",
    "## ğŸ’¡ ì œì–¸\n",
    "{chr(10).join(f\"{i}. {rec}\" for i, rec in enumerate(report.recommendations, 1))}\n",
    "\n",
    "---\n",
    "*ìƒì„±: {datetime.now().strftime('%Y-%m-%d %H:%M')}*\n",
    "*ê²€ìƒ‰: {sum(1 for r in state['search_results'] if r.get('success'))}ê°œ ì„±ê³µ*\"\"\"\n",
    "        \n",
    "        return {\"report\": markdown}\n",
    "        \n",
    "    except Exception as e:\n",
    "        return {\"report\": f\"# {state['topic']}\\n\\nâš ï¸ ë³´ê³ ì„œ ìƒì„±ì— ì‹¤íŒ¨í–ˆìŠµë‹ˆë‹¤: {str(e)}\"}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ===== ì›Œí¬í”Œë¡œìš° êµ¬ì„± =====\n",
    "# 1. ready_to_search (ê²€ìƒ‰ ì¤€ë¹„)\n",
    "# 2. dispatch_searches (ë³‘ë ¬ ê²€ìƒ‰ ì‹œì‘)\n",
    "# 3. search_one (ê°œë³„ ê²€ìƒ‰ - ë³‘ë ¬)\n",
    "# 4. generate_report (ê²€ìƒ‰ ê²°ê³¼ ì·¨í•©/ë¦¬ë“€ìŠ¤) \n",
    "\n",
    "workflow = StateGraph(ResearchState)\n",
    "\n",
    "# ë…¸ë“œ ì¶”ê°€\n",
    "workflow.add_node(\"analyze_topic\", generate_keywords)\n",
    "workflow.add_node(\"review_keywords\", review_keywords)\n",
    "workflow.add_node(\"process_feedback\", process_keyword_feedback)\n",
    "\n",
    "workflow.add_node(\"ready_to_search\", ready_to_search)\n",
    "workflow.add_node(\"search_one\", search_one)  # Sendì˜ íƒ€ê²Ÿ ë…¸ë“œ\n",
    "workflow.add_node(\"generate_report\", generate_report)\n",
    "\n",
    "# ì—£ì§€ ì—°ê²°\n",
    "workflow.add_edge(START, \"analyze_topic\")\n",
    "workflow.add_edge(\"analyze_topic\", \"review_keywords\")\n",
    "\n",
    "# í‚¤ì›Œë“œ ê²€í†  í›„ ì¡°ê±´ë¶€ ë¼ìš°íŒ…\n",
    "workflow.add_conditional_edges(\n",
    "    \"review_keywords\",\n",
    "    should_continue_after_review,\n",
    "    {\n",
    "        \"process_feedback\": \"process_feedback\",\n",
    "        \"regenerate\": \"analyze_topic\",\n",
    "        \"approved\": \"ready_to_search\"\n",
    "    }\n",
    ")\n",
    "\n",
    "# í”¼ë“œë°± ì²˜ë¦¬ í›„ ê²€ìƒ‰\n",
    "workflow.add_edge(\"process_feedback\", \"ready_to_search\")\n",
    "\n",
    "# Send ë§µ-ë¦¬ë“€ìŠ¤ ì—°ê²°\n",
    "workflow.add_conditional_edges(\n",
    "    \"ready_to_search\",\n",
    "    dispatch_searches,\n",
    "    [\"search_one\"]\n",
    ")\n",
    "workflow.add_edge(\"search_one\", \"generate_report\")\n",
    "\n",
    "# ë¶„ì„ ì™„ë£Œ í›„ ì¢…ë£Œ\n",
    "workflow.add_edge(\"generate_report\", END)\n",
    "\n",
    "# ì»´íŒŒì¼\n",
    "graph = workflow.compile(checkpointer=InMemorySaver())\n",
    "\n",
    "# ì‹œê°í™”\n",
    "display(Image(graph.get_graph().draw_mermaid_png()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ì´ˆê¸° ìƒíƒœ ì„¤ì •\n",
    "initial_state = {\n",
    "    \"topic\": \"2025 í•œêµ­ì˜ AI ì‚°ì—…\"\n",
    "}\n",
    "\n",
    "# ìŠ¤ë ˆë“œ ì„¤ì •\n",
    "config = {\"configurable\": {\"thread_id\": f\"test_thread_1\"}}\n",
    "\n",
    "\n",
    "# ì›Œí¬í”Œë¡œìš° ì‹¤í–‰\n",
    "# ì²« ë²ˆì§¸ ì‹¤í–‰ - ì¤‘ë‹¨ì ì—ì„œ ì‹¤í–‰ì„ ë©ˆì¶¤\n",
    "for event in graph.stream(initial_state, config=config):\n",
    "    print(f\"Event: {event}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langgraph.types import Command\n",
    "\n",
    "# ì‚¬ìš©ì í”¼ë“œë°± ì œê³µ (ìŠ¹ì¸ ë¬¸ìì—´ì„ ì‚¬ìš©)\n",
    "human_feedback = \"ìŠ¹ì¸\"\n",
    "\n",
    "# ì‚¬ìš©ì ì…ë ¥ìœ¼ë¡œ ê·¸ë˜í”„ ì¬ê°œ\n",
    "for event in graph.stream(Command(resume=human_feedback), config=config): \n",
    "    print(f\"Event: {event}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ë§ˆì§€ë§‰ ìƒíƒœ ì¶œë ¥\n",
    "final_state = graph.get_state(config)\n",
    "\n",
    "final_state.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ìµœì¢… ê²€ìƒ‰ ê²°ê³¼ ì¶œë ¥\n",
    "print(final_state.values.get(\"report\", []))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- **ì‚¬ìš©ì ê²€í† **: ì‚¬ìš©ìê°€ ë³´ê³ ì„œ ë‚´ìš©ì„ ê²€í† í•˜ê³  ìˆ˜ì • ìš”ì²­"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ===== ë³´ê³ ì„œ ê²€í†  ë…¸ë“œ (Human-in-the-loop) =====\n",
    "\n",
    "def review_report(state: ResearchState) -> ResearchState:\n",
    "    \"\"\"Human-in-the-loop: ë³´ê³ ì„œ ê²€í† \"\"\"\n",
    "    \n",
    "    # ë³´ê³ ì„œ ë¯¸ë¦¬ë³´ê¸° (500ìë¡œ ì œí•œ)\n",
    "    preview = state[\"report\"][:500] + \"...\" if len(state[\"report\"]) > 500 else state[\"report\"]\n",
    "    \n",
    "    # ì‚¬ìš©ì ì…ë ¥ ëŒ€ê¸°\n",
    "    user_input = interrupt({\n",
    "        \"report_preview\": preview,\n",
    "        \"instruction\": \"ë³´ê³ ì„œë¥¼ ê²€í† í•˜ì„¸ìš”. 'ìŠ¹ì¸' ë˜ëŠ” êµ¬ì²´ì ì¸ ìˆ˜ì • ìš”ì²­ì„ ì…ë ¥í•˜ì„¸ìš”:\"\n",
    "    })\n",
    "    \n",
    "    return Command(\n",
    "        goto=END if \"ìŠ¹ì¸\" in user_input else \"revise_report\",\n",
    "        update={\"feedback\": user_input}\n",
    "    )  # type: ignore"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- **ìµœì¢… ì™„ì„±**: í”¼ë“œë°±ì„ ë°˜ì˜í•œ ìµœì¢… ë³´ê³ ì„œ ìƒì„±"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ===== ë³´ê³ ì„œ ìˆ˜ì • ë…¸ë“œ =====\n",
    "def revise_report(state: ResearchState) -> ResearchState:\n",
    "    \"\"\"í”¼ë“œë°± ì²˜ë¦¬ ë° ë³´ê³ ì„œ ìˆ˜ì •\"\"\"\n",
    "    \n",
    "    feedback = state.get(\"feedback\", \"\").strip()\n",
    "    \n",
    "    # ìŠ¹ì¸ì¸ ê²½ìš° ë°”ë¡œ ì™„ë£Œ\n",
    "    if \"ìŠ¹ì¸\" in feedback.lower() or \"approve\" in feedback.lower():\n",
    "        return {\n",
    "            \"messages\": [AIMessage(\"âœ… ë³´ê³ ì„œê°€ ìŠ¹ì¸ë˜ì—ˆìŠµë‹ˆë‹¤!\")]\n",
    "        }  # type: ignore\n",
    "\n",
    "    # ìˆ˜ì • ìš”ì²­ ì²˜ë¦¬\n",
    "    if feedback:\n",
    "\n",
    "        # êµ¬ì¡°í™”ëœ í”„ë¡¬í”„íŠ¸ í…œí”Œë¦¿\n",
    "        revision_prompt = ChatPromptTemplate.from_messages([\n",
    "            (\"system\", \"\"\"ë‹¹ì‹ ì€ ì „ë¬¸ì ì¸ ë³´ê³ ì„œ í¸ì§‘ìì…ë‹ˆë‹¤.\n",
    "    ì‚¬ìš©ìì˜ í”¼ë“œë°±ì„ ë°˜ì˜í•˜ì—¬ ë³´ê³ ì„œë¥¼ ìˆ˜ì •í•˜ì„¸ìš”.\n",
    "\n",
    "    \n",
    "    ## ìˆ˜ì • ì›ì¹™:\n",
    "    1. ì›ë³¸ ë³´ê³ ì„œì˜ êµ¬ì¡°ì™€ í˜•ì‹ ìœ ì§€\n",
    "    2. ì‚¬ìš©ì ìš”ì²­ì‚¬í•­ì„ ì •í™•íˆ ë°˜ì˜\n",
    "    3. ì „ë¬¸ì ì´ê³  ëª…í™•í•œ ë¬¸ì²´ ìœ ì§€\n",
    "    4. ë§ˆí¬ë‹¤ìš´ í˜•ì‹ ì¤€ìˆ˜\"\"\"),\n",
    "            (\"human\", \"\"\"## í˜„ì¬ ë³´ê³ ì„œ:\n",
    "    {report}\n",
    "\n",
    "    ## ìˆ˜ì • ìš”ì²­ì‚¬í•­:\n",
    "    {feedback}\n",
    "\n",
    "    ìœ„ ìš”ì²­ì‚¬í•­ì„ ë°˜ì˜í•˜ì—¬ ë³´ê³ ì„œë¥¼ ìˆ˜ì •í•´ì£¼ì„¸ìš”.\"\"\")\n",
    "        ])\n",
    "        \n",
    "        try:\n",
    "            # LLM ì²´ì¸ ì‹¤í–‰\n",
    "            chain = revision_prompt | llm\n",
    "            response = chain.invoke({\n",
    "                \"report\": state[\"report\"],\n",
    "                \"feedback\": feedback\n",
    "            })\n",
    "            \n",
    "            # ìˆ˜ì •ëœ ë³´ê³ ì„œ ë°˜í™˜\n",
    "            return {\n",
    "                \"report\": response.content,\n",
    "                \"feedback\": \"\",  # í”¼ë“œë°± ì´ˆê¸°í™”\n",
    "                \"messages\": [AIMessage(f\"ğŸ“ ë³´ê³ ì„œê°€ ìˆ˜ì •ë˜ì—ˆìŠµë‹ˆë‹¤: {feedback[:50]}...\")]\n",
    "            }  # type: ignore\n",
    "\n",
    "        except Exception as e:\n",
    "            return {\n",
    "                \"messages\": [AIMessage(f\"âŒ ìˆ˜ì • ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {str(e)[:100]}\")]\n",
    "            }  # type: ignore\n",
    "    \n",
    "    # í”¼ë“œë°±ì´ ì—†ëŠ” ê²½ìš°\n",
    "    return {\n",
    "        \"messages\": [AIMessage(\"âš ï¸ í”¼ë“œë°±ì´ ì—†ì–´ ë³´ê³ ì„œë¥¼ ê·¸ëŒ€ë¡œ ìœ ì§€í•©ë‹ˆë‹¤.\")]\n",
    "    }  # type: ignore"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ===== ì›Œí¬í”Œë¡œìš° êµ¬ì„± =====\n",
    "# 1. ready_to_search (ê²€ìƒ‰ ì¤€ë¹„)\n",
    "# 2. dispatch_searches (ë³‘ë ¬ ê²€ìƒ‰ ì‹œì‘)\n",
    "# 3. search_one (ê°œë³„ ê²€ìƒ‰ - ë³‘ë ¬)\n",
    "# 4. generate_report (ê²€ìƒ‰ ê²°ê³¼ ì·¨í•©/ë¦¬ë“€ìŠ¤) \n",
    "# 5. review_report (ë³´ê³ ì„œ ê²€í† )\n",
    "# 6. revise_report (ë³´ê³ ì„œ ìˆ˜ì •)\n",
    "\n",
    "workflow = StateGraph(ResearchState)\n",
    "\n",
    "# ë…¸ë“œ ì¶”ê°€\n",
    "workflow.add_node(\"analyze_topic\", generate_keywords)\n",
    "workflow.add_node(\"review_keywords\", review_keywords)\n",
    "workflow.add_node(\"process_feedback\", process_keyword_feedback)\n",
    "\n",
    "workflow.add_node(\"ready_to_search\", ready_to_search)\n",
    "workflow.add_node(\"search_one\", search_one)  # Sendì˜ íƒ€ê²Ÿ ë…¸ë“œ\n",
    "workflow.add_node(\"generate_report\", generate_report)\n",
    "\n",
    "workflow.add_node(\"review_report\", review_report)\n",
    "workflow.add_node(\"revise_report\", revise_report)\n",
    "\n",
    "# ì—£ì§€ ì—°ê²°\n",
    "workflow.add_edge(START, \"analyze_topic\")\n",
    "workflow.add_edge(\"analyze_topic\", \"review_keywords\")\n",
    "\n",
    "# í‚¤ì›Œë“œ ê²€í†  í›„ ì¡°ê±´ë¶€ ë¼ìš°íŒ…\n",
    "workflow.add_conditional_edges(\n",
    "    \"review_keywords\",\n",
    "    should_continue_after_review,\n",
    "    {\n",
    "        \"process_feedback\": \"process_feedback\",\n",
    "        \"regenerate\": \"analyze_topic\",\n",
    "        \"approved\": \"ready_to_search\"\n",
    "    }\n",
    ")\n",
    "\n",
    "# í”¼ë“œë°± ì²˜ë¦¬ í›„ ê²€ìƒ‰\n",
    "workflow.add_edge(\"process_feedback\", \"ready_to_search\")\n",
    "\n",
    "# Send ë§µ-ë¦¬ë“€ìŠ¤ ì—°ê²°\n",
    "workflow.add_conditional_edges(\n",
    "    \"ready_to_search\",\n",
    "    dispatch_searches,\n",
    "    [\"search_one\"]\n",
    ")\n",
    "workflow.add_edge(\"search_one\", \"generate_report\")\n",
    "\n",
    "\n",
    "# ë³´ê³ ì„œ ìƒì„± í›„ ê²€í† \n",
    "workflow.add_edge(\"generate_report\", \"review_report\")\n",
    "workflow.add_edge(\"revise_report\", \"review_report\")\n",
    "\n",
    "# ì»´íŒŒì¼\n",
    "graph = workflow.compile(checkpointer=InMemorySaver())\n",
    "\n",
    "# ì‹œê°í™”\n",
    "display(Image(graph.get_graph().draw_mermaid_png()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ì´ˆê¸° ìƒíƒœ ì„¤ì •\n",
    "initial_state = {\n",
    "    \"topic\": \"LangGraphì™€ LlamaIndex ë¹„êµ\"\n",
    "}\n",
    "    \n",
    "# ìŠ¤ë ˆë“œ ì„¤ì •\n",
    "config = {\"configurable\": {\"thread_id\": f\"test_thread_1\"}}\n",
    "\n",
    "\n",
    "# ì›Œí¬í”Œë¡œìš° ì‹¤í–‰\n",
    "# ì²« ë²ˆì§¸ ì‹¤í–‰ - ì¤‘ë‹¨ì ì—ì„œ ì‹¤í–‰ì„ ë©ˆì¶¤\n",
    "for event in graph.stream(initial_state, config=config):\n",
    "    print(f\"Event: {event}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langgraph.types import Command\n",
    "\n",
    "# ì‚¬ìš©ì í”¼ë“œë°± ì œê³µ (ìŠ¹ì¸ ë¬¸ìì—´ì„ ì‚¬ìš©)\n",
    "human_feedback = \"ìŠ¹ì¸\"\n",
    "\n",
    "# ì‚¬ìš©ì ì…ë ¥ìœ¼ë¡œ ê·¸ë˜í”„ ì¬ê°œ\n",
    "for event in graph.stream(Command(resume=human_feedback), config=config): \n",
    "    print(f\"Event: {event}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ìƒíƒœ ì¶œë ¥\n",
    "current_state = graph.get_state(config)\n",
    "\n",
    "current_state.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ë‹¤ìŒ ë…¸ë“œ ì¶œë ¥\n",
    "current_state.next"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langgraph.types import Command\n",
    "\n",
    "# ì‚¬ìš©ì í”¼ë“œë°± ì œê³µ \n",
    "human_feedback = \"ë¹„êµí‘œë¥¼ ë§Œë“¤ì–´ì„œ ì¶”ê°€í•˜ì„¸ìš”.\"\n",
    "\n",
    "# ì‚¬ìš©ì ì…ë ¥ìœ¼ë¡œ ê·¸ë˜í”„ ì¬ê°œ\n",
    "for event in graph.stream(Command(resume=human_feedback), config=config): \n",
    "    print(f\"Event: {event}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ìƒíƒœ ì¶œë ¥\n",
    "current_state = graph.get_state(config)\n",
    "print(current_state.values.get(\"report\", []))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langgraph.types import Command\n",
    "\n",
    "# ì‚¬ìš©ì í”¼ë“œë°± ì œê³µ (ìŠ¹ì¸ ë¬¸ìì—´ì„ ì‚¬ìš©)\n",
    "human_feedback = \"ìŠ¹ì¸\"\n",
    "\n",
    "# ì‚¬ìš©ì ì…ë ¥ìœ¼ë¡œ ê·¸ë˜í”„ ì¬ê°œ\n",
    "for event in graph.stream(Command(resume=human_feedback), config=config): \n",
    "    print(f\"Event: {event}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ë§ˆì§€ë§‰ ìƒíƒœ ì¶œë ¥\n",
    "final_state = graph.get_state(config)\n",
    "\n",
    "# ìµœì¢… ê²€ìƒ‰ ê²°ê³¼ ì¶œë ¥\n",
    "print(final_state.values.get(\"report\", []))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ë‹¤ìŒ ë…¸ë“œ ì¶œë ¥\n",
    "final_state.next"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "kt-ds",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
