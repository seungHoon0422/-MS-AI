{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tool Calling & Agent\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 환경 설정 및 준비"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`(1) Env 환경변수`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dotenv import load_dotenv\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`(2) 기본 라이브러리`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from glob import glob\n",
    "\n",
    "from pprint import pprint\n",
    "import json"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`(3) Langsmith tracing 설정`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Langsmith tracing 여부를 확인 (true: langsmith 추적 활성화, false: langsmith 추적 비활성화)\n",
    "import os\n",
    "print(os.getenv('LANGSMITH_TRACING'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Tool Calling 개념\n",
    "\n",
    "- **Tool Calling**은 LLM이 외부 시스템과 상호작용하기 위한 핵심 메커니즘\n",
    "- **구조화된 출력**: LLM이 정의된 스키마에 따라 함수 호출 정보를 생성\n",
    "- **외부 시스템 연동**: API, 데이터베이스, 파일 시스템 등과 연결\n",
    "- **자동 검증**: 스키마 기반으로 입력 파라미터 자동 검증\n",
    "- **유연한 확장**: 새로운 도구를 쉽게 추가하고 제거 가능\n",
    "\n",
    "\n",
    "![Tool Calling Concept](https://python.langchain.com/assets/images/tool_calling_concept-552a73031228ff9144c7d59f26dedbbf.png)\n",
    "\n",
    "\n",
    "[참조] https://python.langchain.com/docs/concepts/tool_calling/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "### 1. 기본적인 Tool 생성\n",
    "\n",
    "#### 1.1 @tool 데코레이터 사용법\n",
    "\n",
    "- **@tool 데코레이터**로 함수에 스키마 정보 추가\n",
    "\n",
    "- **함수와 스키마** 간 자동 연결로 도구 생성"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.tools import tool\n",
    "from typing import Literal\n",
    "\n",
    "@tool\n",
    "def add(a: int, b: int) -> int:\n",
    "    \"\"\"두 정수를 더합니다.\n",
    "    \n",
    "    Args:\n",
    "        a: 첫 번째 정수\n",
    "        b: 두 번째 정수\n",
    "    \n",
    "    Returns:\n",
    "        두 수의 합\n",
    "    \"\"\"\n",
    "    return a + b\n",
    "\n",
    "@tool\n",
    "def multiply(a: int, b: int) -> int:\n",
    "    \"\"\"두 정수를 곱합니다.\n",
    "    \n",
    "    Args:\n",
    "        a: 첫 번째 정수\n",
    "        b: 두 번째 정수\n",
    "    \n",
    "    Returns:\n",
    "        두 수의 곱\n",
    "    \"\"\"\n",
    "    return a * b\n",
    "\n",
    "# 도구 실행 테스트\n",
    "print(add.invoke({'a': 3, 'b': 5}))  # 8\n",
    "print(multiply.invoke({'a': 4, 'b': 6}))  # 24"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1.2 복잡한 Tool 예제"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import datetime\n",
    "from typing import Optional\n",
    "\n",
    "@tool\n",
    "def get_current_time(format_type: Literal[\"date\", \"time\", \"both\"] = \"both\") -> str:\n",
    "    \"\"\"현재 날짜와 시간을 반환합니다.\n",
    "    \n",
    "    Args:\n",
    "        format_type: 반환할 형식 ('date', 'time', 'both' 중 선택)\n",
    "    \n",
    "    Returns:\n",
    "        포맷된 날짜/시간 문자열\n",
    "    \"\"\"\n",
    "    now = datetime.now()\n",
    "    \n",
    "    if format_type == \"date\":\n",
    "        return now.strftime(\"%Y년 %m월 %d일\")\n",
    "    elif format_type == \"time\":\n",
    "        return now.strftime(\"%H시 %M분 %S초\")\n",
    "    else:\n",
    "        return now.strftime(\"%Y년 %m월 %d일 %H시 %M분 %S초\")\n",
    "\n",
    "@tool\n",
    "def calculate_age(birth_year: int) -> str:\n",
    "    \"\"\"태어난 년도를 입력받아 나이를 계산합니다.\n",
    "    \n",
    "    Args:\n",
    "        birth_year: 태어난 년도 (예: 1990)\n",
    "    \n",
    "    Returns:\n",
    "        계산된 나이\n",
    "    \"\"\"\n",
    "    current_year = datetime.now().year\n",
    "    age = current_year - birth_year\n",
    "    return f\"{age}세\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1.3 DB 연결 Tool 예제"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 벡터 저장소 로드 \n",
    "from langchain_chroma import Chroma\n",
    "from langchain_openai import OpenAIEmbeddings\n",
    "\n",
    "def initialize_vector_store(embeddings = OpenAIEmbeddings(model=\"text-embedding-3-small\"), collection_name=\"hybrid_search_db\", persist_directory = \"./local_chroma_db\"):\n",
    "    \"\"\"\n",
    "    기존 벡터 저장소를 로드하거나 새로 생성\n",
    "    \n",
    "    Returns:\n",
    "        Chroma: 벡터 저장소 객체\n",
    "    \"\"\"\n",
    "    try:\n",
    "        \n",
    "        # 기존 벡터 저장소 로드 시도\n",
    "        vector_store = Chroma(\n",
    "            collection_name=collection_name,\n",
    "            embedding_function=embeddings,\n",
    "            persist_directory=persist_directory,\n",
    "        )\n",
    "        \n",
    "        doc_count = vector_store._collection.count()\n",
    "        if doc_count > 0:\n",
    "            print(f\"✅ 기존 벡터 저장소 로드: {doc_count}개 문서\")\n",
    "            return vector_store\n",
    "        else:\n",
    "            print(\"⚠️ 빈 벡터 저장소입니다. 데이터를 추가해주세요.\")\n",
    "            return vector_store\n",
    "            \n",
    "    except Exception as e:\n",
    "        print(f\"❌ 벡터 저장소 로드 실패: {e}\")\n",
    "        return None\n",
    "\n",
    "# 벡터 저장소 초기화\n",
    "chroma_db = initialize_vector_store()\n",
    "\n",
    "# 검색기 지정하여 테스트 \n",
    "chroma_k_retriever = chroma_db.as_retriever(\n",
    "    search_kwargs={\"k\": 2},\n",
    ")\n",
    "\n",
    "query = \"리비안은 언제 사업을 시작했나요?\"\n",
    "retrieved_docs = chroma_k_retriever.invoke(query)\n",
    "\n",
    "print(f\"쿼리: {query}\")\n",
    "print(\"검색 결과:\")\n",
    "for doc in retrieved_docs:\n",
    "    print(f\"{doc.page_content} [출처: {doc.metadata['source']}]\")\n",
    "    print('-'*100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# DB 검색하는 사용자 정의 도구 생성\n",
    "from langchain_core.tools import tool\n",
    "\n",
    "@tool\n",
    "def search_db(query: str):\n",
    "    \"\"\"리비안, 테슬라 회사에 대한 정보를 관련 데이터베이스에서 검색합니다.\"\"\"\n",
    "    docs = chroma_k_retriever.invoke(query)\n",
    "    return \"/n/n\".join([doc.page_content for doc in docs])\n",
    "\n",
    "# 도구 실행\n",
    "search_db.invoke(\"리비안은 언제 사업을 시작했나요?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.agents.agent_toolkits import create_retriever_tool\n",
    "\n",
    "# DB 검색하는 도구 생성\n",
    "search_db = create_retriever_tool(\n",
    "    chroma_k_retriever,\n",
    "    name=\"search_db\",\n",
    "    description=\"리비안, 테슬라 회사에 대한 정보를 관련 데이터베이스에서 검색합니다.\",\n",
    ")\n",
    "\n",
    "# 도구 실행\n",
    "search_db.invoke(\"리비안은 언제 사업을 시작했나요?\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Tool을 LLM에 연결하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_openai import ChatOpenAI\n",
    "\n",
    "# LLM 모델 초기화\n",
    "llm = ChatOpenAI(model=\"gpt-4.1-mini\", temperature=0)\n",
    "\n",
    "# 도구 목록 생성\n",
    "tools = [add, multiply, get_current_time, calculate_age, search_db]\n",
    "\n",
    "# 도구를 LLM에 바인딩\n",
    "llm_with_tools = llm.bind_tools(tools)\n",
    "\n",
    "# 계산 도구 호출 테스트\n",
    "response = llm_with_tools.invoke(\"15와 23을 더해주세요\")\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(response.tool_calls)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 날짜 시간 도구 호출 테스트\n",
    "response = llm_with_tools.invoke(\"현재 시간을 알려주세요\")\n",
    "print(response) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(response.tool_calls)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 나이 계산 도구 호출 테스트\n",
    "response = llm_with_tools.invoke(\"내가 태어난 년도는 1990년입니다. 내 나이를 알려주세요.\")\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(response.tool_calls)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# DB 검색 도구 호출\n",
    "response = llm_with_tools.invoke(\"리비안은 언제 사업을 시작했나요?\")\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(response.tool_calls)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Tool Calling 처리하기\n",
    "\n",
    "#### 3.1 Tool Calls 확인하고 실행하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def execute_tool_calls(message, tools_dict):\n",
    "    \"\"\"Tool calls를 실행하고 도구 실행 결과인 ToolMessage 리스트를 반환합니다.\"\"\"\n",
    "    results = []\n",
    "    \n",
    "    for tool_call in message.tool_calls:\n",
    "\n",
    "        tool_name = tool_call['name']\n",
    "        \n",
    "        if tool_name in tools_dict:\n",
    "            tool = tools_dict[tool_name]\n",
    "            tool_msg = tool.invoke(tool_call)\n",
    "            results.append(tool_msg)\n",
    "    \n",
    "    return results\n",
    "\n",
    "# 도구 딕셔너리 생성\n",
    "tools_dict = {tool.name: tool for tool in tools}\n",
    "\n",
    "# 테스트\n",
    "response = llm_with_tools.invoke(\"오늘 날짜를 알려주세요\")\n",
    "if response.tool_calls:\n",
    "    tool_messages = execute_tool_calls(response, tools_dict)\n",
    "    for msg in tool_messages:\n",
    "        msg.pretty_print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "msg"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3.2 완전한 대화 흐름"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.messages import HumanMessage, AIMessage, ToolMessage\n",
    "\n",
    "def chat_with_tools(user_input: str, llm_with_tools, tools_dict):\n",
    "    \"\"\"도구를 사용한 완전한 대화 처리\"\"\"\n",
    "    messages = [HumanMessage(content=user_input)]\n",
    "    \n",
    "    # LLM 호출\n",
    "    ai_response = llm_with_tools.invoke(messages)\n",
    "    messages.append(ai_response)\n",
    "    \n",
    "    # Tool calls가 있으면 실행\n",
    "    if ai_response.tool_calls:\n",
    "        for tool_call in ai_response.tool_calls:\n",
    "            tool_name = tool_call['name']            \n",
    "            # 도구 실행\n",
    "            if tool_name in tools_dict:\n",
    "                tool_msg = tools_dict[tool_name].invoke(tool_call)\n",
    "                # ToolMessage 추가\n",
    "                messages.append(tool_msg)\n",
    "\n",
    "        # 최종 응답 생성\n",
    "        final_response = llm_with_tools.invoke(messages)\n",
    "        return final_response.content, messages\n",
    "    else:\n",
    "        return ai_response.content, messages\n",
    "\n",
    "# 테스트\n",
    "result, tool_messages = chat_with_tools(\"15 곱하기 8은 얼마인가요?\", llm_with_tools, tools_dict)\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for msg in tool_messages:\n",
    "    msg.pretty_print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "###  Tool Calling 사용 시 **고려사항**\n",
    "\n",
    "- **모델 호환성**이 Tool Calling 성능에 직접 영향\n",
    "\n",
    "- **명확한 도구 정의**가 모델의 이해도와 활용도 향상\n",
    "\n",
    "- **단순한 기능**의 도구가 더 효과적으로 작동\n",
    "\n",
    "- **과다한 도구**는 모델 성능 저하 유발"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Agent 개념과 실습\n",
    "\n",
    "- **Agent**는 LLM을 의사결정 엔진으로 사용하여 복잡한 작업을 자동으로 수행하는 시스템\n",
    "- Agent의 구성 요소:\n",
    "    1. **LLM (추론 엔진)**: 상황을 분석하고 다음 행동을 결정\n",
    "    2. **Tools (도구)**: Agent가 사용할 수 있는 기능들\n",
    "    3. **Memory (메모리)**: 이전 대화나 작업 기록 저장\n",
    "    4. **Prompt (프롬프트)**: Agent의 역할과 행동 지침 정의\n",
    "- **LangGraph** 활용\n",
    "    - **LangGraph**는 LangChain의 확장 도구로 **고급 에이전트 개발**을 지원\n",
    "    - **그래프 기반 워크플로우**를 통해 복잡한 에이전트 로직을 구현할 수 있음 \n",
    "    - 상태 관리와 **타입 안전성**을 통해 안정적인 에이전트 실행을 보장"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langgraph.prebuilt import create_react_agent \n",
    "\n",
    "# 기본 React Agent 생성\n",
    "tools = [add, multiply, get_current_time, calculate_age, search_db]\n",
    "langgraph_agent = create_react_agent(llm, tools)\n",
    "\n",
    "# 실행\n",
    "response = langgraph_agent.invoke({\n",
    "    \"messages\": [HumanMessage(content=\"25 + 17을 계산해주세요\")]\n",
    "})\n",
    "\n",
    "for message in response['messages']:\n",
    "    message.pretty_print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 실행\n",
    "response = langgraph_agent.invoke({\n",
    "    \"messages\": [HumanMessage(content=\"리비안의 설립 과정에 대해 알려주세요.\")]\n",
    "})\n",
    "\n",
    "for message in response['messages']:\n",
    "    message.pretty_print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pprint(message.content)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
